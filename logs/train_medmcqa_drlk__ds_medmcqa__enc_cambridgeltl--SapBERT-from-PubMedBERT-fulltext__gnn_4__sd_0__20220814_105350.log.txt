Namespace(att_dim=50, att_head_num=2, att_layer_num=1, batch_size=128, cpnet_vocab_path='./data/ddb/vocab.txt', cuda=True, dataset='medmcqa', debug=False, decoder_lr=0.001, dev_adj='./data/medmcqa/graph/dev.graph.adj.pk', dev_embs='./data/medmcqa/features/dev.cambridgeltl--SapBERT-from-PubMedBERT-fulltext.features.pk', dev_statements='./data/medmcqa/statement/dev.statement.jsonl', diag_decompose=True, dropoutf=0.2, dropoutg=0.1, dropouti=0.1, encoder='./LM_models/cambridgeltl--SapBERT-from-PubMedBERT-fulltext', encoder_layer=-1, encoder_lr=5e-05, ent_emb=['ddb'], ent_emb_paths=['./data/ddb/ent_emb.npy'], eps=1e-15, eval_batch_size=4, fc_dim=200, fc_layer_num=0, fix_trans=False, format=[], freeze_ent_emb=True, gamma=1.0, gnn_dim=100, gnn_layer_num=4, inhouse=False, inhouse_train_qids='./data/medmcqa/inhouse_split_qids.txt', init_identity=True, init_range=0.02, init_rn=True, log_interval=20, loss='cross_entropy', lr_schedule='fixed', max_epochs_before_stop=10, max_grad_norm=1.0, max_node_num=200, max_seq_len=128, mini_batch_size=2, mode='train', n_epochs=100, num_basis=0, num_relation=30, optim='radam', preds_dir='./preds_res/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/', refreeze_epoch=10000, save_dir='./saved_models/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/', seed=0, simple=False, subsample=1.0, test_adj='./data/medmcqa/graph/test.graph.adj.pk', test_embs='./data/medmcqa/features/test.cambridgeltl--SapBERT-from-PubMedBERT-fulltext.features.pk', test_statements='./data/medmcqa/statement/test.statement.jsonl', train_adj='./data/medmcqa/graph/train.graph.adj.pk', train_embs='./data/medmcqa/features/train.cambridgeltl--SapBERT-from-PubMedBERT-fulltext.features.pk', train_statements='./data/medmcqa/statement/train.statement.jsonl', unfreeze_epoch=0, use_contextualized=False, warmup_steps=50, weight_decay=0.01)
| num_concepts: 9958 |
loading adj matrices:   0%|          | 0/731288 [00:00<?, ?it/s]/mnt/zm/DRLK/utils/data_utils.py:256: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)
  node_type_ids[idx, :num_concept][torch.tensor(
/mnt/zm/DRLK/utils/data_utils.py:258: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)
  node_type_ids[idx, :num_concept][torch.tensor(
loading adj matrices:   0%|          | 682/731288 [00:00<01:47, 6811.66it/s]loading adj matrices:   0%|          | 1371/731288 [00:00<01:46, 6852.16it/s]loading adj matrices:   0%|          | 2058/731288 [00:00<01:46, 6855.91it/s]loading adj matrices:   0%|          | 2744/731288 [00:00<01:48, 6729.08it/s]loading adj matrices:   0%|          | 3418/731288 [00:00<01:48, 6684.07it/s]loading adj matrices:   1%|          | 4087/731288 [00:00<01:49, 6628.14it/s]loading adj matrices:   1%|          | 4750/731288 [00:00<01:50, 6596.33it/s]loading adj matrices:   1%|          | 5410/731288 [00:00<01:50, 6566.35it/s]loading adj matrices:   1%|          | 6067/731288 [00:00<01:50, 6564.10it/s]loading adj matrices:   1%|          | 6724/731288 [00:01<01:50, 6545.55it/s]loading adj matrices:   1%|          | 7379/731288 [00:01<01:50, 6534.13it/s]loading adj matrices:   1%|          | 8033/731288 [00:01<01:50, 6524.11it/s]loading adj matrices:   1%|          | 8687/731288 [00:01<01:50, 6527.32it/s]loading adj matrices:   1%|▏         | 9340/731288 [00:01<01:50, 6506.87it/s]loading adj matrices:   1%|▏         | 9995/731288 [00:01<01:50, 6517.42it/s]loading adj matrices:   1%|▏         | 10647/731288 [00:01<01:50, 6497.22it/s]loading adj matrices:   2%|▏         | 11297/731288 [00:01<01:51, 6482.09it/s]loading adj matrices:   2%|▏         | 11946/731288 [00:01<01:50, 6484.06it/s]loading adj matrices:   2%|▏         | 12595/731288 [00:01<01:50, 6484.84it/s]loading adj matrices:   2%|▏         | 13244/731288 [00:02<01:51, 6458.02it/s]loading adj matrices:   2%|▏         | 13890/731288 [00:02<01:51, 6456.75it/s]loading adj matrices:   2%|▏         | 14536/731288 [00:02<01:51, 6449.32it/s]loading adj matrices:   2%|▏         | 15185/731288 [00:02<01:50, 6460.53it/s]loading adj matrices:   2%|▏         | 15832/731288 [00:02<01:50, 6460.08it/s]loading adj matrices:   2%|▏         | 16483/731288 [00:02<01:50, 6474.65it/s]loading adj matrices:   2%|▏         | 17134/731288 [00:02<01:50, 6484.55it/s]loading adj matrices:   2%|▏         | 17783/731288 [00:02<01:50, 6469.21it/s]loading adj matrices:   3%|▎         | 18430/731288 [00:02<01:50, 6468.54it/s]loading adj matrices:   3%|▎         | 19077/731288 [00:02<01:50, 6459.13it/s]loading adj matrices:   3%|▎         | 19723/731288 [00:03<01:50, 6435.94it/s]loading adj matrices:   3%|▎         | 20376/731288 [00:03<01:50, 6460.99it/s]loading adj matrices:   3%|▎         | 21023/731288 [00:03<01:49, 6461.09it/s]loading adj matrices:   3%|▎         | 21670/731288 [00:03<01:50, 6438.98it/s]loading adj matrices:   3%|▎         | 22320/731288 [00:03<01:49, 6454.76it/s]loading adj matrices:   3%|▎         | 22967/731288 [00:03<01:49, 6457.88it/s]loading adj matrices:   3%|▎         | 23614/731288 [00:03<01:49, 6458.84it/s]loading adj matrices:   3%|▎         | 24260/731288 [00:03<01:49, 6447.27it/s]loading adj matrices:   3%|▎         | 24905/731288 [00:03<01:49, 6439.61it/s]loading adj matrices:   3%|▎         | 25551/731288 [00:03<01:49, 6444.27it/s]loading adj matrices:   4%|▎         | 26196/731288 [00:04<01:49, 6430.35it/s]loading adj matrices:   4%|▎         | 26842/731288 [00:04<01:49, 6437.10it/s]loading adj matrices:   4%|▍         | 27486/731288 [00:04<01:49, 6436.89it/s]loading adj matrices:   4%|▍         | 28130/731288 [00:04<01:49, 6418.04it/s]loading adj matrices:   4%|▍         | 28772/731288 [00:04<01:49, 6415.98it/s]loading adj matrices:   4%|▍         | 29415/731288 [00:04<01:49, 6418.38it/s]loading adj matrices:   4%|▍         | 30057/731288 [00:04<01:49, 6390.23it/s]loading adj matrices:   4%|▍         | 30697/731288 [00:04<01:49, 6376.44it/s]loading adj matrices:   4%|▍         | 31335/731288 [00:04<01:49, 6365.11it/s]loading adj matrices:   4%|▍         | 31972/731288 [00:04<01:49, 6364.25it/s]loading adj matrices:   4%|▍         | 32609/731288 [00:05<01:50, 6345.36it/s]loading adj matrices:   5%|▍         | 33247/731288 [00:05<01:49, 6354.03it/s]loading adj matrices:   5%|▍         | 33885/731288 [00:05<01:49, 6359.71it/s]loading adj matrices:   5%|▍         | 34521/731288 [00:05<01:49, 6342.04it/s]loading adj matrices:   5%|▍         | 35156/731288 [00:05<01:49, 6332.56it/s]loading adj matrices:   5%|▍         | 35791/731288 [00:05<01:49, 6337.46it/s]loading adj matrices:   5%|▍         | 36425/731288 [00:05<01:49, 6327.96it/s]loading adj matrices:   5%|▌         | 37058/731288 [00:05<01:49, 6316.56it/s]loading adj matrices:   5%|▌         | 37691/731288 [00:05<01:49, 6319.36it/s]loading adj matrices:   5%|▌         | 38326/731288 [00:05<01:49, 6328.45it/s]loading adj matrices:   5%|▌         | 38959/731288 [00:06<01:49, 6313.67it/s]loading adj matrices:   5%|▌         | 39595/731288 [00:06<01:49, 6324.40it/s]loading adj matrices:   6%|▌         | 40228/731288 [00:06<01:49, 6325.66it/s]loading adj matrices:   6%|▌         | 40861/731288 [00:06<01:49, 6301.54it/s]loading adj matrices:   6%|▌         | 41493/731288 [00:06<01:49, 6305.74it/s]loading adj matrices:   6%|▌         | 42124/731288 [00:06<01:49, 6304.63it/s]loading adj matrices:   6%|▌         | 42755/731288 [00:06<01:49, 6294.32it/s]loading adj matrices:   6%|▌         | 43385/731288 [00:06<01:49, 6286.08it/s]loading adj matrices:   6%|▌         | 44014/731288 [00:06<01:49, 6267.10it/s]loading adj matrices:   6%|▌         | 44641/731288 [00:06<01:49, 6248.44it/s]loading adj matrices:   6%|▌         | 45266/731288 [00:07<01:50, 6227.85it/s]loading adj matrices:   6%|▋         | 45891/731288 [00:07<01:49, 6233.81it/s]loading adj matrices:   6%|▋         | 46515/731288 [00:07<01:50, 6216.19it/s]loading adj matrices:   6%|▋         | 47139/731288 [00:07<01:49, 6222.67it/s]loading adj matrices:   7%|▋         | 47762/731288 [00:07<01:49, 6223.03it/s]loading adj matrices:   7%|▋         | 48385/731288 [00:07<01:49, 6213.18it/s]loading adj matrices:   7%|▋         | 49007/731288 [00:07<01:50, 6168.78it/s]loading adj matrices:   7%|▋         | 49624/731288 [00:07<01:51, 6136.89it/s]loading adj matrices:   7%|▋         | 50238/731288 [00:07<01:51, 6123.70it/s]loading adj matrices:   7%|▋         | 50851/731288 [00:07<01:51, 6083.15it/s]loading adj matrices:   7%|▋         | 51467/731288 [00:08<01:51, 6105.36it/s]loading adj matrices:   7%|▋         | 52092/731288 [00:08<01:50, 6147.35it/s]loading adj matrices:   7%|▋         | 52722/731288 [00:08<01:49, 6192.29it/s]loading adj matrices:   7%|▋         | 53342/731288 [00:08<01:49, 6191.25it/s]loading adj matrices:   7%|▋         | 53972/731288 [00:08<01:48, 6221.93it/s]loading adj matrices:   7%|▋         | 54598/731288 [00:08<01:48, 6232.60it/s]loading adj matrices:   8%|▊         | 55222/731288 [00:08<01:48, 6223.21it/s]loading adj matrices:   8%|▊         | 55852/731288 [00:08<01:48, 6244.09it/s]loading adj matrices:   8%|▊         | 56481/731288 [00:08<01:47, 6257.71it/s]loading adj matrices:   8%|▊         | 57107/731288 [00:08<01:48, 6228.58it/s]loading adj matrices:   8%|▊         | 57730/731288 [00:09<01:48, 6201.00it/s]loading adj matrices:   8%|▊         | 58351/731288 [00:09<01:48, 6189.04it/s]loading adj matrices:   8%|▊         | 58974/731288 [00:09<01:48, 6201.11it/s]loading adj matrices:   8%|▊         | 59595/731288 [00:09<01:49, 6153.13it/s]loading adj matrices:   8%|▊         | 60214/731288 [00:09<01:48, 6163.55it/s]loading adj matrices:   8%|▊         | 60841/731288 [00:09<01:48, 6192.11it/s]loading adj matrices:   8%|▊         | 61462/731288 [00:09<01:48, 6194.74it/s]loading adj matrices:   8%|▊         | 62082/731288 [00:09<01:48, 6183.63it/s]loading adj matrices:   9%|▊         | 62702/731288 [00:09<01:48, 6186.03it/s]loading adj matrices:   9%|▊         | 63323/731288 [00:09<01:47, 6193.01it/s]loading adj matrices:   9%|▊         | 63943/731288 [00:10<01:48, 6148.09it/s]loading adj matrices:   9%|▉         | 64562/731288 [00:10<01:48, 6158.29it/s]loading adj matrices:   9%|▉         | 65186/731288 [00:10<01:47, 6180.36it/s]loading adj matrices:   9%|▉         | 65805/731288 [00:10<01:48, 6148.09it/s]loading adj matrices:   9%|▉         | 66420/731288 [00:10<01:48, 6146.34it/s]loading adj matrices:   9%|▉         | 67038/731288 [00:10<01:47, 6153.93it/s]loading adj matrices:   9%|▉         | 67654/731288 [00:10<01:47, 6150.71it/s]loading adj matrices:   9%|▉         | 68270/731288 [00:10<01:48, 6127.54it/s]loading adj matrices:   9%|▉         | 68887/731288 [00:10<01:47, 6137.77it/s]loading adj matrices:  10%|▉         | 69501/731288 [00:10<01:47, 6135.73it/s]loading adj matrices:  10%|▉         | 70115/731288 [00:12<07:43, 1426.95it/s]loading adj matrices:  10%|▉         | 70683/731288 [00:12<06:04, 1811.27it/s]loading adj matrices:  10%|▉         | 71272/731288 [00:12<04:49, 2277.24it/s]loading adj matrices:  10%|▉         | 71869/731288 [00:12<03:55, 2795.49it/s]loading adj matrices:  10%|▉         | 72460/731288 [00:12<03:18, 3315.32it/s]loading adj matrices:  10%|▉         | 73059/731288 [00:12<02:51, 3829.40it/s]loading adj matrices:  10%|█         | 73657/731288 [00:12<02:33, 4291.79it/s]loading adj matrices:  10%|█         | 74251/731288 [00:12<02:20, 4678.32it/s]loading adj matrices:  10%|█         | 74840/731288 [00:12<02:11, 4982.97it/s]loading adj matrices:  10%|█         | 75430/731288 [00:13<02:05, 5223.76it/s]loading adj matrices:  10%|█         | 76016/731288 [00:13<02:01, 5384.93it/s]loading adj matrices:  10%|█         | 76600/731288 [00:13<01:58, 5509.85it/s]loading adj matrices:  11%|█         | 77193/731288 [00:13<01:56, 5629.42it/s]loading adj matrices:  11%|█         | 77787/731288 [00:13<01:54, 5718.58it/s]loading adj matrices:  11%|█         | 78376/731288 [00:13<01:53, 5766.33it/s]loading adj matrices:  11%|█         | 78965/731288 [00:13<01:53, 5751.05it/s]loading adj matrices:  11%|█         | 79549/731288 [00:13<01:53, 5752.77it/s]loading adj matrices:  11%|█         | 80135/731288 [00:13<01:52, 5782.74it/s]loading adj matrices:  11%|█         | 80718/731288 [00:13<01:52, 5773.90it/s]loading adj matrices:  11%|█         | 81302/731288 [00:14<01:52, 5791.23it/s]loading adj matrices:  11%|█         | 81884/731288 [00:14<01:52, 5792.54it/s]loading adj matrices:  11%|█▏        | 82465/731288 [00:14<01:52, 5772.46it/s]loading adj matrices:  11%|█▏        | 83044/731288 [00:14<01:52, 5764.71it/s]loading adj matrices:  11%|█▏        | 83627/731288 [00:14<01:52, 5781.64it/s]loading adj matrices:  12%|█▏        | 84206/731288 [00:14<01:52, 5761.34it/s]loading adj matrices:  12%|█▏        | 84783/731288 [00:14<01:52, 5739.11it/s]loading adj matrices:  12%|█▏        | 85358/731288 [00:14<01:52, 5730.51it/s]loading adj matrices:  12%|█▏        | 85932/731288 [00:14<01:52, 5730.25it/s]loading adj matrices:  12%|█▏        | 86506/731288 [00:14<01:52, 5712.54it/s]loading adj matrices:  12%|█▏        | 87078/731288 [00:15<01:53, 5689.87it/s]loading adj matrices:  12%|█▏        | 87648/731288 [00:15<01:53, 5681.92it/s]loading adj matrices:  12%|█▏        | 88217/731288 [00:15<01:53, 5665.86it/s]loading adj matrices:  12%|█▏        | 88787/731288 [00:15<01:53, 5674.68it/s]loading adj matrices:  12%|█▏        | 89355/731288 [00:15<01:53, 5673.02it/s]loading adj matrices:  12%|█▏        | 89923/731288 [00:15<01:53, 5671.90it/s]loading adj matrices:  12%|█▏        | 90491/731288 [00:15<01:53, 5669.41it/s]loading adj matrices:  12%|█▏        | 91058/731288 [00:15<01:53, 5655.86it/s]loading adj matrices:  13%|█▎        | 91624/731288 [00:15<01:53, 5640.18it/s]loading adj matrices:  13%|█▎        | 92194/731288 [00:15<01:53, 5655.05it/s]loading adj matrices:  13%|█▎        | 92760/731288 [00:16<01:53, 5637.81it/s]loading adj matrices:  13%|█▎        | 93324/731288 [00:16<01:53, 5614.00it/s]loading adj matrices:  13%|█▎        | 93886/731288 [00:16<01:53, 5609.34it/s]loading adj matrices:  13%|█▎        | 94448/731288 [00:16<01:53, 5609.83it/s]loading adj matrices:  13%|█▎        | 95012/731288 [00:16<01:53, 5616.77it/s]loading adj matrices:  13%|█▎        | 95574/731288 [00:16<01:53, 5592.35it/s]loading adj matrices:  13%|█▎        | 96135/731288 [00:16<01:53, 5596.04it/s]loading adj matrices:  13%|█▎        | 96695/731288 [00:16<01:53, 5590.92it/s]loading adj matrices:  13%|█▎        | 97255/731288 [00:16<01:53, 5577.25it/s]loading adj matrices:  13%|█▎        | 97813/731288 [00:17<01:53, 5559.69it/s]loading adj matrices:  13%|█▎        | 98376/731288 [00:17<01:53, 5577.64it/s]loading adj matrices:  14%|█▎        | 98938/731288 [00:17<01:53, 5590.08it/s]loading adj matrices:  14%|█▎        | 99498/731288 [00:17<01:53, 5570.45it/s]loading adj matrices:  14%|█▎        | 100061/731288 [00:17<01:53, 5585.75it/s]loading adj matrices:  14%|█▍        | 100621/731288 [00:17<01:52, 5589.08it/s]loading adj matrices:  14%|█▍        | 101183/731288 [00:17<01:52, 5595.60it/s]loading adj matrices:  14%|█▍        | 101743/731288 [00:17<01:52, 5577.60it/s]loading adj matrices:  14%|█▍        | 102302/731288 [00:17<01:52, 5580.93it/s]loading adj matrices:  14%|█▍        | 102861/731288 [00:17<01:52, 5574.03it/s]loading adj matrices:  14%|█▍        | 103419/731288 [00:18<01:53, 5547.13it/s]loading adj matrices:  14%|█▍        | 103977/731288 [00:18<01:52, 5554.29it/s]loading adj matrices:  14%|█▍        | 104533/731288 [00:18<01:52, 5555.21it/s]loading adj matrices:  14%|█▍        | 105089/731288 [00:18<01:52, 5555.83it/s]loading adj matrices:  14%|█▍        | 105645/731288 [00:18<01:52, 5551.24it/s]loading adj matrices:  15%|█▍        | 106201/731288 [00:18<01:52, 5542.72it/s]loading adj matrices:  15%|█▍        | 106756/731288 [00:18<01:52, 5539.11it/s]loading adj matrices:  15%|█▍        | 107315/731288 [00:18<01:52, 5553.17it/s]loading adj matrices:  15%|█▍        | 107871/731288 [00:18<01:52, 5530.32it/s]loading adj matrices:  15%|█▍        | 108427/731288 [00:18<01:52, 5538.52it/s]loading adj matrices:  15%|█▍        | 108981/731288 [00:19<01:52, 5535.76it/s]loading adj matrices:  15%|█▍        | 109535/731288 [00:19<01:52, 5533.33it/s]loading adj matrices:  15%|█▌        | 110089/731288 [00:19<01:52, 5498.85it/s]loading adj matrices:  15%|█▌        | 110640/731288 [00:19<01:52, 5501.21it/s]loading adj matrices:  15%|█▌        | 111191/731288 [00:19<01:52, 5492.65it/s]loading adj matrices:  15%|█▌        | 111743/731288 [00:19<01:52, 5498.64it/s]loading adj matrices:  15%|█▌        | 112293/731288 [00:19<01:52, 5497.31it/s]loading adj matrices:  15%|█▌        | 112845/731288 [00:19<01:52, 5502.09it/s]loading adj matrices:  16%|█▌        | 113399/731288 [00:19<01:52, 5512.81it/s]loading adj matrices:  16%|█▌        | 113954/731288 [00:19<01:51, 5522.12it/s]loading adj matrices:  16%|█▌        | 114507/731288 [00:20<01:52, 5500.93it/s]loading adj matrices:  16%|█▌        | 115058/731288 [00:20<01:51, 5503.41it/s]loading adj matrices:  16%|█▌        | 115609/731288 [00:20<01:51, 5505.06it/s]loading adj matrices:  16%|█▌        | 116160/731288 [00:20<01:52, 5484.22it/s]loading adj matrices:  16%|█▌        | 116713/731288 [00:20<01:51, 5494.89it/s]loading adj matrices:  16%|█▌        | 117264/731288 [00:20<01:51, 5498.41it/s]loading adj matrices:  16%|█▌        | 117814/731288 [00:20<01:51, 5497.71it/s]loading adj matrices:  16%|█▌        | 118364/731288 [00:20<01:51, 5484.61it/s]loading adj matrices:  16%|█▋        | 118915/731288 [00:20<01:51, 5491.03it/s]loading adj matrices:  16%|█▋        | 119467/731288 [00:20<01:51, 5499.22it/s]loading adj matrices:  16%|█▋        | 120018/731288 [00:21<01:51, 5501.73it/s]loading adj matrices:  16%|█▋        | 120569/731288 [00:21<01:51, 5480.04it/s]loading adj matrices:  17%|█▋        | 121119/731288 [00:21<01:51, 5484.05it/s]loading adj matrices:  17%|█▋        | 121669/731288 [00:21<01:51, 5486.68it/s]loading adj matrices:  17%|█▋        | 122221/731288 [00:21<01:50, 5495.67it/s]loading adj matrices:  17%|█▋        | 122771/731288 [00:21<01:51, 5469.18it/s]loading adj matrices:  17%|█▋        | 123321/731288 [00:21<01:51, 5476.56it/s]loading adj matrices:  17%|█▋        | 123869/731288 [00:21<01:50, 5476.02it/s]loading adj matrices:  17%|█▋        | 124418/731288 [00:21<01:50, 5478.88it/s]loading adj matrices:  17%|█▋        | 124966/731288 [00:21<01:50, 5469.28it/s]loading adj matrices:  17%|█▋        | 125516/731288 [00:22<01:50, 5476.99it/s]loading adj matrices:  17%|█▋        | 126065/731288 [00:22<01:50, 5478.61it/s]loading adj matrices:  17%|█▋        | 126616/731288 [00:22<01:50, 5486.57it/s]loading adj matrices:  17%|█▋        | 127165/731288 [00:22<01:50, 5476.86it/s]loading adj matrices:  17%|█▋        | 127713/731288 [00:22<01:50, 5466.07it/s]loading adj matrices:  18%|█▊        | 128262/731288 [00:22<01:50, 5473.16it/s]loading adj matrices:  18%|█▊        | 128810/731288 [00:22<01:50, 5453.09it/s]loading adj matrices:  18%|█▊        | 129365/731288 [00:22<01:49, 5480.03it/s]loading adj matrices:  18%|█▊        | 129919/731288 [00:22<01:49, 5496.79it/s]loading adj matrices:  18%|█▊        | 130470/731288 [00:22<01:49, 5499.48it/s]loading adj matrices:  18%|█▊        | 131020/731288 [00:23<01:49, 5490.43it/s]loading adj matrices:  18%|█▊        | 131574/731288 [00:23<01:48, 5503.04it/s]loading adj matrices:  18%|█▊        | 132125/731288 [00:23<01:49, 5492.31it/s]loading adj matrices:  18%|█▊        | 132676/731288 [00:23<01:48, 5495.85it/s]loading adj matrices:  18%|█▊        | 133226/731288 [00:23<01:49, 5479.58it/s]loading adj matrices:  18%|█▊        | 133774/731288 [00:23<01:49, 5474.06it/s]loading adj matrices:  18%|█▊        | 134322/731288 [00:23<01:49, 5463.99it/s]loading adj matrices:  18%|█▊        | 134870/731288 [00:23<01:49, 5466.77it/s]loading adj matrices:  19%|█▊        | 135417/731288 [00:23<01:49, 5453.96it/s]loading adj matrices:  19%|█▊        | 135964/731288 [00:23<01:49, 5457.49it/s]loading adj matrices:  19%|█▊        | 136513/731288 [00:24<01:48, 5464.45it/s]loading adj matrices:  19%|█▊        | 137060/731288 [00:24<01:48, 5463.70it/s]loading adj matrices:  19%|█▉        | 137607/731288 [00:24<01:49, 5442.24it/s]loading adj matrices:  19%|█▉        | 138159/731288 [00:24<01:48, 5462.56it/s]loading adj matrices:  19%|█▉        | 138706/731288 [00:24<01:48, 5454.43it/s]loading adj matrices:  19%|█▉        | 139254/731288 [00:24<01:48, 5459.54it/s]loading adj matrices:  19%|█▉        | 139800/731288 [00:24<01:48, 5431.10it/s]loading adj matrices:  19%|█▉        | 140346/731288 [00:24<01:48, 5439.14it/s]loading adj matrices:  19%|█▉        | 140890/731288 [00:24<01:48, 5436.90it/s]loading adj matrices:  19%|█▉        | 141434/731288 [00:24<01:48, 5425.64it/s]loading adj matrices:  19%|█▉        | 141981/731288 [00:25<01:48, 5438.67it/s]loading adj matrices:  19%|█▉        | 142526/731288 [00:25<01:48, 5439.79it/s]loading adj matrices:  20%|█▉        | 143071/731288 [00:25<01:48, 5441.10it/s]loading adj matrices:  20%|█▉        | 143616/731288 [00:25<01:48, 5425.73it/s]loading adj matrices:  20%|█▉        | 144161/731288 [00:25<01:48, 5430.92it/s]loading adj matrices:  20%|█▉        | 144705/731288 [00:25<01:47, 5432.77it/s]loading adj matrices:  20%|█▉        | 145249/731288 [00:25<01:47, 5434.01it/s]loading adj matrices:  20%|█▉        | 145793/731288 [00:25<01:48, 5417.94it/s]loading adj matrices:  20%|██        | 146343/731288 [00:25<01:47, 5439.41it/s]loading adj matrices:  20%|██        | 146888/731288 [00:25<01:47, 5442.46it/s]loading adj matrices:  20%|██        | 147433/731288 [00:26<01:47, 5424.26it/s]loading adj matrices:  20%|██        | 147978/731288 [00:26<01:47, 5430.95it/s]loading adj matrices:  20%|██        | 148525/731288 [00:26<01:47, 5441.45it/s]loading adj matrices:  20%|██        | 149071/731288 [00:26<01:46, 5445.39it/s]loading adj matrices:  20%|██        | 149617/731288 [00:26<01:46, 5448.21it/s]loading adj matrices:  21%|██        | 150162/731288 [00:26<01:46, 5432.54it/s]loading adj matrices:  21%|██        | 150707/731288 [00:26<01:46, 5435.11it/s]loading adj matrices:  21%|██        | 151251/731288 [00:26<01:47, 5419.19it/s]loading adj matrices:  21%|██        | 151797/731288 [00:26<01:46, 5429.76it/s]loading adj matrices:  21%|██        | 152340/731288 [00:26<01:47, 5409.57it/s]loading adj matrices:  21%|██        | 152884/731288 [00:27<01:46, 5418.23it/s]loading adj matrices:  21%|██        | 153430/731288 [00:27<01:46, 5430.38it/s]loading adj matrices:  21%|██        | 153974/731288 [00:27<01:46, 5419.92it/s]loading adj matrices:  21%|██        | 154519/731288 [00:27<01:46, 5428.38it/s]loading adj matrices:  21%|██        | 155064/731288 [00:27<01:46, 5433.88it/s]loading adj matrices:  21%|██▏       | 155608/731288 [00:27<01:46, 5429.92it/s]loading adj matrices:  21%|██▏       | 156151/731288 [00:27<01:46, 5419.87it/s]loading adj matrices:  21%|██▏       | 156693/731288 [00:27<01:46, 5418.53it/s]loading adj matrices:  22%|██▏       | 157236/731288 [00:27<01:45, 5419.70it/s]loading adj matrices:  22%|██▏       | 157783/731288 [00:27<01:45, 5432.71it/s]loading adj matrices:  22%|██▏       | 158327/731288 [00:28<01:45, 5423.62it/s]loading adj matrices:  22%|██▏       | 158872/731288 [00:28<01:45, 5429.21it/s]loading adj matrices:  22%|██▏       | 159416/731288 [00:28<01:45, 5431.33it/s]loading adj matrices:  22%|██▏       | 159961/731288 [00:28<01:45, 5435.87it/s]loading adj matrices:  22%|██▏       | 160505/731288 [00:28<01:45, 5415.24it/s]loading adj matrices:  22%|██▏       | 161048/731288 [00:28<01:45, 5418.60it/s]loading adj matrices:  22%|██▏       | 161590/731288 [00:28<01:45, 5415.35it/s]loading adj matrices:  22%|██▏       | 162133/731288 [00:28<01:45, 5416.56it/s]loading adj matrices:  22%|██▏       | 162675/731288 [00:28<01:45, 5402.47it/s]loading adj matrices:  22%|██▏       | 163218/731288 [00:28<01:45, 5409.94it/s]loading adj matrices:  22%|██▏       | 163760/731288 [00:29<01:44, 5411.38it/s]loading adj matrices:  22%|██▏       | 164302/731288 [00:29<01:44, 5407.18it/s]loading adj matrices:  23%|██▎       | 164843/731288 [00:29<01:45, 5391.37it/s]loading adj matrices:  23%|██▎       | 165386/731288 [00:29<01:44, 5401.78it/s]loading adj matrices:  23%|██▎       | 165927/731288 [00:29<01:44, 5403.56it/s]loading adj matrices:  23%|██▎       | 166479/731288 [00:29<01:43, 5435.50it/s]loading adj matrices:  23%|██▎       | 167023/731288 [00:29<01:44, 5413.57it/s]loading adj matrices:  23%|██▎       | 167566/731288 [00:29<01:44, 5416.10it/s]loading adj matrices:  23%|██▎       | 168108/731288 [00:29<01:44, 5408.43it/s]loading adj matrices:  23%|██▎       | 168651/731288 [00:29<01:43, 5412.40it/s]loading adj matrices:  23%|██▎       | 169193/731288 [00:30<01:44, 5394.84it/s]loading adj matrices:  23%|██▎       | 169738/731288 [00:30<01:43, 5408.88it/s]loading adj matrices:  23%|██▎       | 170280/731288 [00:30<01:43, 5410.75it/s]loading adj matrices:  23%|██▎       | 170822/731288 [00:30<01:43, 5399.11it/s]loading adj matrices:  23%|██▎       | 171365/731288 [00:30<01:43, 5405.93it/s]loading adj matrices:  24%|██▎       | 171906/731288 [00:30<01:43, 5406.15it/s]loading adj matrices:  24%|██▎       | 172447/731288 [00:30<01:43, 5406.75it/s]loading adj matrices:  24%|██▎       | 172989/731288 [00:30<01:43, 5408.90it/s]loading adj matrices:  24%|██▎       | 173530/731288 [00:30<01:43, 5404.57it/s]loading adj matrices:  24%|██▍       | 174071/731288 [00:30<01:43, 5390.64it/s]loading adj matrices:  24%|██▍       | 174612/731288 [00:31<01:43, 5394.06it/s]loading adj matrices:  24%|██▍       | 175152/731288 [00:31<01:43, 5391.89it/s]loading adj matrices:  24%|██▍       | 175696/731288 [00:31<01:42, 5404.00it/s]loading adj matrices:  24%|██▍       | 176242/731288 [00:31<01:42, 5419.40it/s]loading adj matrices:  24%|██▍       | 176784/731288 [00:31<01:42, 5416.66it/s]loading adj matrices:  24%|██▍       | 177326/731288 [00:31<01:42, 5388.91it/s]loading adj matrices:  24%|██▍       | 177868/731288 [00:31<01:42, 5397.80it/s]loading adj matrices:  24%|██▍       | 178414/731288 [00:31<01:42, 5414.73it/s]loading adj matrices:  24%|██▍       | 178958/731288 [00:31<01:41, 5419.57it/s]loading adj matrices:  25%|██▍       | 179500/731288 [00:31<01:42, 5392.48it/s]loading adj matrices:  25%|██▍       | 180040/731288 [00:32<01:42, 5391.36it/s]loading adj matrices:  25%|██▍       | 180580/731288 [00:32<01:42, 5391.89it/s]loading adj matrices:  25%|██▍       | 181123/731288 [00:32<01:41, 5400.98it/s]loading adj matrices:  25%|██▍       | 181664/731288 [00:32<01:42, 5374.67it/s]loading adj matrices:  25%|██▍       | 182202/731288 [00:32<01:42, 5374.98it/s]loading adj matrices:  25%|██▍       | 182745/731288 [00:32<01:41, 5388.49it/s]loading adj matrices:  25%|██▌       | 183288/731288 [00:32<01:41, 5399.71it/s]loading adj matrices:  25%|██▌       | 183828/731288 [00:32<01:41, 5393.32it/s]loading adj matrices:  25%|██▌       | 184372/731288 [00:32<01:41, 5404.47it/s]loading adj matrices:  25%|██▌       | 184914/731288 [00:32<01:41, 5407.60it/s]loading adj matrices:  25%|██▌       | 185455/731288 [00:33<01:41, 5404.01it/s]loading adj matrices:  25%|██▌       | 185996/731288 [00:34<07:37, 1190.71it/s]loading adj matrices:  26%|██▌       | 186534/731288 [00:34<05:51, 1551.28it/s]loading adj matrices:  26%|██▌       | 187080/731288 [00:34<04:34, 1979.32it/s]loading adj matrices:  26%|██▌       | 187620/731288 [00:34<03:42, 2442.01it/s]loading adj matrices:  26%|██▌       | 188153/731288 [00:34<03:06, 2908.94it/s]loading adj matrices:  26%|██▌       | 188698/731288 [00:34<02:40, 3385.86it/s]loading adj matrices:  26%|██▌       | 189240/731288 [00:34<02:22, 3815.12it/s]loading adj matrices:  26%|██▌       | 189782/731288 [00:35<02:09, 4187.07it/s]loading adj matrices:  26%|██▌       | 190317/731288 [00:35<02:00, 4475.75it/s]loading adj matrices:  26%|██▌       | 190859/731288 [00:35<01:54, 4722.42it/s]loading adj matrices:  26%|██▌       | 191395/731288 [00:35<01:50, 4894.62it/s]loading adj matrices:  26%|██▌       | 191930/731288 [00:35<01:47, 5019.66it/s]loading adj matrices:  26%|██▋       | 192468/731288 [00:35<01:45, 5120.06it/s]loading adj matrices:  26%|██▋       | 193008/731288 [00:35<01:43, 5200.30it/s]loading adj matrices:  26%|██▋       | 193549/731288 [00:35<01:42, 5261.12it/s]loading adj matrices:  27%|██▋       | 194087/731288 [00:35<01:41, 5288.57it/s]loading adj matrices:  27%|██▋       | 194626/731288 [00:35<01:40, 5316.59it/s]loading adj matrices:  27%|██▋       | 195168/731288 [00:36<01:40, 5347.24it/s]loading adj matrices:  27%|██▋       | 195707/731288 [00:36<01:40, 5353.55it/s]loading adj matrices:  27%|██▋       | 196246/731288 [00:36<01:39, 5353.97it/s]loading adj matrices:  27%|██▋       | 196785/731288 [00:36<01:39, 5363.16it/s]loading adj matrices:  27%|██▋       | 197324/731288 [00:36<01:39, 5369.21it/s]loading adj matrices:  27%|██▋       | 197862/731288 [00:36<01:39, 5360.63it/s]loading adj matrices:  27%|██▋       | 198399/731288 [00:36<01:39, 5357.14it/s]loading adj matrices:  27%|██▋       | 198942/731288 [00:36<01:39, 5377.09it/s]loading adj matrices:  27%|██▋       | 199482/731288 [00:36<01:38, 5382.45it/s]loading adj matrices:  27%|██▋       | 200022/731288 [00:36<01:38, 5387.07it/s]loading adj matrices:  27%|██▋       | 200561/731288 [00:37<01:39, 5360.51it/s]loading adj matrices:  27%|██▋       | 201104/731288 [00:37<01:38, 5378.22it/s]loading adj matrices:  28%|██▊       | 201643/731288 [00:37<01:38, 5380.08it/s]loading adj matrices:  28%|██▊       | 202183/731288 [00:37<01:38, 5384.64it/s]loading adj matrices:  28%|██▊       | 202722/731288 [00:37<01:38, 5362.48it/s]loading adj matrices:  28%|██▊       | 203264/731288 [00:37<01:38, 5377.35it/s]loading adj matrices:  28%|██▊       | 203803/731288 [00:37<01:38, 5378.25it/s]loading adj matrices:  28%|██▊       | 204341/731288 [00:37<01:38, 5375.95it/s]loading adj matrices:  28%|██▊       | 204880/731288 [00:37<01:37, 5378.01it/s]loading adj matrices:  28%|██▊       | 205418/731288 [00:37<01:37, 5375.56it/s]loading adj matrices:  28%|██▊       | 205956/731288 [00:38<01:37, 5371.72it/s]loading adj matrices:  28%|██▊       | 206495/731288 [00:38<01:37, 5377.09it/s]loading adj matrices:  28%|██▊       | 207033/731288 [00:38<01:37, 5356.35it/s]loading adj matrices:  28%|██▊       | 207570/731288 [00:38<01:37, 5357.80it/s]loading adj matrices:  28%|██▊       | 208110/731288 [00:38<01:37, 5368.98it/s]loading adj matrices:  29%|██▊       | 208647/731288 [00:38<01:37, 5359.24it/s]loading adj matrices:  29%|██▊       | 209183/731288 [00:38<01:37, 5339.77it/s]loading adj matrices:  29%|██▊       | 209719/731288 [00:38<01:37, 5344.89it/s]loading adj matrices:  29%|██▉       | 210272/731288 [00:38<01:36, 5397.71it/s]loading adj matrices:  29%|██▉       | 210812/731288 [00:38<01:36, 5380.48it/s]loading adj matrices:  29%|██▉       | 211351/731288 [00:39<01:36, 5376.61it/s]loading adj matrices:  29%|██▉       | 211893/731288 [00:39<01:36, 5387.41it/s]loading adj matrices:  29%|██▉       | 212432/731288 [00:39<01:36, 5379.91it/s]loading adj matrices:  29%|██▉       | 212971/731288 [00:39<01:36, 5364.48it/s]loading adj matrices:  29%|██▉       | 213509/731288 [00:39<01:36, 5367.46it/s]loading adj matrices:  29%|██▉       | 214048/731288 [00:39<01:36, 5371.17it/s]loading adj matrices:  29%|██▉       | 214590/731288 [00:39<01:35, 5382.86it/s]loading adj matrices:  29%|██▉       | 215129/731288 [00:39<01:36, 5370.87it/s]loading adj matrices:  29%|██▉       | 215667/731288 [00:39<01:36, 5358.60it/s]loading adj matrices:  30%|██▉       | 216205/731288 [00:39<01:36, 5363.90it/s]loading adj matrices:  30%|██▉       | 216742/731288 [00:40<01:36, 5351.14it/s]loading adj matrices:  30%|██▉       | 217278/731288 [00:40<01:36, 5330.24it/s]loading adj matrices:  30%|██▉       | 217814/731288 [00:40<01:36, 5338.56it/s]loading adj matrices:  30%|██▉       | 218350/731288 [00:40<01:35, 5343.37it/s]loading adj matrices:  30%|██▉       | 218888/731288 [00:40<01:35, 5352.52it/s]loading adj matrices:  30%|███       | 219424/731288 [00:40<01:35, 5347.97it/s]loading adj matrices:  30%|███       | 219961/731288 [00:40<01:35, 5352.83it/s]loading adj matrices:  30%|███       | 220502/731288 [00:40<01:35, 5367.53it/s]loading adj matrices:  30%|███       | 221045/731288 [00:40<01:34, 5385.21it/s]loading adj matrices:  30%|███       | 221584/731288 [00:40<01:35, 5359.47it/s]loading adj matrices:  30%|███       | 222120/731288 [00:41<01:35, 5356.65it/s]loading adj matrices:  30%|███       | 222666/731288 [00:41<01:34, 5385.67it/s]loading adj matrices:  31%|███       | 223233/731288 [00:41<01:32, 5469.64it/s]loading adj matrices:  31%|███       | 223806/731288 [00:41<01:31, 5547.43it/s]loading adj matrices:  31%|███       | 224375/731288 [00:41<01:30, 5588.20it/s]loading adj matrices:  31%|███       | 224956/731288 [00:41<01:29, 5652.83it/s]loading adj matrices:  31%|███       | 225522/731288 [00:41<01:29, 5651.87it/s]loading adj matrices:  31%|███       | 226096/731288 [00:41<01:28, 5677.46it/s]loading adj matrices:  31%|███       | 226666/731288 [00:41<01:28, 5681.85it/s]loading adj matrices:  31%|███       | 227236/731288 [00:41<01:28, 5684.38it/s]loading adj matrices:  31%|███       | 227805/731288 [00:42<01:28, 5669.55it/s]loading adj matrices:  31%|███       | 228377/731288 [00:42<01:28, 5681.24it/s]loading adj matrices:  31%|███▏      | 228956/731288 [00:42<01:27, 5712.26it/s]loading adj matrices:  31%|███▏      | 229537/731288 [00:42<01:27, 5738.88it/s]loading adj matrices:  31%|███▏      | 230111/731288 [00:42<01:28, 5686.96it/s]loading adj matrices:  32%|███▏      | 230685/731288 [00:42<01:27, 5700.49it/s]loading adj matrices:  32%|███▏      | 231256/731288 [00:42<01:27, 5689.38it/s]loading adj matrices:  32%|███▏      | 231825/731288 [00:42<01:27, 5685.16it/s]loading adj matrices:  32%|███▏      | 232399/731288 [00:42<01:27, 5699.26it/s]loading adj matrices:  32%|███▏      | 232973/731288 [00:42<01:27, 5711.17it/s]loading adj matrices:  32%|███▏      | 233554/731288 [00:43<01:26, 5739.05it/s]loading adj matrices:  32%|███▏      | 234128/731288 [00:43<01:26, 5715.16it/s]loading adj matrices:  32%|███▏      | 234700/731288 [00:43<01:27, 5698.57it/s]loading adj matrices:  32%|███▏      | 235270/731288 [00:43<01:27, 5670.34it/s]loading adj matrices:  32%|███▏      | 235838/731288 [00:43<01:29, 5523.89it/s]loading adj matrices:  32%|███▏      | 236392/731288 [00:43<01:30, 5456.32it/s]loading adj matrices:  32%|███▏      | 236948/731288 [00:43<01:30, 5486.55it/s]loading adj matrices:  32%|███▏      | 237518/731288 [00:43<01:28, 5548.58it/s]loading adj matrices:  33%|███▎      | 238074/731288 [00:43<01:29, 5539.47it/s]loading adj matrices:  33%|███▎      | 238634/731288 [00:43<01:28, 5555.77it/s]loading adj matrices:  33%|███▎      | 239197/731288 [00:44<01:28, 5577.31it/s]loading adj matrices:  33%|███▎      | 239761/731288 [00:44<01:27, 5593.83it/s]loading adj matrices:  33%|███▎      | 240321/731288 [00:44<01:27, 5579.92it/s]loading adj matrices:  33%|███▎      | 240881/731288 [00:44<01:27, 5584.69it/s]loading adj matrices:  33%|███▎      | 241448/731288 [00:44<01:27, 5607.79it/s]loading adj matrices:  33%|███▎      | 242009/731288 [00:44<01:27, 5605.00it/s]loading adj matrices:  33%|███▎      | 242570/731288 [00:44<01:27, 5596.95it/s]loading adj matrices:  33%|███▎      | 243130/731288 [00:44<01:27, 5586.77it/s]loading adj matrices:  33%|███▎      | 243693/731288 [00:44<01:27, 5599.12it/s]loading adj matrices:  33%|███▎      | 244256/731288 [00:45<01:26, 5606.38it/s]loading adj matrices:  33%|███▎      | 244817/731288 [00:45<01:27, 5561.04it/s]loading adj matrices:  34%|███▎      | 245374/731288 [00:45<01:27, 5561.20it/s]loading adj matrices:  34%|███▎      | 245937/731288 [00:45<01:27, 5578.43it/s]loading adj matrices:  34%|███▎      | 246495/731288 [00:45<01:26, 5572.42it/s]loading adj matrices:  34%|███▍      | 247071/731288 [00:45<01:26, 5625.74it/s]loading adj matrices:  34%|███▍      | 247634/731288 [00:45<01:26, 5610.37it/s]loading adj matrices:  34%|███▍      | 248196/731288 [00:45<01:26, 5601.48it/s]loading adj matrices:  34%|███▍      | 248757/731288 [00:45<01:26, 5578.21it/s]loading adj matrices:  34%|███▍      | 249324/731288 [00:45<01:25, 5605.17it/s]loading adj matrices:  34%|███▍      | 249889/731288 [00:46<01:25, 5616.11it/s]loading adj matrices:  34%|███▍      | 250461/731288 [00:46<01:25, 5646.55it/s]loading adj matrices:  34%|███▍      | 251027/731288 [00:46<01:25, 5648.76it/s]loading adj matrices:  34%|███▍      | 251596/731288 [00:46<01:24, 5659.28it/s]loading adj matrices:  34%|███▍      | 252162/731288 [00:46<01:24, 5638.96it/s]loading adj matrices:  35%|███▍      | 252735/731288 [00:46<01:24, 5665.21it/s]loading adj matrices:  35%|███▍      | 253302/731288 [00:46<01:24, 5645.81it/s]loading adj matrices:  35%|███▍      | 253867/731288 [00:46<01:24, 5637.85it/s]loading adj matrices:  35%|███▍      | 254441/731288 [00:46<01:24, 5666.98it/s]loading adj matrices:  35%|███▍      | 255008/731288 [00:46<01:24, 5659.27it/s]loading adj matrices:  35%|███▍      | 255574/731288 [00:47<01:24, 5652.21it/s]loading adj matrices:  35%|███▌      | 256140/731288 [00:47<01:24, 5642.62it/s]loading adj matrices:  35%|███▌      | 256710/731288 [00:47<01:23, 5659.08it/s]loading adj matrices:  35%|███▌      | 257276/731288 [00:47<01:23, 5655.38it/s]loading adj matrices:  35%|███▌      | 257849/731288 [00:47<01:23, 5676.49it/s]loading adj matrices:  35%|███▌      | 258417/731288 [00:47<01:23, 5667.50it/s]loading adj matrices:  35%|███▌      | 258984/731288 [00:47<01:23, 5654.49it/s]loading adj matrices:  35%|███▌      | 259550/731288 [00:47<01:23, 5640.74it/s]loading adj matrices:  36%|███▌      | 260126/731288 [00:47<01:23, 5676.13it/s]loading adj matrices:  36%|███▌      | 260694/731288 [00:47<01:22, 5671.17it/s]loading adj matrices:  36%|███▌      | 261262/731288 [00:48<01:23, 5654.09it/s]loading adj matrices:  36%|███▌      | 261835/731288 [00:48<01:22, 5675.86it/s]loading adj matrices:  36%|███▌      | 262407/731288 [00:48<01:22, 5686.28it/s]loading adj matrices:  36%|███▌      | 262979/731288 [00:48<01:22, 5694.60it/s]loading adj matrices:  36%|███▌      | 263549/731288 [00:48<01:22, 5670.98it/s]loading adj matrices:  36%|███▌      | 264118/731288 [00:48<01:22, 5675.04it/s]loading adj matrices:  36%|███▌      | 264690/731288 [00:48<01:22, 5687.40it/s]loading adj matrices:  36%|███▋      | 265263/731288 [00:48<01:21, 5698.93it/s]loading adj matrices:  36%|███▋      | 265833/731288 [00:48<01:21, 5682.14it/s]loading adj matrices:  36%|███▋      | 266405/731288 [00:48<01:21, 5692.07it/s]loading adj matrices:  37%|███▋      | 266975/731288 [00:49<01:21, 5691.38it/s]loading adj matrices:  37%|███▋      | 267545/731288 [00:49<01:21, 5663.20it/s]loading adj matrices:  37%|███▋      | 268114/731288 [00:49<01:21, 5669.36it/s]loading adj matrices:  37%|███▋      | 268688/731288 [00:49<01:21, 5688.95it/s]loading adj matrices:  37%|███▋      | 269266/731288 [00:49<01:20, 5715.99it/s]loading adj matrices:  37%|███▋      | 269838/731288 [00:49<01:21, 5691.32it/s]loading adj matrices:  37%|███▋      | 270408/731288 [00:49<01:21, 5688.37it/s]loading adj matrices:  37%|███▋      | 270983/731288 [00:49<01:20, 5706.23it/s]loading adj matrices:  37%|███▋      | 271554/731288 [00:49<01:20, 5690.88it/s]loading adj matrices:  37%|███▋      | 272124/731288 [00:49<01:20, 5674.09it/s]loading adj matrices:  37%|███▋      | 272700/731288 [00:50<01:20, 5696.26it/s]loading adj matrices:  37%|███▋      | 273270/731288 [00:50<01:20, 5687.71it/s]loading adj matrices:  37%|███▋      | 273839/731288 [00:50<01:20, 5653.47it/s]loading adj matrices:  38%|███▊      | 274405/731288 [00:50<01:20, 5646.34it/s]loading adj matrices:  38%|███▊      | 274975/731288 [00:50<01:20, 5659.85it/s]loading adj matrices:  38%|███▊      | 275548/731288 [00:50<01:20, 5678.07it/s]loading adj matrices:  38%|███▊      | 276116/731288 [00:50<01:20, 5667.37it/s]loading adj matrices:  38%|███▊      | 276688/731288 [00:50<01:20, 5680.51it/s]loading adj matrices:  38%|███▊      | 277266/731288 [00:50<01:19, 5708.95it/s]loading adj matrices:  38%|███▊      | 277837/731288 [00:50<01:19, 5701.39it/s]loading adj matrices:  38%|███▊      | 278408/731288 [00:51<01:19, 5694.71it/s]loading adj matrices:  38%|███▊      | 278978/731288 [00:51<01:19, 5690.35it/s]loading adj matrices:  38%|███▊      | 279549/731288 [00:51<01:19, 5692.78it/s]loading adj matrices:  38%|███▊      | 280125/731288 [00:51<01:19, 5710.64it/s]loading adj matrices:  38%|███▊      | 280698/731288 [00:51<01:18, 5714.38it/s]loading adj matrices:  38%|███▊      | 281271/731288 [00:51<01:18, 5717.15it/s]loading adj matrices:  39%|███▊      | 281843/731288 [00:51<01:18, 5704.85it/s]loading adj matrices:  39%|███▊      | 282414/731288 [00:51<01:19, 5676.46it/s]loading adj matrices:  39%|███▊      | 282988/731288 [00:51<01:18, 5694.69it/s]loading adj matrices:  39%|███▉      | 283558/731288 [00:51<01:19, 5657.99it/s]loading adj matrices:  39%|███▉      | 284124/731288 [00:52<01:19, 5642.48it/s]loading adj matrices:  39%|███▉      | 284689/731288 [00:52<01:19, 5633.69it/s]loading adj matrices:  39%|███▉      | 285258/731288 [00:52<01:18, 5648.60it/s]loading adj matrices:  39%|███▉      | 285829/731288 [00:52<01:18, 5664.97it/s]loading adj matrices:  39%|███▉      | 286396/731288 [00:52<01:18, 5649.82it/s]loading adj matrices:  39%|███▉      | 286964/731288 [00:52<01:18, 5658.29it/s]loading adj matrices:  39%|███▉      | 287542/731288 [00:52<01:17, 5693.62it/s]loading adj matrices:  39%|███▉      | 288113/731288 [00:52<01:17, 5698.12it/s]loading adj matrices:  39%|███▉      | 288683/731288 [00:52<01:18, 5660.71it/s]loading adj matrices:  40%|███▉      | 289261/731288 [00:52<01:17, 5694.37it/s]loading adj matrices:  40%|███▉      | 289836/731288 [00:53<01:17, 5709.71it/s]loading adj matrices:  40%|███▉      | 290408/731288 [00:53<01:17, 5709.40it/s]loading adj matrices:  40%|███▉      | 290979/731288 [00:53<01:17, 5687.93it/s]loading adj matrices:  40%|███▉      | 291551/731288 [00:53<01:17, 5696.41it/s]loading adj matrices:  40%|███▉      | 292123/731288 [00:53<01:17, 5701.90it/s]loading adj matrices:  40%|████      | 292694/731288 [00:53<01:17, 5691.70it/s]loading adj matrices:  40%|████      | 293272/731288 [00:53<01:16, 5716.62it/s]loading adj matrices:  40%|████      | 293844/731288 [00:53<01:16, 5704.43it/s]loading adj matrices:  40%|████      | 294415/731288 [00:53<01:16, 5702.57it/s]loading adj matrices:  40%|████      | 294986/731288 [00:53<01:17, 5650.66it/s]loading adj matrices:  40%|████      | 295559/731288 [00:54<01:16, 5671.86it/s]loading adj matrices:  40%|████      | 296127/731288 [00:54<01:16, 5672.36it/s]loading adj matrices:  41%|████      | 296697/731288 [00:54<01:16, 5679.50it/s]loading adj matrices:  41%|████      | 297269/731288 [00:54<01:16, 5689.88it/s]loading adj matrices:  41%|████      | 297839/731288 [00:54<01:16, 5681.84it/s]loading adj matrices:  41%|████      | 298408/731288 [00:54<01:16, 5681.56it/s]loading adj matrices:  41%|████      | 298977/731288 [00:54<01:16, 5665.49it/s]loading adj matrices:  41%|████      | 299544/731288 [00:54<01:16, 5659.56it/s]loading adj matrices:  41%|████      | 300110/731288 [00:54<01:16, 5636.89it/s]loading adj matrices:  41%|████      | 300674/731288 [00:54<01:16, 5618.36it/s]loading adj matrices:  41%|████      | 301238/731288 [00:55<01:16, 5623.80it/s]loading adj matrices:  41%|████▏     | 301801/731288 [00:55<01:16, 5604.84it/s]loading adj matrices:  41%|████▏     | 302370/731288 [00:55<01:16, 5630.05it/s]loading adj matrices:  41%|████▏     | 302938/731288 [00:55<01:15, 5644.75it/s]loading adj matrices:  42%|████▏     | 303503/731288 [00:55<01:16, 5621.61it/s]loading adj matrices:  42%|████▏     | 304066/731288 [00:55<01:16, 5605.66it/s]loading adj matrices:  42%|████▏     | 304627/731288 [00:55<01:16, 5601.22it/s]loading adj matrices:  42%|████▏     | 305191/731288 [00:55<01:15, 5612.72it/s]loading adj matrices:  42%|████▏     | 305753/731288 [00:55<01:16, 5589.04it/s]loading adj matrices:  42%|████▏     | 306312/731288 [00:55<01:16, 5570.64it/s]loading adj matrices:  42%|████▏     | 306874/731288 [00:56<01:16, 5582.98it/s]loading adj matrices:  42%|████▏     | 307433/731288 [00:56<01:15, 5584.60it/s]loading adj matrices:  42%|████▏     | 307997/731288 [00:56<01:15, 5600.40it/s]loading adj matrices:  42%|████▏     | 308558/731288 [00:56<01:15, 5577.17it/s]loading adj matrices:  42%|████▏     | 309116/731288 [00:56<01:15, 5564.31it/s]loading adj matrices:  42%|████▏     | 309685/731288 [00:56<01:15, 5599.68it/s]loading adj matrices:  42%|████▏     | 310259/731288 [00:56<01:14, 5639.17it/s]loading adj matrices:  43%|████▎     | 310828/731288 [00:56<01:14, 5652.52it/s]loading adj matrices:  43%|████▎     | 311398/731288 [00:56<01:14, 5666.29it/s]loading adj matrices:  43%|████▎     | 311966/731288 [00:56<01:13, 5669.10it/s]loading adj matrices:  43%|████▎     | 312535/731288 [00:57<01:13, 5672.96it/s]loading adj matrices:  43%|████▎     | 313111/731288 [00:57<01:13, 5695.66it/s]loading adj matrices:  43%|████▎     | 313681/731288 [00:57<01:13, 5664.70it/s]loading adj matrices:  43%|████▎     | 314255/731288 [00:57<01:13, 5686.16it/s]loading adj matrices:  43%|████▎     | 314834/731288 [00:57<01:12, 5715.70it/s]loading adj matrices:  43%|████▎     | 315406/731288 [00:57<01:12, 5701.69it/s]loading adj matrices:  43%|████▎     | 315977/731288 [00:57<01:12, 5697.94it/s]loading adj matrices:  43%|████▎     | 316554/731288 [00:57<01:12, 5718.09it/s]loading adj matrices:  43%|████▎     | 317126/731288 [00:57<01:12, 5709.30it/s]loading adj matrices:  43%|████▎     | 317697/731288 [00:57<01:12, 5687.20it/s]loading adj matrices:  44%|████▎     | 318266/731288 [00:58<01:12, 5676.99it/s]loading adj matrices:  44%|████▎     | 318844/731288 [00:58<01:12, 5706.34it/s]loading adj matrices:  44%|████▎     | 319415/731288 [00:58<01:12, 5684.28it/s]loading adj matrices:  44%|████▍     | 319984/731288 [00:58<01:12, 5655.48it/s]loading adj matrices:  44%|████▍     | 320562/731288 [00:58<01:12, 5690.27it/s]loading adj matrices:  44%|████▍     | 321133/731288 [00:58<01:12, 5696.03it/s]loading adj matrices:  44%|████▍     | 321710/731288 [00:58<01:11, 5716.57it/s]loading adj matrices:  44%|████▍     | 322282/731288 [00:58<01:11, 5692.06it/s]loading adj matrices:  44%|████▍     | 322852/731288 [00:58<01:11, 5684.74it/s]loading adj matrices:  44%|████▍     | 323428/731288 [00:58<01:11, 5705.41it/s]loading adj matrices:  44%|████▍     | 323999/731288 [00:59<01:11, 5684.51it/s]loading adj matrices:  44%|████▍     | 324568/731288 [00:59<01:11, 5665.92it/s]loading adj matrices:  44%|████▍     | 325142/731288 [00:59<01:11, 5685.85it/s]loading adj matrices:  45%|████▍     | 325713/731288 [00:59<01:11, 5690.41it/s]loading adj matrices:  45%|████▍     | 326283/731288 [00:59<01:11, 5679.26it/s]loading adj matrices:  45%|████▍     | 326853/731288 [00:59<01:11, 5684.53it/s]loading adj matrices:  45%|████▍     | 327425/731288 [00:59<01:10, 5694.30it/s]loading adj matrices:  45%|████▍     | 328000/731288 [00:59<01:10, 5710.09it/s]loading adj matrices:  45%|████▍     | 328572/731288 [01:01<05:49, 1152.79it/s]loading adj matrices:  45%|████▌     | 329136/731288 [01:01<04:26, 1509.35it/s]loading adj matrices:  45%|████▌     | 329706/731288 [01:01<03:27, 1936.55it/s]loading adj matrices:  45%|████▌     | 330284/731288 [01:01<02:45, 2425.12it/s]loading adj matrices:  45%|████▌     | 330844/731288 [01:01<02:17, 2912.58it/s]loading adj matrices:  45%|████▌     | 331414/731288 [01:01<01:57, 3413.89it/s]loading adj matrices:  45%|████▌     | 331978/731288 [01:01<01:43, 3868.47it/s]loading adj matrices:  45%|████▌     | 332552/731288 [01:01<01:32, 4291.03it/s]loading adj matrices:  46%|████▌     | 333116/731288 [01:02<01:26, 4619.06it/s]loading adj matrices:  46%|████▌     | 333684/731288 [01:02<01:21, 4891.80it/s]loading adj matrices:  46%|████▌     | 334252/731288 [01:02<01:17, 5102.90it/s]loading adj matrices:  46%|████▌     | 334815/731288 [01:02<01:15, 5241.85it/s]loading adj matrices:  46%|████▌     | 335395/731288 [01:02<01:13, 5399.00it/s]loading adj matrices:  46%|████▌     | 335963/731288 [01:02<01:12, 5463.42it/s]loading adj matrices:  46%|████▌     | 336530/731288 [01:02<01:11, 5522.27it/s]loading adj matrices:  46%|████▌     | 337101/731288 [01:02<01:10, 5577.01it/s]loading adj matrices:  46%|████▌     | 337673/731288 [01:02<01:10, 5617.49it/s]loading adj matrices:  46%|████▋     | 338242/731288 [01:02<01:09, 5638.44it/s]loading adj matrices:  46%|████▋     | 338819/731288 [01:03<01:09, 5674.85it/s]loading adj matrices:  46%|████▋     | 339390/731288 [01:03<01:09, 5655.56it/s]loading adj matrices:  46%|████▋     | 339958/731288 [01:03<01:09, 5654.94it/s]loading adj matrices:  47%|████▋     | 340531/731288 [01:03<01:08, 5675.13it/s]loading adj matrices:  47%|████▋     | 341100/731288 [01:03<01:09, 5651.20it/s]loading adj matrices:  47%|████▋     | 341666/731288 [01:03<01:09, 5642.92it/s]loading adj matrices:  47%|████▋     | 342248/731288 [01:03<01:08, 5693.86it/s]loading adj matrices:  47%|████▋     | 342822/731288 [01:03<01:08, 5706.81it/s]loading adj matrices:  47%|████▋     | 343393/731288 [01:03<01:08, 5701.26it/s]loading adj matrices:  47%|████▋     | 343964/731288 [01:03<01:07, 5703.32it/s]loading adj matrices:  47%|████▋     | 344535/731288 [01:04<01:08, 5673.36it/s]loading adj matrices:  47%|████▋     | 345103/731288 [01:04<01:08, 5666.46it/s]loading adj matrices:  47%|████▋     | 345670/731288 [01:04<01:08, 5640.94it/s]loading adj matrices:  47%|████▋     | 346247/731288 [01:04<01:07, 5678.03it/s]loading adj matrices:  47%|████▋     | 346815/731288 [01:04<01:08, 5645.65it/s]loading adj matrices:  48%|████▊     | 347388/731288 [01:04<01:07, 5669.94it/s]loading adj matrices:  48%|████▊     | 347956/731288 [01:04<01:07, 5661.75it/s]loading adj matrices:  48%|████▊     | 348528/731288 [01:04<01:07, 5677.34it/s]loading adj matrices:  48%|████▊     | 349109/731288 [01:04<01:06, 5715.96it/s]loading adj matrices:  48%|████▊     | 349681/731288 [01:04<01:07, 5673.86it/s]loading adj matrices:  48%|████▊     | 350256/731288 [01:05<01:06, 5693.59it/s]loading adj matrices:  48%|████▊     | 350832/731288 [01:05<01:06, 5712.24it/s]loading adj matrices:  48%|████▊     | 351404/731288 [01:05<01:06, 5683.34it/s]loading adj matrices:  48%|████▊     | 351973/731288 [01:05<01:06, 5680.44it/s]loading adj matrices:  48%|████▊     | 352542/731288 [01:05<01:06, 5668.44it/s]loading adj matrices:  48%|████▊     | 353110/731288 [01:05<01:06, 5670.95it/s]loading adj matrices:  48%|████▊     | 353678/731288 [01:05<01:06, 5645.49it/s]loading adj matrices:  48%|████▊     | 354257/731288 [01:05<01:06, 5686.61it/s]loading adj matrices:  49%|████▊     | 354831/731288 [01:05<01:06, 5701.01it/s]loading adj matrices:  49%|████▊     | 355402/731288 [01:05<01:05, 5697.11it/s]loading adj matrices:  49%|████▊     | 355972/731288 [01:06<01:06, 5674.07it/s]loading adj matrices:  49%|████▉     | 356541/731288 [01:06<01:06, 5677.09it/s]loading adj matrices:  49%|████▉     | 357111/731288 [01:06<01:05, 5682.18it/s]loading adj matrices:  49%|████▉     | 357684/731288 [01:06<01:05, 5696.33it/s]loading adj matrices:  49%|████▉     | 358254/731288 [01:06<01:05, 5669.18it/s]loading adj matrices:  49%|████▉     | 358832/731288 [01:06<01:05, 5701.09it/s]loading adj matrices:  49%|████▉     | 359403/731288 [01:06<01:05, 5660.73it/s]loading adj matrices:  49%|████▉     | 359970/731288 [01:06<01:05, 5647.91it/s]loading adj matrices:  49%|████▉     | 360538/731288 [01:06<01:05, 5655.87it/s]loading adj matrices:  49%|████▉     | 361108/731288 [01:06<01:05, 5667.78it/s]loading adj matrices:  49%|████▉     | 361681/731288 [01:07<01:05, 5684.28it/s]loading adj matrices:  50%|████▉     | 362250/731288 [01:07<01:05, 5662.06it/s]loading adj matrices:  50%|████▉     | 362817/731288 [01:07<01:05, 5662.77it/s]loading adj matrices:  50%|████▉     | 363403/731288 [01:07<01:04, 5720.35it/s]loading adj matrices:  50%|████▉     | 363976/731288 [01:07<01:04, 5693.51it/s]loading adj matrices:  50%|████▉     | 364546/731288 [01:07<01:04, 5682.33it/s]loading adj matrices:  50%|████▉     | 365121/731288 [01:07<01:04, 5702.29it/s]loading adj matrices:  50%|█████     | 365693/731288 [01:07<01:04, 5704.21it/s]loading adj matrices:  50%|█████     | 366264/731288 [01:07<01:04, 5700.61it/s]loading adj matrices:  50%|█████     | 366841/731288 [01:07<01:03, 5718.90it/s]loading adj matrices:  50%|█████     | 367413/731288 [01:08<01:03, 5712.88it/s]loading adj matrices:  50%|█████     | 367985/731288 [01:08<01:03, 5696.31it/s]loading adj matrices:  50%|█████     | 368556/731288 [01:08<01:03, 5699.64it/s]loading adj matrices:  50%|█████     | 369126/731288 [01:08<01:03, 5696.73it/s]loading adj matrices:  51%|█████     | 369698/731288 [01:08<01:03, 5702.34it/s]loading adj matrices:  51%|█████     | 370269/731288 [01:08<01:03, 5672.06it/s]loading adj matrices:  51%|█████     | 370837/731288 [01:08<01:03, 5650.01it/s]loading adj matrices:  51%|█████     | 371405/731288 [01:08<01:03, 5658.53it/s]loading adj matrices:  51%|█████     | 371980/731288 [01:08<01:03, 5682.84it/s]loading adj matrices:  51%|█████     | 372549/731288 [01:08<01:03, 5669.92it/s]loading adj matrices:  51%|█████     | 373117/731288 [01:09<01:03, 5661.42it/s]loading adj matrices:  51%|█████     | 373691/731288 [01:09<01:02, 5684.00it/s]loading adj matrices:  51%|█████     | 374262/731288 [01:09<01:02, 5690.16it/s]loading adj matrices:  51%|█████▏    | 374833/731288 [01:09<01:02, 5692.93it/s]loading adj matrices:  51%|█████▏    | 375403/731288 [01:09<01:02, 5689.36it/s]loading adj matrices:  51%|█████▏    | 375972/731288 [01:09<01:02, 5666.05it/s]loading adj matrices:  51%|█████▏    | 376548/731288 [01:09<01:02, 5692.76it/s]loading adj matrices:  52%|█████▏    | 377118/731288 [01:09<01:02, 5660.47it/s]loading adj matrices:  52%|█████▏    | 377690/731288 [01:09<01:02, 5676.08it/s]loading adj matrices:  52%|█████▏    | 378258/731288 [01:09<01:02, 5676.04it/s]loading adj matrices:  52%|█████▏    | 378834/731288 [01:10<01:01, 5698.78it/s]loading adj matrices:  52%|█████▏    | 379404/731288 [01:10<01:01, 5684.36it/s]loading adj matrices:  52%|█████▏    | 379973/731288 [01:10<01:01, 5667.90it/s]loading adj matrices:  52%|█████▏    | 380543/731288 [01:10<01:01, 5677.34it/s]loading adj matrices:  52%|█████▏    | 381111/731288 [01:10<01:01, 5655.03it/s]loading adj matrices:  52%|█████▏    | 381678/731288 [01:10<01:01, 5658.82it/s]loading adj matrices:  52%|█████▏    | 382248/731288 [01:10<01:01, 5669.05it/s]loading adj matrices:  52%|█████▏    | 382821/731288 [01:10<01:01, 5685.52it/s]loading adj matrices:  52%|█████▏    | 383390/731288 [01:10<01:01, 5677.14it/s]loading adj matrices:  53%|█████▎    | 383972/731288 [01:10<01:00, 5716.56it/s]loading adj matrices:  53%|█████▎    | 384544/731288 [01:11<01:01, 5675.23it/s]loading adj matrices:  53%|█████▎    | 385118/731288 [01:11<01:00, 5693.92it/s]loading adj matrices:  53%|█████▎    | 385688/731288 [01:11<01:00, 5675.65it/s]loading adj matrices:  53%|█████▎    | 386260/731288 [01:11<01:00, 5685.62it/s]loading adj matrices:  53%|█████▎    | 386829/731288 [01:11<01:00, 5680.89it/s]loading adj matrices:  53%|█████▎    | 387398/731288 [01:11<01:00, 5679.58it/s]loading adj matrices:  53%|█████▎    | 387970/731288 [01:11<01:00, 5689.18it/s]loading adj matrices:  53%|█████▎    | 388539/731288 [01:11<01:00, 5669.09it/s]loading adj matrices:  53%|█████▎    | 389112/731288 [01:11<01:00, 5685.59it/s]loading adj matrices:  53%|█████▎    | 389681/731288 [01:11<01:00, 5674.12it/s]loading adj matrices:  53%|█████▎    | 390249/731288 [01:12<01:00, 5671.71it/s]loading adj matrices:  53%|█████▎    | 390817/731288 [01:12<01:00, 5665.28it/s]loading adj matrices:  54%|█████▎    | 391384/731288 [01:12<00:59, 5665.57it/s]loading adj matrices:  54%|█████▎    | 391968/731288 [01:12<00:59, 5715.56it/s]loading adj matrices:  54%|█████▎    | 392540/731288 [01:12<00:59, 5698.87it/s]loading adj matrices:  54%|█████▍    | 393112/731288 [01:12<00:59, 5703.82it/s]loading adj matrices:  54%|█████▍    | 393683/731288 [01:12<00:59, 5689.02it/s]loading adj matrices:  54%|█████▍    | 394252/731288 [01:12<00:59, 5679.51it/s]loading adj matrices:  54%|█████▍    | 394820/731288 [01:12<00:59, 5672.57it/s]loading adj matrices:  54%|█████▍    | 395391/731288 [01:12<00:59, 5683.42it/s]loading adj matrices:  54%|█████▍    | 395960/731288 [01:13<00:59, 5662.94it/s]loading adj matrices:  54%|█████▍    | 396534/731288 [01:13<00:58, 5683.47it/s]loading adj matrices:  54%|█████▍    | 397103/731288 [01:13<00:58, 5674.56it/s]loading adj matrices:  54%|█████▍    | 397677/731288 [01:13<00:58, 5691.31it/s]loading adj matrices:  54%|█████▍    | 398247/731288 [01:13<00:58, 5667.01it/s]loading adj matrices:  55%|█████▍    | 398817/731288 [01:13<00:58, 5674.58it/s]loading adj matrices:  55%|█████▍    | 399387/731288 [01:13<00:58, 5680.59it/s]loading adj matrices:  55%|█████▍    | 399959/731288 [01:13<00:58, 5689.94it/s]loading adj matrices:  55%|█████▍    | 400529/731288 [01:13<00:58, 5691.54it/s]loading adj matrices:  55%|█████▍    | 401099/731288 [01:13<00:58, 5669.81it/s]loading adj matrices:  55%|█████▍    | 401669/731288 [01:14<00:58, 5677.96it/s]loading adj matrices:  55%|█████▌    | 402241/731288 [01:14<00:57, 5689.91it/s]loading adj matrices:  55%|█████▌    | 402819/731288 [01:14<00:57, 5715.95it/s]loading adj matrices:  55%|█████▌    | 403393/731288 [01:14<00:57, 5722.80it/s]loading adj matrices:  55%|█████▌    | 403966/731288 [01:14<00:57, 5724.46it/s]loading adj matrices:  55%|█████▌    | 404539/731288 [01:14<00:57, 5687.39it/s]loading adj matrices:  55%|█████▌    | 405108/731288 [01:14<00:57, 5669.39it/s]loading adj matrices:  55%|█████▌    | 405687/731288 [01:14<00:57, 5704.36it/s]loading adj matrices:  56%|█████▌    | 406258/731288 [01:14<00:57, 5684.74it/s]loading adj matrices:  56%|█████▌    | 406831/731288 [01:14<00:56, 5696.73it/s]loading adj matrices:  56%|█████▌    | 407401/731288 [01:15<00:56, 5694.75it/s]loading adj matrices:  56%|█████▌    | 407971/731288 [01:15<00:56, 5673.82it/s]loading adj matrices:  56%|█████▌    | 408543/731288 [01:15<00:56, 5685.57it/s]loading adj matrices:  56%|█████▌    | 409117/731288 [01:15<00:56, 5699.85it/s]loading adj matrices:  56%|█████▌    | 409692/731288 [01:15<00:56, 5713.96it/s]loading adj matrices:  56%|█████▌    | 410264/731288 [01:15<00:56, 5708.51it/s]loading adj matrices:  56%|█████▌    | 410835/731288 [01:15<00:56, 5672.12it/s]loading adj matrices:  56%|█████▋    | 411403/731288 [01:15<00:56, 5669.06it/s]loading adj matrices:  56%|█████▋    | 411980/731288 [01:15<00:56, 5697.45it/s]loading adj matrices:  56%|█████▋    | 412550/731288 [01:15<00:56, 5673.73it/s]loading adj matrices:  56%|█████▋    | 413118/731288 [01:16<00:56, 5662.92it/s]loading adj matrices:  57%|█████▋    | 413689/731288 [01:16<00:55, 5676.28it/s]loading adj matrices:  57%|█████▋    | 414262/731288 [01:16<00:55, 5690.03it/s]loading adj matrices:  57%|█████▋    | 414832/731288 [01:16<00:55, 5692.20it/s]loading adj matrices:  57%|█████▋    | 415402/731288 [01:16<00:55, 5691.11it/s]loading adj matrices:  57%|█████▋    | 415972/731288 [01:16<00:55, 5687.15it/s]loading adj matrices:  57%|█████▋    | 416542/731288 [01:16<00:55, 5688.82it/s]loading adj matrices:  57%|█████▋    | 417112/731288 [01:16<00:55, 5690.57it/s]loading adj matrices:  57%|█████▋    | 417682/731288 [01:16<00:55, 5680.92it/s]loading adj matrices:  57%|█████▋    | 418251/731288 [01:16<00:55, 5681.66it/s]loading adj matrices:  57%|█████▋    | 418823/731288 [01:17<00:54, 5691.52it/s]loading adj matrices:  57%|█████▋    | 419400/731288 [01:17<00:54, 5712.79it/s]loading adj matrices:  57%|█████▋    | 419976/731288 [01:17<00:54, 5724.83it/s]loading adj matrices:  58%|█████▊    | 420549/731288 [01:17<00:54, 5694.00it/s]loading adj matrices:  58%|█████▊    | 421119/731288 [01:17<00:54, 5687.10it/s]loading adj matrices:  58%|█████▊    | 421691/731288 [01:17<00:54, 5693.80it/s]loading adj matrices:  58%|█████▊    | 422261/731288 [01:17<00:54, 5693.17it/s]loading adj matrices:  58%|█████▊    | 422831/731288 [01:17<00:54, 5682.51it/s]loading adj matrices:  58%|█████▊    | 423400/731288 [01:17<00:54, 5666.04it/s]loading adj matrices:  58%|█████▊    | 423969/731288 [01:17<00:54, 5671.12it/s]loading adj matrices:  58%|█████▊    | 424537/731288 [01:18<00:54, 5664.82it/s]loading adj matrices:  58%|█████▊    | 425104/731288 [01:18<00:54, 5661.91it/s]loading adj matrices:  58%|█████▊    | 425675/731288 [01:18<00:53, 5673.72it/s]loading adj matrices:  58%|█████▊    | 426243/731288 [01:18<00:53, 5672.25it/s]loading adj matrices:  58%|█████▊    | 426811/731288 [01:18<00:53, 5667.04it/s]loading adj matrices:  58%|█████▊    | 427379/731288 [01:18<00:53, 5667.64it/s]loading adj matrices:  59%|█████▊    | 427950/731288 [01:18<00:53, 5677.87it/s]loading adj matrices:  59%|█████▊    | 428520/731288 [01:18<00:53, 5682.17it/s]loading adj matrices:  59%|█████▊    | 429089/731288 [01:18<00:53, 5669.28it/s]loading adj matrices:  59%|█████▉    | 429656/731288 [01:18<00:53, 5655.50it/s]loading adj matrices:  59%|█████▉    | 430222/731288 [01:19<00:53, 5654.19it/s]loading adj matrices:  59%|█████▉    | 430788/731288 [01:19<00:53, 5652.73it/s]loading adj matrices:  59%|█████▉    | 431354/731288 [01:19<00:53, 5651.95it/s]loading adj matrices:  59%|█████▉    | 431940/731288 [01:19<00:52, 5711.69it/s]loading adj matrices:  59%|█████▉    | 432512/731288 [01:19<00:52, 5698.99it/s]loading adj matrices:  59%|█████▉    | 433085/731288 [01:19<00:52, 5706.46it/s]loading adj matrices:  59%|█████▉    | 433656/731288 [01:19<00:52, 5678.43it/s]loading adj matrices:  59%|█████▉    | 434224/731288 [01:19<00:52, 5664.71it/s]loading adj matrices:  59%|█████▉    | 434794/731288 [01:19<00:52, 5672.41it/s]loading adj matrices:  60%|█████▉    | 435363/731288 [01:19<00:52, 5674.58it/s]loading adj matrices:  60%|█████▉    | 435932/731288 [01:20<00:52, 5676.26it/s]loading adj matrices:  60%|█████▉    | 436500/731288 [01:20<00:52, 5666.81it/s]loading adj matrices:  60%|█████▉    | 437067/731288 [01:20<00:51, 5663.68it/s]loading adj matrices:  60%|█████▉    | 437641/731288 [01:20<00:51, 5686.15it/s]loading adj matrices:  60%|█████▉    | 438210/731288 [01:20<00:51, 5675.32it/s]loading adj matrices:  60%|██████    | 438778/731288 [01:20<00:51, 5667.76it/s]loading adj matrices:  60%|██████    | 439351/731288 [01:20<00:51, 5683.23it/s]loading adj matrices:  60%|██████    | 439920/731288 [01:20<00:51, 5668.41it/s]loading adj matrices:  60%|██████    | 440487/731288 [01:20<00:51, 5664.88it/s]loading adj matrices:  60%|██████    | 441054/731288 [01:21<00:51, 5664.48it/s]loading adj matrices:  60%|██████    | 441621/731288 [01:21<00:51, 5647.59it/s]loading adj matrices:  60%|██████    | 442186/731288 [01:21<00:51, 5628.06it/s]loading adj matrices:  61%|██████    | 442754/731288 [01:21<00:51, 5642.26it/s]loading adj matrices:  61%|██████    | 443330/731288 [01:21<00:50, 5675.71it/s]loading adj matrices:  61%|██████    | 443898/731288 [01:21<00:50, 5667.66it/s]loading adj matrices:  61%|██████    | 444465/731288 [01:21<00:50, 5656.27it/s]loading adj matrices:  61%|██████    | 445046/731288 [01:21<00:50, 5699.38it/s]loading adj matrices:  61%|██████    | 445616/731288 [01:21<00:50, 5687.63it/s]loading adj matrices:  61%|██████    | 446185/731288 [01:21<00:50, 5676.56it/s]loading adj matrices:  61%|██████    | 446753/731288 [01:22<00:50, 5650.60it/s]loading adj matrices:  61%|██████    | 447319/731288 [01:22<00:50, 5650.45it/s]loading adj matrices:  61%|██████    | 447891/731288 [01:22<00:49, 5669.23it/s]loading adj matrices:  61%|██████▏   | 448469/731288 [01:22<00:49, 5700.28it/s]loading adj matrices:  61%|██████▏   | 449040/731288 [01:22<00:49, 5691.26it/s]loading adj matrices:  61%|██████▏   | 449614/731288 [01:22<00:49, 5703.57it/s]loading adj matrices:  62%|██████▏   | 450185/731288 [01:22<00:49, 5704.48it/s]loading adj matrices:  62%|██████▏   | 450756/731288 [01:22<00:49, 5681.09it/s]loading adj matrices:  62%|██████▏   | 451328/731288 [01:22<00:49, 5690.54it/s]loading adj matrices:  62%|██████▏   | 451898/731288 [01:22<00:49, 5680.43it/s]loading adj matrices:  62%|██████▏   | 452468/731288 [01:23<00:49, 5685.88it/s]loading adj matrices:  62%|██████▏   | 453037/731288 [01:23<00:49, 5660.10it/s]loading adj matrices:  62%|██████▏   | 453605/731288 [01:23<00:49, 5665.70it/s]loading adj matrices:  62%|██████▏   | 454173/731288 [01:23<00:48, 5669.39it/s]loading adj matrices:  62%|██████▏   | 454740/731288 [01:23<00:48, 5652.39it/s]loading adj matrices:  62%|██████▏   | 455310/731288 [01:23<00:48, 5665.96it/s]loading adj matrices:  62%|██████▏   | 455890/731288 [01:23<00:48, 5703.83it/s]loading adj matrices:  62%|██████▏   | 456461/731288 [01:23<00:48, 5669.24it/s]loading adj matrices:  62%|██████▏   | 457031/731288 [01:23<00:48, 5676.36it/s]loading adj matrices:  63%|██████▎   | 457602/731288 [01:23<00:48, 5683.75it/s]loading adj matrices:  63%|██████▎   | 458175/731288 [01:24<00:47, 5694.38it/s]loading adj matrices:  63%|██████▎   | 458745/731288 [01:24<00:48, 5669.92it/s]loading adj matrices:  63%|██████▎   | 459314/731288 [01:24<00:47, 5675.48it/s]loading adj matrices:  63%|██████▎   | 459882/731288 [01:24<00:47, 5671.68it/s]loading adj matrices:  63%|██████▎   | 460457/731288 [01:24<00:47, 5694.10it/s]loading adj matrices:  63%|██████▎   | 461031/731288 [01:24<00:47, 5706.40it/s]loading adj matrices:  63%|██████▎   | 461602/731288 [01:24<00:47, 5700.53it/s]loading adj matrices:  63%|██████▎   | 462174/731288 [01:24<00:47, 5705.54it/s]loading adj matrices:  63%|██████▎   | 462745/731288 [01:24<00:47, 5683.00it/s]loading adj matrices:  63%|██████▎   | 463314/731288 [01:24<00:47, 5679.37it/s]loading adj matrices:  63%|██████▎   | 463883/731288 [01:25<00:47, 5681.80it/s]loading adj matrices:  64%|██████▎   | 464454/731288 [01:25<00:46, 5688.44it/s]loading adj matrices:  64%|██████▎   | 465023/731288 [01:25<00:46, 5666.37it/s]loading adj matrices:  64%|██████▎   | 465590/731288 [01:25<00:47, 5645.34it/s]loading adj matrices:  64%|██████▎   | 466164/731288 [01:25<00:46, 5671.86it/s]loading adj matrices:  64%|██████▍   | 466732/731288 [01:25<00:46, 5655.16it/s]loading adj matrices:  64%|██████▍   | 467298/731288 [01:25<00:46, 5628.85it/s]loading adj matrices:  64%|██████▍   | 467869/731288 [01:25<00:46, 5651.91it/s]loading adj matrices:  64%|██████▍   | 468439/731288 [01:25<00:46, 5664.37it/s]loading adj matrices:  64%|██████▍   | 469009/731288 [01:25<00:46, 5674.51it/s]loading adj matrices:  64%|██████▍   | 469577/731288 [01:26<00:46, 5669.75it/s]loading adj matrices:  64%|██████▍   | 470147/731288 [01:26<00:45, 5678.07it/s]loading adj matrices:  64%|██████▍   | 470716/731288 [01:26<00:45, 5681.02it/s]loading adj matrices:  64%|██████▍   | 471285/731288 [01:26<00:45, 5662.32it/s]loading adj matrices:  65%|██████▍   | 471856/731288 [01:26<00:45, 5675.05it/s]loading adj matrices:  65%|██████▍   | 472426/731288 [01:26<00:45, 5679.94it/s]loading adj matrices:  65%|██████▍   | 472995/731288 [01:26<00:45, 5660.86it/s]loading adj matrices:  65%|██████▍   | 473562/731288 [01:26<00:45, 5663.39it/s]loading adj matrices:  65%|██████▍   | 474144/731288 [01:26<00:45, 5708.07it/s]loading adj matrices:  65%|██████▍   | 474715/731288 [01:26<00:44, 5703.75it/s]loading adj matrices:  65%|██████▍   | 475286/731288 [01:27<00:44, 5689.02it/s]loading adj matrices:  65%|██████▌   | 475855/731288 [01:27<00:45, 5676.18it/s]loading adj matrices:  65%|██████▌   | 476433/731288 [01:27<00:44, 5705.95it/s]loading adj matrices:  65%|██████▌   | 477009/731288 [01:27<00:44, 5719.50it/s]loading adj matrices:  65%|██████▌   | 477581/731288 [01:27<00:44, 5697.35it/s]loading adj matrices:  65%|██████▌   | 478156/731288 [01:27<00:44, 5712.85it/s]loading adj matrices:  65%|██████▌   | 478729/731288 [01:27<00:44, 5716.79it/s]loading adj matrices:  66%|██████▌   | 479301/731288 [01:27<00:44, 5705.41it/s]loading adj matrices:  66%|██████▌   | 479872/731288 [01:27<00:44, 5656.95it/s]loading adj matrices:  66%|██████▌   | 480442/731288 [01:27<00:44, 5667.89it/s]loading adj matrices:  66%|██████▌   | 481010/731288 [01:28<00:44, 5669.68it/s]loading adj matrices:  66%|██████▌   | 481583/731288 [01:28<00:43, 5687.22it/s]loading adj matrices:  66%|██████▌   | 482154/731288 [01:28<00:43, 5692.63it/s]loading adj matrices:  66%|██████▌   | 482726/731288 [01:28<00:43, 5700.05it/s]loading adj matrices:  66%|██████▌   | 483297/731288 [01:28<00:43, 5668.11it/s]loading adj matrices:  66%|██████▌   | 483864/731288 [01:28<00:43, 5666.04it/s]loading adj matrices:  66%|██████▌   | 484438/731288 [01:28<00:43, 5687.06it/s]loading adj matrices:  66%|██████▋   | 485010/731288 [01:28<00:43, 5695.00it/s]loading adj matrices:  66%|██████▋   | 485581/731288 [01:28<00:43, 5698.43it/s]loading adj matrices:  66%|██████▋   | 486151/731288 [01:28<00:43, 5670.30it/s]loading adj matrices:  67%|██████▋   | 486719/731288 [01:29<00:43, 5671.98it/s]loading adj matrices:  67%|██████▋   | 487287/731288 [01:29<00:43, 5638.13it/s]loading adj matrices:  67%|██████▋   | 487854/731288 [01:29<00:43, 5646.99it/s]loading adj matrices:  67%|██████▋   | 488422/731288 [01:29<00:42, 5655.93it/s]loading adj matrices:  67%|██████▋   | 488994/731288 [01:29<00:42, 5674.12it/s]loading adj matrices:  67%|██████▋   | 489570/731288 [01:29<00:42, 5699.12it/s]loading adj matrices:  67%|██████▋   | 490140/731288 [01:29<00:42, 5695.79it/s]loading adj matrices:  67%|██████▋   | 490710/731288 [01:29<00:42, 5672.82it/s]loading adj matrices:  67%|██████▋   | 491280/731288 [01:29<00:42, 5679.41it/s]loading adj matrices:  67%|██████▋   | 491851/731288 [01:29<00:42, 5687.54it/s]loading adj matrices:  67%|██████▋   | 492420/731288 [01:30<00:42, 5684.93it/s]loading adj matrices:  67%|██████▋   | 492989/731288 [01:30<00:41, 5685.91it/s]loading adj matrices:  67%|██████▋   | 493558/731288 [01:30<00:41, 5675.36it/s]loading adj matrices:  68%|██████▊   | 494127/731288 [01:30<00:41, 5677.41it/s]loading adj matrices:  68%|██████▊   | 494695/731288 [01:30<00:41, 5670.58it/s]loading adj matrices:  68%|██████▊   | 495263/731288 [01:30<00:41, 5646.43it/s]loading adj matrices:  68%|██████▊   | 495832/731288 [01:30<00:41, 5658.00it/s]loading adj matrices:  68%|██████▊   | 496401/731288 [01:30<00:41, 5665.56it/s]loading adj matrices:  68%|██████▊   | 496969/731288 [01:30<00:41, 5668.31it/s]loading adj matrices:  68%|██████▊   | 497549/731288 [01:30<00:40, 5707.43it/s]loading adj matrices:  68%|██████▊   | 498120/731288 [01:31<00:40, 5701.13it/s]loading adj matrices:  68%|██████▊   | 498691/731288 [01:31<00:40, 5676.46it/s]loading adj matrices:  68%|██████▊   | 499265/731288 [01:31<00:40, 5692.74it/s]loading adj matrices:  68%|██████▊   | 499836/731288 [01:31<00:40, 5697.01it/s]loading adj matrices:  68%|██████▊   | 500406/731288 [01:31<00:40, 5682.61it/s]loading adj matrices:  69%|██████▊   | 500975/731288 [01:31<00:40, 5654.84it/s]loading adj matrices:  69%|██████▊   | 501550/731288 [01:31<00:40, 5682.51it/s]loading adj matrices:  69%|██████▊   | 502119/731288 [01:31<00:40, 5678.38it/s]loading adj matrices:  69%|██████▊   | 502689/731288 [01:31<00:40, 5683.23it/s]loading adj matrices:  69%|██████▉   | 503258/731288 [01:31<00:40, 5682.35it/s]loading adj matrices:  69%|██████▉   | 503832/731288 [01:32<00:39, 5697.01it/s]loading adj matrices:  69%|██████▉   | 504402/731288 [01:32<00:39, 5676.97it/s]loading adj matrices:  69%|██████▉   | 504970/731288 [01:32<00:40, 5652.64it/s]loading adj matrices:  69%|██████▉   | 505541/731288 [01:32<00:39, 5669.12it/s]loading adj matrices:  69%|██████▉   | 506124/731288 [01:32<00:39, 5714.50it/s]loading adj matrices:  69%|██████▉   | 506696/731288 [01:32<00:39, 5678.62it/s]loading adj matrices:  69%|██████▉   | 507264/731288 [01:34<03:34, 1042.73it/s]loading adj matrices:  69%|██████▉   | 507833/731288 [01:34<02:41, 1379.51it/s]loading adj matrices:  70%|██████▉   | 508400/731288 [01:34<02:05, 1782.00it/s]loading adj matrices:  70%|██████▉   | 508968/731288 [01:34<01:39, 2242.39it/s]loading adj matrices:  70%|██████▉   | 509540/731288 [01:34<01:20, 2743.96it/s]loading adj matrices:  70%|██████▉   | 510104/731288 [01:34<01:08, 3238.98it/s]loading adj matrices:  70%|██████▉   | 510670/731288 [01:34<00:59, 3713.02it/s]loading adj matrices:  70%|██████▉   | 511234/731288 [01:34<00:53, 4134.71it/s]loading adj matrices:  70%|██████▉   | 511790/731288 [01:34<00:49, 4472.70it/s]loading adj matrices:  70%|███████   | 512356/731288 [01:35<00:45, 4773.41it/s]loading adj matrices:  70%|███████   | 512922/731288 [01:35<00:43, 5007.56it/s]loading adj matrices:  70%|███████   | 513489/731288 [01:35<00:41, 5189.81it/s]loading adj matrices:  70%|███████   | 514059/731288 [01:35<00:40, 5332.82it/s]loading adj matrices:  70%|███████   | 514624/731288 [01:35<00:39, 5421.02it/s]loading adj matrices:  70%|███████   | 515200/731288 [01:35<00:39, 5518.62it/s]loading adj matrices:  71%|███████   | 515768/731288 [01:35<00:39, 5524.75it/s]loading adj matrices:  71%|███████   | 516333/731288 [01:35<00:38, 5561.37it/s]loading adj matrices:  71%|███████   | 516905/731288 [01:35<00:38, 5607.22it/s]loading adj matrices:  71%|███████   | 517472/731288 [01:35<00:38, 5625.06it/s]loading adj matrices:  71%|███████   | 518040/731288 [01:36<00:37, 5639.61it/s]loading adj matrices:  71%|███████   | 518608/731288 [01:36<00:37, 5650.40it/s]loading adj matrices:  71%|███████   | 519175/731288 [01:36<00:37, 5648.52it/s]loading adj matrices:  71%|███████   | 519745/731288 [01:36<00:37, 5660.93it/s]loading adj matrices:  71%|███████   | 520314/731288 [01:36<00:37, 5666.95it/s]loading adj matrices:  71%|███████   | 520882/731288 [01:36<00:37, 5658.67it/s]loading adj matrices:  71%|███████▏  | 521449/731288 [01:36<00:37, 5661.74it/s]loading adj matrices:  71%|███████▏  | 522016/731288 [01:36<00:37, 5636.79it/s]loading adj matrices:  71%|███████▏  | 522589/731288 [01:36<00:36, 5661.88it/s]loading adj matrices:  72%|███████▏  | 523157/731288 [01:36<00:36, 5666.77it/s]loading adj matrices:  72%|███████▏  | 523729/731288 [01:37<00:36, 5681.05it/s]loading adj matrices:  72%|███████▏  | 524298/731288 [01:37<00:36, 5681.13it/s]loading adj matrices:  72%|███████▏  | 524867/731288 [01:37<00:36, 5675.99it/s]loading adj matrices:  72%|███████▏  | 525438/731288 [01:37<00:36, 5684.73it/s]loading adj matrices:  72%|███████▏  | 526007/731288 [01:37<00:36, 5682.36it/s]loading adj matrices:  72%|███████▏  | 526576/731288 [01:37<00:36, 5665.74it/s]loading adj matrices:  72%|███████▏  | 527143/731288 [01:37<00:36, 5650.33it/s]loading adj matrices:  72%|███████▏  | 527714/731288 [01:37<00:35, 5666.73it/s]loading adj matrices:  72%|███████▏  | 528281/731288 [01:37<00:35, 5648.85it/s]loading adj matrices:  72%|███████▏  | 528852/731288 [01:37<00:35, 5666.92it/s]loading adj matrices:  72%|███████▏  | 529429/731288 [01:38<00:35, 5697.00it/s]loading adj matrices:  72%|███████▏  | 529999/731288 [01:38<00:35, 5690.90it/s]loading adj matrices:  73%|███████▎  | 530569/731288 [01:38<00:35, 5693.13it/s]loading adj matrices:  73%|███████▎  | 531139/731288 [01:38<00:35, 5686.49it/s]loading adj matrices:  73%|███████▎  | 531708/731288 [01:38<00:35, 5685.19it/s]loading adj matrices:  73%|███████▎  | 532277/731288 [01:38<00:35, 5681.21it/s]loading adj matrices:  73%|███████▎  | 532846/731288 [01:38<00:34, 5683.41it/s]loading adj matrices:  73%|███████▎  | 533415/731288 [01:38<00:34, 5675.69it/s]loading adj matrices:  73%|███████▎  | 533993/731288 [01:38<00:34, 5706.00it/s]loading adj matrices:  73%|███████▎  | 534564/731288 [01:38<00:34, 5683.29it/s]loading adj matrices:  73%|███████▎  | 535133/731288 [01:39<00:34, 5679.57it/s]loading adj matrices:  73%|███████▎  | 535701/731288 [01:39<00:34, 5670.48it/s]loading adj matrices:  73%|███████▎  | 536269/731288 [01:39<00:34, 5666.56it/s]loading adj matrices:  73%|███████▎  | 536836/731288 [01:39<00:34, 5653.21it/s]loading adj matrices:  73%|███████▎  | 537402/731288 [01:39<00:34, 5648.43it/s]loading adj matrices:  74%|███████▎  | 537971/731288 [01:39<00:34, 5659.68it/s]loading adj matrices:  74%|███████▎  | 538540/731288 [01:39<00:34, 5666.26it/s]loading adj matrices:  74%|███████▎  | 539107/731288 [01:39<00:33, 5663.55it/s]loading adj matrices:  74%|███████▍  | 539674/731288 [01:39<00:33, 5658.17it/s]loading adj matrices:  74%|███████▍  | 540240/731288 [01:39<00:33, 5657.55it/s]loading adj matrices:  74%|███████▍  | 540806/731288 [01:40<00:33, 5657.78it/s]loading adj matrices:  74%|███████▍  | 541372/731288 [01:40<00:33, 5654.87it/s]loading adj matrices:  74%|███████▍  | 541943/731288 [01:40<00:33, 5669.64it/s]loading adj matrices:  74%|███████▍  | 542517/731288 [01:40<00:33, 5690.35it/s]loading adj matrices:  74%|███████▍  | 543087/731288 [01:40<00:33, 5657.11it/s]loading adj matrices:  74%|███████▍  | 543655/731288 [01:40<00:33, 5662.04it/s]loading adj matrices:  74%|███████▍  | 544222/731288 [01:40<00:33, 5663.72it/s]loading adj matrices:  74%|███████▍  | 544789/731288 [01:40<00:32, 5658.72it/s]loading adj matrices:  75%|███████▍  | 545355/731288 [01:40<00:32, 5650.06it/s]loading adj matrices:  75%|███████▍  | 545921/731288 [01:40<00:32, 5640.47it/s]loading adj matrices:  75%|███████▍  | 546492/731288 [01:41<00:32, 5660.01it/s]loading adj matrices:  75%|███████▍  | 547061/731288 [01:41<00:32, 5666.54it/s]loading adj matrices:  75%|███████▍  | 547632/731288 [01:41<00:32, 5677.01it/s]loading adj matrices:  75%|███████▍  | 548200/731288 [01:41<00:32, 5675.45it/s]loading adj matrices:  75%|███████▌  | 548777/731288 [01:41<00:32, 5703.21it/s]loading adj matrices:  75%|███████▌  | 549348/731288 [01:41<00:32, 5675.03it/s]loading adj matrices:  75%|███████▌  | 549917/731288 [01:41<00:31, 5678.97it/s]loading adj matrices:  75%|███████▌  | 550492/731288 [01:41<00:31, 5697.94it/s]loading adj matrices:  75%|███████▌  | 551062/731288 [01:41<00:31, 5673.09it/s]loading adj matrices:  75%|███████▌  | 551630/731288 [01:41<00:31, 5644.56it/s]loading adj matrices:  76%|███████▌  | 552208/731288 [01:42<00:31, 5683.71it/s]loading adj matrices:  76%|███████▌  | 552778/731288 [01:42<00:31, 5686.13it/s]loading adj matrices:  76%|███████▌  | 553352/731288 [01:42<00:31, 5701.17it/s]loading adj matrices:  76%|███████▌  | 553930/731288 [01:42<00:30, 5722.57it/s]loading adj matrices:  76%|███████▌  | 554503/731288 [01:42<00:30, 5715.90it/s]loading adj matrices:  76%|███████▌  | 555079/731288 [01:42<00:30, 5727.54it/s]loading adj matrices:  76%|███████▌  | 555652/731288 [01:42<00:30, 5710.51it/s]loading adj matrices:  76%|███████▌  | 556224/731288 [01:42<00:30, 5688.71it/s]loading adj matrices:  76%|███████▌  | 556793/731288 [01:42<00:30, 5684.79it/s]loading adj matrices:  76%|███████▌  | 557362/731288 [01:42<00:30, 5669.72it/s]loading adj matrices:  76%|███████▋  | 557929/731288 [01:43<00:30, 5640.90it/s]loading adj matrices:  76%|███████▋  | 558494/731288 [01:43<00:30, 5626.64it/s]loading adj matrices:  76%|███████▋  | 559059/731288 [01:43<00:30, 5633.48it/s]loading adj matrices:  77%|███████▋  | 559632/731288 [01:43<00:30, 5661.33it/s]loading adj matrices:  77%|███████▋  | 560200/731288 [01:43<00:30, 5666.34it/s]loading adj matrices:  77%|███████▋  | 560770/731288 [01:43<00:30, 5676.18it/s]loading adj matrices:  77%|███████▋  | 561338/731288 [01:43<00:30, 5647.47it/s]loading adj matrices:  77%|███████▋  | 561916/731288 [01:43<00:29, 5685.45it/s]loading adj matrices:  77%|███████▋  | 562485/731288 [01:43<00:29, 5686.06it/s]loading adj matrices:  77%|███████▋  | 563057/731288 [01:43<00:29, 5693.46it/s]loading adj matrices:  77%|███████▋  | 563627/731288 [01:44<00:29, 5673.20it/s]loading adj matrices:  77%|███████▋  | 564196/731288 [01:44<00:29, 5676.81it/s]loading adj matrices:  77%|███████▋  | 564765/731288 [01:44<00:29, 5678.32it/s]loading adj matrices:  77%|███████▋  | 565333/731288 [01:44<00:29, 5664.49it/s]loading adj matrices:  77%|███████▋  | 565902/731288 [01:44<00:29, 5669.51it/s]loading adj matrices:  77%|███████▋  | 566486/731288 [01:44<00:28, 5717.62it/s]loading adj matrices:  78%|███████▊  | 567058/731288 [01:44<00:28, 5694.77it/s]loading adj matrices:  78%|███████▊  | 567628/731288 [01:44<00:28, 5693.51it/s]loading adj matrices:  78%|███████▊  | 568198/731288 [01:44<00:28, 5677.85it/s]loading adj matrices:  78%|███████▊  | 568766/731288 [01:44<00:28, 5668.95it/s]loading adj matrices:  78%|███████▊  | 569343/731288 [01:45<00:28, 5696.45it/s]loading adj matrices:  78%|███████▊  | 569920/731288 [01:45<00:28, 5716.41it/s]loading adj matrices:  78%|███████▊  | 570492/731288 [01:45<00:28, 5699.27it/s]loading adj matrices:  78%|███████▊  | 571062/731288 [01:45<00:28, 5688.04it/s]loading adj matrices:  78%|███████▊  | 571631/731288 [01:45<00:28, 5686.12it/s]loading adj matrices:  78%|███████▊  | 572200/731288 [01:45<00:28, 5654.64it/s]loading adj matrices:  78%|███████▊  | 572771/731288 [01:45<00:27, 5669.34it/s]loading adj matrices:  78%|███████▊  | 573344/731288 [01:45<00:27, 5684.40it/s]loading adj matrices:  78%|███████▊  | 573913/731288 [01:45<00:27, 5660.68it/s]loading adj matrices:  79%|███████▊  | 574480/731288 [01:46<00:27, 5648.28it/s]loading adj matrices:  79%|███████▊  | 575058/731288 [01:46<00:27, 5686.29it/s]loading adj matrices:  79%|███████▊  | 575627/731288 [01:46<00:27, 5684.79it/s]loading adj matrices:  79%|███████▉  | 576201/731288 [01:46<00:27, 5699.39it/s]loading adj matrices:  79%|███████▉  | 576771/731288 [01:46<00:27, 5668.64it/s]loading adj matrices:  79%|███████▉  | 577338/731288 [01:46<00:27, 5646.87it/s]loading adj matrices:  79%|███████▉  | 577904/731288 [01:46<00:27, 5647.84it/s]loading adj matrices:  79%|███████▉  | 578480/731288 [01:46<00:26, 5680.50it/s]loading adj matrices:  79%|███████▉  | 579050/731288 [01:46<00:26, 5685.05it/s]loading adj matrices:  79%|███████▉  | 579620/731288 [01:46<00:26, 5689.17it/s]loading adj matrices:  79%|███████▉  | 580189/731288 [01:47<00:26, 5656.40it/s]loading adj matrices:  79%|███████▉  | 580755/731288 [01:47<00:26, 5643.80it/s]loading adj matrices:  79%|███████▉  | 581333/731288 [01:47<00:26, 5684.13it/s]loading adj matrices:  80%|███████▉  | 581902/731288 [01:47<00:26, 5669.32it/s]loading adj matrices:  80%|███████▉  | 582476/731288 [01:47<00:26, 5687.88it/s]loading adj matrices:  80%|███████▉  | 583045/731288 [01:47<00:26, 5679.94it/s]loading adj matrices:  80%|███████▉  | 583614/731288 [01:47<00:26, 5666.50it/s]loading adj matrices:  80%|███████▉  | 584188/731288 [01:47<00:25, 5686.76it/s]loading adj matrices:  80%|███████▉  | 584757/731288 [01:47<00:25, 5678.35it/s]loading adj matrices:  80%|████████  | 585328/731288 [01:47<00:25, 5687.16it/s]loading adj matrices:  80%|████████  | 585901/731288 [01:48<00:25, 5698.63it/s]loading adj matrices:  80%|████████  | 586471/731288 [01:48<00:25, 5688.77it/s]loading adj matrices:  80%|████████  | 587040/731288 [01:48<00:25, 5665.97it/s]loading adj matrices:  80%|████████  | 587613/731288 [01:48<00:25, 5685.01it/s]loading adj matrices:  80%|████████  | 588182/731288 [01:48<00:25, 5673.63it/s]loading adj matrices:  81%|████████  | 588751/731288 [01:48<00:25, 5677.15it/s]loading adj matrices:  81%|████████  | 589324/731288 [01:48<00:24, 5690.93it/s]loading adj matrices:  81%|████████  | 589896/731288 [01:48<00:24, 5699.05it/s]loading adj matrices:  81%|████████  | 590466/731288 [01:48<00:24, 5693.02it/s]loading adj matrices:  81%|████████  | 591041/731288 [01:48<00:24, 5702.18it/s]loading adj matrices:  81%|████████  | 591612/731288 [01:49<00:24, 5693.94it/s]loading adj matrices:  81%|████████  | 592182/731288 [01:49<00:24, 5689.61it/s]loading adj matrices:  81%|████████  | 592751/731288 [01:49<00:24, 5688.69it/s]loading adj matrices:  81%|████████  | 593320/731288 [01:49<00:24, 5677.08it/s]loading adj matrices:  81%|████████  | 593888/731288 [01:49<00:24, 5667.59it/s]loading adj matrices:  81%|████████▏ | 594457/731288 [01:49<00:24, 5671.69it/s]loading adj matrices:  81%|████████▏ | 595027/731288 [01:49<00:23, 5678.70it/s]loading adj matrices:  81%|████████▏ | 595595/731288 [01:49<00:24, 5652.37it/s]loading adj matrices:  82%|████████▏ | 596177/731288 [01:49<00:23, 5700.36it/s]loading adj matrices:  82%|████████▏ | 596750/731288 [01:49<00:23, 5705.67it/s]loading adj matrices:  82%|████████▏ | 597321/731288 [01:50<00:23, 5693.97it/s]loading adj matrices:  82%|████████▏ | 597891/731288 [01:50<00:23, 5641.24it/s]loading adj matrices:  82%|████████▏ | 598464/731288 [01:50<00:23, 5665.26it/s]loading adj matrices:  82%|████████▏ | 599031/731288 [01:50<00:23, 5637.97it/s]loading adj matrices:  82%|████████▏ | 599598/731288 [01:50<00:23, 5645.09it/s]loading adj matrices:  82%|████████▏ | 600165/731288 [01:50<00:23, 5650.34it/s]loading adj matrices:  82%|████████▏ | 600732/731288 [01:50<00:23, 5654.72it/s]loading adj matrices:  82%|████████▏ | 601299/731288 [01:50<00:22, 5656.36it/s]loading adj matrices:  82%|████████▏ | 601865/731288 [01:50<00:22, 5652.79it/s]loading adj matrices:  82%|████████▏ | 602431/731288 [01:50<00:22, 5638.43it/s]loading adj matrices:  82%|████████▏ | 603002/731288 [01:51<00:22, 5659.61it/s]loading adj matrices:  83%|████████▎ | 603571/731288 [01:51<00:22, 5667.96it/s]loading adj matrices:  83%|████████▎ | 604138/731288 [01:51<00:22, 5650.38it/s]loading adj matrices:  83%|████████▎ | 604704/731288 [01:51<00:22, 5515.81it/s]loading adj matrices:  83%|████████▎ | 605257/731288 [01:51<00:22, 5503.56it/s]loading adj matrices:  83%|████████▎ | 605818/731288 [01:51<00:22, 5534.69it/s]loading adj matrices:  83%|████████▎ | 606390/731288 [01:51<00:22, 5588.54it/s]loading adj matrices:  83%|████████▎ | 606967/731288 [01:51<00:22, 5640.75it/s]loading adj matrices:  83%|████████▎ | 607538/731288 [01:51<00:21, 5661.24it/s]loading adj matrices:  83%|████████▎ | 608105/731288 [01:51<00:21, 5643.78it/s]loading adj matrices:  83%|████████▎ | 608670/731288 [01:52<00:21, 5640.09it/s]loading adj matrices:  83%|████████▎ | 609235/731288 [01:52<00:21, 5633.45it/s]loading adj matrices:  83%|████████▎ | 609805/731288 [01:52<00:21, 5652.44it/s]loading adj matrices:  83%|████████▎ | 610371/731288 [01:52<00:21, 5648.22it/s]loading adj matrices:  84%|████████▎ | 610943/731288 [01:52<00:21, 5666.26it/s]loading adj matrices:  84%|████████▎ | 611527/731288 [01:52<00:20, 5717.69it/s]loading adj matrices:  84%|████████▎ | 612099/731288 [01:52<00:20, 5704.62it/s]loading adj matrices:  84%|████████▍ | 612670/731288 [01:52<00:20, 5693.54it/s]loading adj matrices:  84%|████████▍ | 613240/731288 [01:52<00:20, 5653.94it/s]loading adj matrices:  84%|████████▍ | 613806/731288 [01:52<00:20, 5655.13it/s]loading adj matrices:  84%|████████▍ | 614372/731288 [01:53<00:20, 5636.19it/s]loading adj matrices:  84%|████████▍ | 614943/731288 [01:53<00:20, 5656.05it/s]loading adj matrices:  84%|████████▍ | 615516/731288 [01:53<00:20, 5674.68it/s]loading adj matrices:  84%|████████▍ | 616084/731288 [01:53<00:20, 5658.67it/s]loading adj matrices:  84%|████████▍ | 616650/731288 [01:53<00:20, 5632.69it/s]loading adj matrices:  84%|████████▍ | 617232/731288 [01:53<00:20, 5686.95it/s]loading adj matrices:  84%|████████▍ | 617802/731288 [01:53<00:19, 5688.28it/s]loading adj matrices:  85%|████████▍ | 618372/731288 [01:53<00:19, 5690.24it/s]loading adj matrices:  85%|████████▍ | 618942/731288 [01:53<00:19, 5678.70it/s]loading adj matrices:  85%|████████▍ | 619511/731288 [01:53<00:19, 5681.27it/s]loading adj matrices:  85%|████████▍ | 620082/731288 [01:54<00:19, 5687.17it/s]loading adj matrices:  85%|████████▍ | 620651/731288 [01:54<00:19, 5674.78it/s]loading adj matrices:  85%|████████▍ | 621219/731288 [01:54<00:19, 5667.10it/s]loading adj matrices:  85%|████████▌ | 621786/731288 [01:54<00:19, 5652.56it/s]loading adj matrices:  85%|████████▌ | 622354/731288 [01:54<00:19, 5658.05it/s]loading adj matrices:  85%|████████▌ | 622920/731288 [01:54<00:19, 5635.86it/s]loading adj matrices:  85%|████████▌ | 623493/731288 [01:54<00:19, 5663.64it/s]loading adj matrices:  85%|████████▌ | 624062/731288 [01:54<00:18, 5670.90it/s]loading adj matrices:  85%|████████▌ | 624630/731288 [01:54<00:18, 5668.78it/s]loading adj matrices:  85%|████████▌ | 625197/731288 [01:54<00:18, 5654.84it/s]loading adj matrices:  86%|████████▌ | 625764/731288 [01:55<00:18, 5656.83it/s]loading adj matrices:  86%|████████▌ | 626339/731288 [01:55<00:18, 5684.42it/s]loading adj matrices:  86%|████████▌ | 626908/731288 [01:55<00:18, 5682.79it/s]loading adj matrices:  86%|████████▌ | 627477/731288 [01:55<00:18, 5676.69it/s]loading adj matrices:  86%|████████▌ | 628045/731288 [01:55<00:18, 5649.52it/s]loading adj matrices:  86%|████████▌ | 628616/731288 [01:55<00:18, 5667.26it/s]loading adj matrices:  86%|████████▌ | 629183/731288 [01:55<00:18, 5651.49it/s]loading adj matrices:  86%|████████▌ | 629758/731288 [01:55<00:17, 5679.73it/s]loading adj matrices:  86%|████████▌ | 630327/731288 [01:55<00:17, 5678.65it/s]loading adj matrices:  86%|████████▋ | 630895/731288 [01:55<00:17, 5635.94it/s]loading adj matrices:  86%|████████▋ | 631459/731288 [01:56<00:17, 5627.10it/s]loading adj matrices:  86%|████████▋ | 632037/731288 [01:56<00:17, 5669.87it/s]loading adj matrices:  87%|████████▋ | 632605/731288 [01:56<00:17, 5656.32it/s]loading adj matrices:  87%|████████▋ | 633171/731288 [01:56<00:17, 5655.29it/s]loading adj matrices:  87%|████████▋ | 633746/731288 [01:56<00:17, 5680.97it/s]loading adj matrices:  87%|████████▋ | 634315/731288 [01:56<00:17, 5655.61it/s]loading adj matrices:  87%|████████▋ | 634888/731288 [01:56<00:16, 5677.02it/s]loading adj matrices:  87%|████████▋ | 635456/731288 [01:56<00:17, 5635.98it/s]loading adj matrices:  87%|████████▋ | 636026/731288 [01:56<00:16, 5653.49it/s]loading adj matrices:  87%|████████▋ | 636597/731288 [01:56<00:16, 5668.67it/s]loading adj matrices:  87%|████████▋ | 637175/731288 [01:57<00:16, 5701.17it/s]loading adj matrices:  87%|████████▋ | 637746/731288 [01:57<00:16, 5672.54it/s]loading adj matrices:  87%|████████▋ | 638321/731288 [01:57<00:16, 5695.14it/s]loading adj matrices:  87%|████████▋ | 638891/731288 [01:57<00:16, 5683.07it/s]loading adj matrices:  87%|████████▋ | 639460/731288 [01:57<00:16, 5677.74it/s]loading adj matrices:  88%|████████▊ | 640031/731288 [01:57<00:16, 5685.68it/s]loading adj matrices:  88%|████████▊ | 640600/731288 [01:57<00:15, 5683.22it/s]loading adj matrices:  88%|████████▊ | 641169/731288 [01:57<00:15, 5668.79it/s]loading adj matrices:  88%|████████▊ | 641736/731288 [01:57<00:15, 5668.66it/s]loading adj matrices:  88%|████████▊ | 642303/731288 [01:57<00:15, 5666.05it/s]loading adj matrices:  88%|████████▊ | 642870/731288 [01:58<00:15, 5656.04it/s]loading adj matrices:  88%|████████▊ | 643445/731288 [01:58<00:15, 5680.71it/s]loading adj matrices:  88%|████████▊ | 644014/731288 [01:58<00:15, 5659.76it/s]loading adj matrices:  88%|████████▊ | 644584/731288 [01:58<00:15, 5670.64it/s]loading adj matrices:  88%|████████▊ | 645152/731288 [01:58<00:15, 5660.37it/s]loading adj matrices:  88%|████████▊ | 645719/731288 [01:58<00:15, 5640.40it/s]loading adj matrices:  88%|████████▊ | 646294/731288 [01:58<00:14, 5671.80it/s]loading adj matrices:  88%|████████▊ | 646878/731288 [01:58<00:14, 5719.07it/s]loading adj matrices:  89%|████████▊ | 647450/731288 [01:58<00:14, 5699.04it/s]loading adj matrices:  89%|████████▊ | 648020/731288 [01:58<00:14, 5670.07it/s]loading adj matrices:  89%|████████▊ | 648588/731288 [01:59<00:14, 5670.91it/s]loading adj matrices:  89%|████████▉ | 649156/731288 [01:59<00:14, 5660.59it/s]loading adj matrices:  89%|████████▉ | 649727/731288 [01:59<00:14, 5674.56it/s]loading adj matrices:  89%|████████▉ | 650295/731288 [01:59<00:14, 5670.46it/s]loading adj matrices:  89%|████████▉ | 650870/731288 [01:59<00:14, 5692.69it/s]loading adj matrices:  89%|████████▉ | 651440/731288 [01:59<00:14, 5691.87it/s]loading adj matrices:  89%|████████▉ | 652010/731288 [01:59<00:13, 5676.00it/s]loading adj matrices:  89%|████████▉ | 652578/731288 [01:59<00:13, 5673.23it/s]loading adj matrices:  89%|████████▉ | 653148/731288 [01:59<00:13, 5679.00it/s]loading adj matrices:  89%|████████▉ | 653716/731288 [01:59<00:13, 5669.11it/s]loading adj matrices:  89%|████████▉ | 654283/731288 [02:00<00:13, 5641.12it/s]loading adj matrices:  90%|████████▉ | 654849/731288 [02:00<00:13, 5645.83it/s]loading adj matrices:  90%|████████▉ | 655434/731288 [02:00<00:13, 5705.55it/s]loading adj matrices:  90%|████████▉ | 656005/731288 [02:00<00:13, 5694.11it/s]loading adj matrices:  90%|████████▉ | 656575/731288 [02:00<00:13, 5671.50it/s]loading adj matrices:  90%|████████▉ | 657154/731288 [02:00<00:12, 5706.43it/s]loading adj matrices:  90%|████████▉ | 657725/731288 [02:00<00:12, 5693.09it/s]loading adj matrices:  90%|█████████ | 658295/731288 [02:00<00:12, 5678.91it/s]loading adj matrices:  90%|█████████ | 658863/731288 [02:00<00:12, 5670.86it/s]loading adj matrices:  90%|█████████ | 659434/731288 [02:00<00:12, 5680.73it/s]loading adj matrices:  90%|█████████ | 660010/731288 [02:01<00:12, 5701.47it/s]loading adj matrices:  90%|█████████ | 660581/731288 [02:01<00:12, 5688.50it/s]loading adj matrices:  90%|█████████ | 661154/731288 [02:01<00:12, 5698.64it/s]loading adj matrices:  90%|█████████ | 661724/731288 [02:01<00:12, 5698.34it/s]loading adj matrices:  91%|█████████ | 662294/731288 [02:01<00:12, 5698.31it/s]loading adj matrices:  91%|█████████ | 662864/731288 [02:01<00:12, 5677.38it/s]loading adj matrices:  91%|█████████ | 663438/731288 [02:01<00:11, 5693.24it/s]loading adj matrices:  91%|█████████ | 664012/731288 [02:01<00:11, 5704.33it/s]loading adj matrices:  91%|█████████ | 664583/731288 [02:01<00:11, 5686.78it/s]loading adj matrices:  91%|█████████ | 665156/731288 [02:01<00:11, 5697.61it/s]loading adj matrices:  91%|█████████ | 665728/731288 [02:02<00:11, 5703.28it/s]loading adj matrices:  91%|█████████ | 666299/731288 [02:02<00:11, 5669.50it/s]loading adj matrices:  91%|█████████ | 666867/731288 [02:02<00:11, 5658.19it/s]loading adj matrices:  91%|█████████▏| 667441/731288 [02:02<00:11, 5679.97it/s]loading adj matrices:  91%|█████████▏| 668013/731288 [02:02<00:11, 5688.44it/s]loading adj matrices:  91%|█████████▏| 668585/731288 [02:02<00:11, 5696.31it/s]loading adj matrices:  92%|█████████▏| 669155/731288 [02:02<00:10, 5688.67it/s]loading adj matrices:  92%|█████████▏| 669725/731288 [02:02<00:10, 5690.01it/s]loading adj matrices:  92%|█████████▏| 670295/731288 [02:02<00:10, 5685.18it/s]loading adj matrices:  92%|█████████▏| 670864/731288 [02:03<00:10, 5675.09it/s]loading adj matrices:  92%|█████████▏| 671432/731288 [02:03<00:10, 5659.02it/s]loading adj matrices:  92%|█████████▏| 671998/731288 [02:03<00:10, 5656.77it/s]loading adj matrices:  92%|█████████▏| 672567/731288 [02:03<00:10, 5664.20it/s]loading adj matrices:  92%|█████████▏| 673134/731288 [02:03<00:10, 5642.44it/s]loading adj matrices:  92%|█████████▏| 673708/731288 [02:03<00:10, 5670.70it/s]loading adj matrices:  92%|█████████▏| 674277/731288 [02:03<00:10, 5676.12it/s]loading adj matrices:  92%|█████████▏| 674845/731288 [02:03<00:09, 5674.08it/s]loading adj matrices:  92%|█████████▏| 675413/731288 [02:03<00:09, 5658.29it/s]loading adj matrices:  92%|█████████▏| 675980/731288 [02:03<00:09, 5660.93it/s]loading adj matrices:  93%|█████████▎| 676548/731288 [02:04<00:09, 5665.87it/s]loading adj matrices:  93%|█████████▎| 677121/731288 [02:04<00:09, 5682.48it/s]loading adj matrices:  93%|█████████▎| 677690/731288 [02:04<00:09, 5677.43it/s]loading adj matrices:  93%|█████████▎| 678262/731288 [02:04<00:09, 5689.20it/s]loading adj matrices:  93%|█████████▎| 678834/731288 [02:04<00:09, 5696.29it/s]loading adj matrices:  93%|█████████▎| 679404/731288 [02:04<00:09, 5692.72it/s]loading adj matrices:  93%|█████████▎| 679974/731288 [02:04<00:09, 5682.25it/s]loading adj matrices:  93%|█████████▎| 680543/731288 [02:04<00:08, 5678.23it/s]loading adj matrices:  93%|█████████▎| 681120/731288 [02:04<00:08, 5703.94it/s]loading adj matrices:  93%|█████████▎| 681692/731288 [02:04<00:08, 5708.10it/s]loading adj matrices:  93%|█████████▎| 682264/731288 [02:05<00:08, 5708.89it/s]loading adj matrices:  93%|█████████▎| 682835/731288 [02:05<00:08, 5707.86it/s]loading adj matrices:  93%|█████████▎| 683413/731288 [02:05<00:08, 5726.89it/s]loading adj matrices:  94%|█████████▎| 683986/731288 [02:05<00:08, 5718.19it/s]loading adj matrices:  94%|█████████▎| 684567/731288 [02:05<00:08, 5743.51it/s]loading adj matrices:  94%|█████████▎| 685142/731288 [02:05<00:08, 5701.47it/s]loading adj matrices:  94%|█████████▍| 685713/731288 [02:05<00:08, 5676.93it/s]loading adj matrices:  94%|█████████▍| 686281/731288 [02:05<00:07, 5659.29it/s]loading adj matrices:  94%|█████████▍| 686851/731288 [02:05<00:07, 5671.00it/s]loading adj matrices:  94%|█████████▍| 687419/731288 [02:05<00:07, 5652.69it/s]loading adj matrices:  94%|█████████▍| 687991/731288 [02:06<00:07, 5671.59it/s]loading adj matrices:  94%|█████████▍| 688559/731288 [02:06<00:07, 5671.77it/s]loading adj matrices:  94%|█████████▍| 689127/731288 [02:06<00:07, 5665.91it/s]loading adj matrices:  94%|█████████▍| 689714/731288 [02:06<00:07, 5724.24it/s]loading adj matrices:  94%|█████████▍| 690287/731288 [02:06<00:07, 5703.06it/s]loading adj matrices:  94%|█████████▍| 690858/731288 [02:06<00:07, 5702.39it/s]loading adj matrices:  95%|█████████▍| 691429/731288 [02:06<00:07, 5693.30it/s]loading adj matrices:  95%|█████████▍| 691999/731288 [02:06<00:06, 5694.00it/s]loading adj matrices:  95%|█████████▍| 692569/731288 [02:06<00:06, 5678.74it/s]loading adj matrices:  95%|█████████▍| 693150/731288 [02:06<00:06, 5715.31it/s]loading adj matrices:  95%|█████████▍| 693722/731288 [02:07<00:06, 5710.90it/s]loading adj matrices:  95%|█████████▍| 694294/731288 [02:07<00:06, 5696.34it/s]loading adj matrices:  95%|█████████▌| 694880/731288 [02:07<00:06, 5742.86it/s]loading adj matrices:  95%|█████████▌| 695455/731288 [02:07<00:06, 5706.10it/s]loading adj matrices:  95%|█████████▌| 696031/731288 [02:07<00:06, 5720.62it/s]loading adj matrices:  95%|█████████▌| 696604/731288 [02:07<00:06, 5696.34it/s]loading adj matrices:  95%|█████████▌| 697174/731288 [02:07<00:05, 5697.05it/s]loading adj matrices:  95%|█████████▌| 697744/731288 [02:07<00:05, 5687.93it/s]loading adj matrices:  95%|█████████▌| 698313/731288 [02:07<00:05, 5665.55it/s]loading adj matrices:  96%|█████████▌| 698882/731288 [02:07<00:05, 5671.19it/s]loading adj matrices:  96%|█████████▌| 699450/731288 [02:08<00:05, 5590.08it/s]loading adj matrices:  96%|█████████▌| 700010/731288 [02:08<00:05, 5503.77it/s]loading adj matrices:  96%|█████████▌| 700572/731288 [02:08<00:05, 5537.39it/s]loading adj matrices:  96%|█████████▌| 701133/731288 [02:08<00:05, 5558.32it/s]loading adj matrices:  96%|█████████▌| 701699/731288 [02:08<00:05, 5586.33it/s]loading adj matrices:  96%|█████████▌| 702274/731288 [02:08<00:05, 5634.67it/s]loading adj matrices:  96%|█████████▌| 702839/731288 [02:08<00:05, 5636.93it/s]loading adj matrices:  96%|█████████▌| 703410/731288 [02:08<00:04, 5657.74it/s]loading adj matrices:  96%|█████████▋| 703986/731288 [02:08<00:04, 5687.62it/s]loading adj matrices:  96%|█████████▋| 704556/731288 [02:08<00:04, 5689.85it/s]loading adj matrices:  96%|█████████▋| 705126/731288 [02:09<00:04, 5661.96it/s]loading adj matrices:  97%|█████████▋| 705693/731288 [02:09<00:04, 5654.78it/s]loading adj matrices:  97%|█████████▋| 706263/731288 [02:09<00:04, 5667.60it/s]loading adj matrices:  97%|█████████▋| 706835/731288 [02:09<00:04, 5681.18it/s]loading adj matrices:  97%|█████████▋| 707412/731288 [02:09<00:04, 5706.39it/s]loading adj matrices:  97%|█████████▋| 707983/731288 [02:09<00:04, 5691.65it/s]loading adj matrices:  97%|█████████▋| 708559/731288 [02:09<00:03, 5709.55it/s]loading adj matrices:  97%|█████████▋| 709130/731288 [02:09<00:03, 5690.14it/s]loading adj matrices:  97%|█████████▋| 709703/731288 [02:09<00:03, 5699.89it/s]loading adj matrices:  97%|█████████▋| 710274/731288 [02:09<00:03, 5688.38it/s]loading adj matrices:  97%|█████████▋| 710843/731288 [02:10<00:03, 5669.17it/s]loading adj matrices:  97%|█████████▋| 711410/731288 [02:10<00:03, 5667.96it/s]loading adj matrices:  97%|█████████▋| 711978/731288 [02:10<00:03, 5671.42it/s]loading adj matrices:  97%|█████████▋| 712546/731288 [02:10<00:03, 5670.98it/s]loading adj matrices:  98%|█████████▊| 713114/731288 [02:10<00:03, 5637.64it/s]loading adj matrices:  98%|█████████▊| 713683/731288 [02:10<00:03, 5652.38it/s]loading adj matrices:  98%|█████████▊| 714249/731288 [02:10<00:03, 5653.70it/s]loading adj matrices:  98%|█████████▊| 714816/731288 [02:10<00:02, 5657.83it/s]loading adj matrices:  98%|█████████▊| 715382/731288 [02:10<00:02, 5648.73it/s]loading adj matrices:  98%|█████████▊| 715952/731288 [02:10<00:02, 5663.03it/s]loading adj matrices:  98%|█████████▊| 716534/731288 [02:11<00:02, 5707.34it/s]loading adj matrices:  98%|█████████▊| 717105/731288 [02:11<00:02, 5685.36it/s]loading adj matrices:  98%|█████████▊| 717674/731288 [02:11<00:02, 5684.17it/s]loading adj matrices:  98%|█████████▊| 718245/731288 [02:11<00:02, 5689.85it/s]loading adj matrices:  98%|█████████▊| 718814/731288 [02:11<00:02, 5681.94it/s]loading adj matrices:  98%|█████████▊| 719383/731288 [02:11<00:02, 5667.50it/s]loading adj matrices:  98%|█████████▊| 719951/731288 [02:11<00:02, 5668.22it/s]loading adj matrices:  99%|█████████▊| 720523/731288 [02:11<00:01, 5683.41it/s]loading adj matrices:  99%|█████████▊| 721092/731288 [02:11<00:01, 5672.69it/s]loading adj matrices:  99%|█████████▊| 721660/731288 [02:11<00:01, 5654.77it/s]loading adj matrices:  99%|█████████▉| 722238/731288 [02:12<00:01, 5691.67it/s]loading adj matrices:  99%|█████████▉| 722812/731288 [02:12<00:01, 5702.98it/s]loading adj matrices:  99%|█████████▉| 723383/731288 [02:12<00:01, 5668.67it/s]loading adj matrices:  99%|█████████▉| 723951/731288 [02:12<00:01, 5670.21it/s]loading adj matrices:  99%|█████████▉| 724520/731288 [02:12<00:01, 5674.47it/s]loading adj matrices:  99%|█████████▉| 725089/731288 [02:12<00:01, 5678.67it/s]loading adj matrices:  99%|█████████▉| 725659/731288 [02:12<00:00, 5682.87it/s]loading adj matrices:  99%|█████████▉| 726232/731288 [02:12<00:00, 5696.40it/s]loading adj matrices:  99%|█████████▉| 726802/731288 [02:12<00:00, 5693.57it/s]loading adj matrices:  99%|█████████▉| 727372/731288 [02:12<00:00, 5691.75it/s]loading adj matrices: 100%|█████████▉| 727942/731288 [02:13<00:00, 5658.96it/s]loading adj matrices: 100%|█████████▉| 728514/731288 [02:13<00:00, 5674.72it/s]loading adj matrices: 100%|█████████▉| 729082/731288 [02:13<00:00, 5663.44it/s]loading adj matrices: 100%|█████████▉| 729649/731288 [02:13<00:00, 5642.20it/s]loading adj matrices: 100%|█████████▉| 730215/731288 [02:13<00:00, 5644.97it/s]loading adj matrices: 100%|█████████▉| 730780/731288 [02:13<00:00, 5632.95it/s]loading adj matrices: 100%|██████████| 731288/731288 [02:13<00:00, 5471.52it/s]
| ori_adj_len: 4.40 | adj_len: 4.40 | prune_rate： 0.00 | qc_num: 1.23 | ac_num: 1.04 |
loading adj matrices:   0%|          | 0/16732 [00:00<?, ?it/s]loading adj matrices:   4%|▍         | 648/16732 [00:00<00:02, 6474.82it/s]loading adj matrices:   8%|▊         | 1308/16732 [00:00<00:02, 6545.65it/s]loading adj matrices:  12%|█▏        | 1968/16732 [00:00<00:02, 6568.07it/s]loading adj matrices:  16%|█▌        | 2633/16732 [00:00<00:02, 6597.01it/s]loading adj matrices:  20%|█▉        | 3293/16732 [00:00<00:02, 6573.49it/s]loading adj matrices:  24%|██▎       | 3961/16732 [00:00<00:01, 6609.32it/s]loading adj matrices:  28%|██▊       | 4626/16732 [00:00<00:01, 6622.36it/s]loading adj matrices:  32%|███▏      | 5289/16732 [00:00<00:01, 6598.04it/s]loading adj matrices:  36%|███▌      | 5956/16732 [00:00<00:01, 6620.01it/s]loading adj matrices:  40%|███▉      | 6631/16732 [00:01<00:01, 6658.45it/s]loading adj matrices:  44%|████▎     | 7297/16732 [00:01<00:01, 6626.45it/s]loading adj matrices:  48%|████▊     | 7967/16732 [00:01<00:01, 6647.50it/s]loading adj matrices:  52%|█████▏    | 8636/16732 [00:01<00:01, 6657.51it/s]loading adj matrices:  56%|█████▌    | 9302/16732 [00:01<00:01, 6628.17it/s]loading adj matrices:  60%|█████▉    | 9972/16732 [00:01<00:01, 6648.24it/s]loading adj matrices:  64%|██████▎   | 10637/16732 [00:01<00:00, 6631.13it/s]loading adj matrices:  68%|██████▊   | 11301/16732 [00:01<00:00, 6591.91it/s]loading adj matrices:  71%|███████▏  | 11961/16732 [00:01<00:00, 6532.69it/s]loading adj matrices:  75%|███████▌  | 12615/16732 [00:01<00:00, 6471.77it/s]loading adj matrices:  79%|███████▉  | 13263/16732 [00:02<00:00, 6396.19it/s]loading adj matrices:  83%|████████▎ | 13903/16732 [00:02<00:00, 6323.68it/s]loading adj matrices:  87%|████████▋ | 14536/16732 [00:02<00:00, 6278.14it/s]loading adj matrices:  91%|█████████ | 15164/16732 [00:02<00:00, 6233.25it/s]loading adj matrices:  94%|█████████▍| 15788/16732 [00:02<00:00, 6150.59it/s]loading adj matrices:  98%|█████████▊| 16404/16732 [00:02<00:00, 6122.18it/s]loading adj matrices: 100%|██████████| 16732/16732 [00:02<00:00, 6459.37it/s]
| ori_adj_len: 4.24 | adj_len: 4.24 | prune_rate： 0.00 | qc_num: 1.19 | ac_num: 1.03 |
loading adj matrices:   0%|          | 0/24600 [00:00<?, ?it/s]loading adj matrices:   2%|▏         | 590/24600 [00:00<00:04, 5897.47it/s]loading adj matrices:   5%|▍         | 1187/24600 [00:00<00:03, 5938.81it/s]loading adj matrices:   7%|▋         | 1781/24600 [00:00<00:03, 5925.37it/s]loading adj matrices:  10%|▉         | 2374/24600 [00:00<00:03, 5918.45it/s]loading adj matrices:  12%|█▏        | 2966/24600 [00:00<00:03, 5889.45it/s]loading adj matrices:  14%|█▍        | 3555/24600 [00:00<00:03, 5861.23it/s]loading adj matrices:  17%|█▋        | 4142/24600 [00:00<00:03, 5832.84it/s]loading adj matrices:  19%|█▉        | 4726/24600 [00:00<00:03, 5831.18it/s]loading adj matrices:  22%|██▏       | 5317/24600 [00:00<00:03, 5853.22it/s]loading adj matrices:  24%|██▍       | 5903/24600 [00:01<00:03, 5834.73it/s]loading adj matrices:  26%|██▋       | 6487/24600 [00:01<00:03, 5801.53it/s]loading adj matrices:  29%|██▊       | 7068/24600 [00:01<00:03, 5803.32it/s]loading adj matrices:  31%|███       | 7649/24600 [00:01<00:02, 5804.50it/s]loading adj matrices:  33%|███▎      | 8235/24600 [00:01<00:02, 5820.98it/s]loading adj matrices:  36%|███▌      | 8824/24600 [00:01<00:02, 5840.94it/s]loading adj matrices:  38%|███▊      | 9409/24600 [00:01<00:02, 5809.89it/s]loading adj matrices:  41%|████      | 9991/24600 [00:01<00:02, 5800.25it/s]loading adj matrices:  43%|████▎     | 10572/24600 [00:01<00:02, 5780.14it/s]loading adj matrices:  45%|████▌     | 11154/24600 [00:01<00:02, 5789.19it/s]loading adj matrices:  48%|████▊     | 11733/24600 [00:02<00:02, 5759.03it/s]loading adj matrices:  50%|█████     | 12309/24600 [00:02<00:02, 5717.54it/s]loading adj matrices:  52%|█████▏    | 12889/24600 [00:02<00:02, 5741.50it/s]loading adj matrices:  55%|█████▍    | 13464/24600 [00:02<00:01, 5719.83it/s]loading adj matrices:  57%|█████▋    | 14039/24600 [00:02<00:01, 5726.27it/s]loading adj matrices:  59%|█████▉    | 14612/24600 [00:02<00:01, 5689.20it/s]loading adj matrices:  62%|██████▏   | 15181/24600 [00:02<00:01, 5679.74it/s]loading adj matrices:  64%|██████▍   | 15751/24600 [00:02<00:01, 5684.50it/s]loading adj matrices:  66%|██████▋   | 16320/24600 [00:02<00:01, 5660.05it/s]loading adj matrices:  69%|██████▊   | 16887/24600 [00:02<00:01, 5659.79it/s]loading adj matrices:  71%|███████   | 17454/24600 [00:03<00:01, 5641.96it/s]loading adj matrices:  73%|███████▎  | 18023/24600 [00:03<00:01, 5654.34it/s]loading adj matrices:  76%|███████▌  | 18589/24600 [00:03<00:01, 5644.31it/s]loading adj matrices:  78%|███████▊  | 19159/24600 [00:03<00:00, 5658.40it/s]loading adj matrices:  80%|████████  | 19725/24600 [00:03<00:00, 5641.26it/s]loading adj matrices:  82%|████████▏ | 20290/24600 [00:03<00:00, 5633.76it/s]loading adj matrices:  85%|████████▍ | 20854/24600 [00:03<00:00, 5614.96it/s]loading adj matrices:  87%|████████▋ | 21416/24600 [00:03<00:00, 5600.04it/s]loading adj matrices:  89%|████████▉ | 21978/24600 [00:03<00:00, 5602.98it/s]loading adj matrices:  92%|█████████▏| 22539/24600 [00:03<00:00, 5585.49it/s]loading adj matrices:  94%|█████████▍| 23098/24600 [00:04<00:00, 5577.73it/s]loading adj matrices:  96%|█████████▌| 23656/24600 [00:04<00:00, 5572.34it/s]loading adj matrices:  98%|█████████▊| 24214/24600 [00:04<00:00, 5563.01it/s]loading adj matrices: 100%|██████████| 24600/24600 [00:04<00:00, 5718.84it/s]
| ori_adj_len: 3.72 | adj_len: 3.72 | prune_rate： 0.00 | qc_num: 1.12 | ac_num: 1.03 |
parameters:
	concept_emb.emb.weight                       	fixed	torch.Size([9958, 768])
	concept_emb.cpt_transform.weight             	trainable	torch.Size([100, 768])
	concept_emb.cpt_transform.bias               	trainable	torch.Size([100])
	reasoningnet.inter_layers.0.typed_transform.weight	trainable	torch.Size([300, 100])
	reasoningnet.inter_layers.0.typed_transform.bias	trainable	torch.Size([300])
	reasoningnet.inter_layers.0.path_attention.trans_scores	trainable	torch.Size([900])
	reasoningnet.inter_layers.0.path_attention.start_attention.layers.0-Linear.weight	trainable	torch.Size([50, 768])
	reasoningnet.inter_layers.0.path_attention.start_attention.layers.0-Linear.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.0.path_attention.start_attention.layers.0-LayerNorm.weight	trainable	torch.Size([50])
	reasoningnet.inter_layers.0.path_attention.start_attention.layers.0-LayerNorm.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.0.path_attention.start_attention.layers.1-Linear.weight	trainable	torch.Size([3, 50])
	reasoningnet.inter_layers.0.path_attention.start_attention.layers.1-Linear.bias	trainable	torch.Size([3])
	reasoningnet.inter_layers.0.path_attention.end_attention.layers.0-Linear.weight	trainable	torch.Size([50, 768])
	reasoningnet.inter_layers.0.path_attention.end_attention.layers.0-Linear.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.0.path_attention.end_attention.layers.0-LayerNorm.weight	trainable	torch.Size([50])
	reasoningnet.inter_layers.0.path_attention.end_attention.layers.0-LayerNorm.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.0.path_attention.end_attention.layers.1-Linear.weight	trainable	torch.Size([3, 50])
	reasoningnet.inter_layers.0.path_attention.end_attention.layers.1-Linear.bias	trainable	torch.Size([3])
	reasoningnet.inter_layers.0.path_attention.path_uni_attention.layers.0-Linear.weight	trainable	torch.Size([50, 768])
	reasoningnet.inter_layers.0.path_attention.path_uni_attention.layers.0-Linear.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.0.path_attention.path_uni_attention.layers.0-LayerNorm.weight	trainable	torch.Size([50])
	reasoningnet.inter_layers.0.path_attention.path_uni_attention.layers.0-LayerNorm.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.0.path_attention.path_uni_attention.layers.1-Linear.weight	trainable	torch.Size([30, 50])
	reasoningnet.inter_layers.0.path_attention.path_uni_attention.layers.1-Linear.bias	trainable	torch.Size([30])
	reasoningnet.inter_layers.0.message_passing.w_vs	trainable	torch.Size([1, 100, 31])
	reasoningnet.inter_layers.0.aggregator.w_qs.weight	trainable	torch.Size([100, 768])
	reasoningnet.inter_layers.0.aggregator.w_qs.bias	trainable	torch.Size([100])
	reasoningnet.inter_layers.0.Vh.weight        	trainable	torch.Size([100, 100])
	reasoningnet.inter_layers.0.Vh.bias          	trainable	torch.Size([100])
	reasoningnet.inter_layers.0.Vz.weight        	trainable	torch.Size([100, 100])
	reasoningnet.inter_layers.0.Vz.bias          	trainable	torch.Size([100])
	reasoningnet.inter_layers.1.typed_transform.weight	trainable	torch.Size([300, 100])
	reasoningnet.inter_layers.1.typed_transform.bias	trainable	torch.Size([300])
	reasoningnet.inter_layers.1.path_attention.trans_scores	trainable	torch.Size([900])
	reasoningnet.inter_layers.1.path_attention.start_attention.layers.0-Linear.weight	trainable	torch.Size([50, 768])
	reasoningnet.inter_layers.1.path_attention.start_attention.layers.0-Linear.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.1.path_attention.start_attention.layers.0-LayerNorm.weight	trainable	torch.Size([50])
	reasoningnet.inter_layers.1.path_attention.start_attention.layers.0-LayerNorm.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.1.path_attention.start_attention.layers.1-Linear.weight	trainable	torch.Size([3, 50])
	reasoningnet.inter_layers.1.path_attention.start_attention.layers.1-Linear.bias	trainable	torch.Size([3])
	reasoningnet.inter_layers.1.path_attention.end_attention.layers.0-Linear.weight	trainable	torch.Size([50, 768])
	reasoningnet.inter_layers.1.path_attention.end_attention.layers.0-Linear.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.1.path_attention.end_attention.layers.0-LayerNorm.weight	trainable	torch.Size([50])
	reasoningnet.inter_layers.1.path_attention.end_attention.layers.0-LayerNorm.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.1.path_attention.end_attention.layers.1-Linear.weight	trainable	torch.Size([3, 50])
	reasoningnet.inter_layers.1.path_attention.end_attention.layers.1-Linear.bias	trainable	torch.Size([3])
	reasoningnet.inter_layers.1.path_attention.path_uni_attention.layers.0-Linear.weight	trainable	torch.Size([50, 768])
	reasoningnet.inter_layers.1.path_attention.path_uni_attention.layers.0-Linear.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.1.path_attention.path_uni_attention.layers.0-LayerNorm.weight	trainable	torch.Size([50])
	reasoningnet.inter_layers.1.path_attention.path_uni_attention.layers.0-LayerNorm.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.1.path_attention.path_uni_attention.layers.1-Linear.weight	trainable	torch.Size([30, 50])
	reasoningnet.inter_layers.1.path_attention.path_uni_attention.layers.1-Linear.bias	trainable	torch.Size([30])
	reasoningnet.inter_layers.1.message_passing.w_vs	trainable	torch.Size([1, 100, 31])
	reasoningnet.inter_layers.1.aggregator.w_qs.weight	trainable	torch.Size([100, 768])
	reasoningnet.inter_layers.1.aggregator.w_qs.bias	trainable	torch.Size([100])
	reasoningnet.inter_layers.1.Vh.weight        	trainable	torch.Size([100, 100])
	reasoningnet.inter_layers.1.Vh.bias          	trainable	torch.Size([100])
	reasoningnet.inter_layers.1.Vz.weight        	trainable	torch.Size([100, 100])
	reasoningnet.inter_layers.1.Vz.bias          	trainable	torch.Size([100])
	reasoningnet.inter_layers.2.typed_transform.weight	trainable	torch.Size([300, 100])
	reasoningnet.inter_layers.2.typed_transform.bias	trainable	torch.Size([300])
	reasoningnet.inter_layers.2.path_attention.trans_scores	trainable	torch.Size([900])
	reasoningnet.inter_layers.2.path_attention.start_attention.layers.0-Linear.weight	trainable	torch.Size([50, 768])
	reasoningnet.inter_layers.2.path_attention.start_attention.layers.0-Linear.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.2.path_attention.start_attention.layers.0-LayerNorm.weight	trainable	torch.Size([50])
	reasoningnet.inter_layers.2.path_attention.start_attention.layers.0-LayerNorm.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.2.path_attention.start_attention.layers.1-Linear.weight	trainable	torch.Size([3, 50])
	reasoningnet.inter_layers.2.path_attention.start_attention.layers.1-Linear.bias	trainable	torch.Size([3])
	reasoningnet.inter_layers.2.path_attention.end_attention.layers.0-Linear.weight	trainable	torch.Size([50, 768])
	reasoningnet.inter_layers.2.path_attention.end_attention.layers.0-Linear.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.2.path_attention.end_attention.layers.0-LayerNorm.weight	trainable	torch.Size([50])
	reasoningnet.inter_layers.2.path_attention.end_attention.layers.0-LayerNorm.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.2.path_attention.end_attention.layers.1-Linear.weight	trainable	torch.Size([3, 50])
	reasoningnet.inter_layers.2.path_attention.end_attention.layers.1-Linear.bias	trainable	torch.Size([3])
	reasoningnet.inter_layers.2.path_attention.path_uni_attention.layers.0-Linear.weight	trainable	torch.Size([50, 768])
	reasoningnet.inter_layers.2.path_attention.path_uni_attention.layers.0-Linear.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.2.path_attention.path_uni_attention.layers.0-LayerNorm.weight	trainable	torch.Size([50])
	reasoningnet.inter_layers.2.path_attention.path_uni_attention.layers.0-LayerNorm.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.2.path_attention.path_uni_attention.layers.1-Linear.weight	trainable	torch.Size([30, 50])
	reasoningnet.inter_layers.2.path_attention.path_uni_attention.layers.1-Linear.bias	trainable	torch.Size([30])
	reasoningnet.inter_layers.2.message_passing.w_vs	trainable	torch.Size([1, 100, 31])
	reasoningnet.inter_layers.2.aggregator.w_qs.weight	trainable	torch.Size([100, 768])
	reasoningnet.inter_layers.2.aggregator.w_qs.bias	trainable	torch.Size([100])
	reasoningnet.inter_layers.2.Vh.weight        	trainable	torch.Size([100, 100])
	reasoningnet.inter_layers.2.Vh.bias          	trainable	torch.Size([100])
	reasoningnet.inter_layers.2.Vz.weight        	trainable	torch.Size([100, 100])
	reasoningnet.inter_layers.2.Vz.bias          	trainable	torch.Size([100])
	reasoningnet.inter_layers.3.typed_transform.weight	trainable	torch.Size([300, 100])
	reasoningnet.inter_layers.3.typed_transform.bias	trainable	torch.Size([300])
	reasoningnet.inter_layers.3.path_attention.trans_scores	trainable	torch.Size([900])
	reasoningnet.inter_layers.3.path_attention.start_attention.layers.0-Linear.weight	trainable	torch.Size([50, 768])
	reasoningnet.inter_layers.3.path_attention.start_attention.layers.0-Linear.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.3.path_attention.start_attention.layers.0-LayerNorm.weight	trainable	torch.Size([50])
	reasoningnet.inter_layers.3.path_attention.start_attention.layers.0-LayerNorm.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.3.path_attention.start_attention.layers.1-Linear.weight	trainable	torch.Size([3, 50])
	reasoningnet.inter_layers.3.path_attention.start_attention.layers.1-Linear.bias	trainable	torch.Size([3])
	reasoningnet.inter_layers.3.path_attention.end_attention.layers.0-Linear.weight	trainable	torch.Size([50, 768])
	reasoningnet.inter_layers.3.path_attention.end_attention.layers.0-Linear.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.3.path_attention.end_attention.layers.0-LayerNorm.weight	trainable	torch.Size([50])
	reasoningnet.inter_layers.3.path_attention.end_attention.layers.0-LayerNorm.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.3.path_attention.end_attention.layers.1-Linear.weight	trainable	torch.Size([3, 50])
	reasoningnet.inter_layers.3.path_attention.end_attention.layers.1-Linear.bias	trainable	torch.Size([3])
	reasoningnet.inter_layers.3.path_attention.path_uni_attention.layers.0-Linear.weight	trainable	torch.Size([50, 768])
	reasoningnet.inter_layers.3.path_attention.path_uni_attention.layers.0-Linear.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.3.path_attention.path_uni_attention.layers.0-LayerNorm.weight	trainable	torch.Size([50])
	reasoningnet.inter_layers.3.path_attention.path_uni_attention.layers.0-LayerNorm.bias	trainable	torch.Size([50])
	reasoningnet.inter_layers.3.path_attention.path_uni_attention.layers.1-Linear.weight	trainable	torch.Size([30, 50])
	reasoningnet.inter_layers.3.path_attention.path_uni_attention.layers.1-Linear.bias	trainable	torch.Size([30])
	reasoningnet.inter_layers.3.message_passing.w_vs	trainable	torch.Size([1, 100, 31])
	reasoningnet.inter_layers.3.aggregator.w_qs.weight	trainable	torch.Size([100, 768])
	reasoningnet.inter_layers.3.aggregator.w_qs.bias	trainable	torch.Size([100])
	reasoningnet.inter_layers.3.Vh.weight        	trainable	torch.Size([100, 100])
	reasoningnet.inter_layers.3.Vh.bias          	trainable	torch.Size([100])
	reasoningnet.inter_layers.3.Vz.weight        	trainable	torch.Size([100, 100])
	reasoningnet.inter_layers.3.Vz.bias          	trainable	torch.Size([100])
	reasoningnet.intra_layers_interact.w_qs.weight	trainable	torch.Size([100, 768])
	reasoningnet.intra_layers_interact.w_qs.bias 	trainable	torch.Size([100])
	reasoningnet.intra_layers_interact.w_ks.weight	trainable	torch.Size([100, 100])
	reasoningnet.intra_layers_interact.w_ks.bias 	trainable	torch.Size([100])
	reasoningnet.intra_layers_interact.w_vs.weight	trainable	torch.Size([100, 100])
	reasoningnet.intra_layers_interact.w_vs.bias 	trainable	torch.Size([100])
	reasoningnet.intra_layers_feature.layers.0-Linear.weight	trainable	torch.Size([384, 768])
	reasoningnet.intra_layers_feature.layers.0-Linear.bias	trainable	torch.Size([384])
	reasoningnet.intra_layers_feature.layers.0-LayerNorm.weight	trainable	torch.Size([384])
	reasoningnet.intra_layers_feature.layers.0-LayerNorm.bias	trainable	torch.Size([384])
	reasoningnet.intra_layers_feature.layers.1-Linear.weight	trainable	torch.Size([768, 384])
	reasoningnet.intra_layers_feature.layers.1-Linear.bias	trainable	torch.Size([768])
	reasoningnet.linear.weight                   	trainable	torch.Size([100, 768])
	reasoningnet.linear.bias                     	trainable	torch.Size([100])
	reasoningnet.ln_layers.0.weight              	trainable	torch.Size([100, 100])
	reasoningnet.ln_layers.0.bias                	trainable	torch.Size([100])
	reasoningnet.ln_layers.1.weight              	trainable	torch.Size([100, 100])
	reasoningnet.ln_layers.1.bias                	trainable	torch.Size([100])
	reasoningnet.ln_layers.2.weight              	trainable	torch.Size([100, 100])
	reasoningnet.ln_layers.2.bias                	trainable	torch.Size([100])
	reasoningnet.ln_layers.3.weight              	trainable	torch.Size([100, 100])
	reasoningnet.ln_layers.3.bias                	trainable	torch.Size([100])
	pred_pooler.w_qs.weight                      	trainable	torch.Size([100, 768])
	pred_pooler.w_qs.bias                        	trainable	torch.Size([100])
	pred_pooler.w_ks.weight                      	trainable	torch.Size([100, 100])
	pred_pooler.w_ks.bias                        	trainable	torch.Size([100])
	pred_pooler.w_vs.weight                      	trainable	torch.Size([100, 100])
	pred_pooler.w_vs.bias                        	trainable	torch.Size([100])
	pred_fc.layers.0-Linear.weight               	trainable	torch.Size([1, 868])
	pred_fc.layers.0-Linear.bias                 	trainable	torch.Size([1])
	total: 1976557
-----------------------------------------------------------------------
/mnt/zm/DRLK/utils/optimization_utils.py:61: UserWarning: This overload of addcmul_ is deprecated:
	addcmul_(Number value, Tensor tensor1, Tensor tensor2)
Consider using one of the following signatures instead:
	addcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)
  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
/home/zm/IDE/anaconda3/envs/ekprn_latest/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
| step    19 |  lr: 0.0000500 | loss  1.4007 | ms/batch 6386.78 |
| step    39 |  lr: 0.0000500 | loss  1.3948 | ms/batch 6322.31 |
| step    59 |  lr: 0.0000500 | loss  1.3946 | ms/batch 6543.79 |
| step    79 |  lr: 0.0000500 | loss  1.3925 | ms/batch 6262.00 |
| step    99 |  lr: 0.0000500 | loss  1.3905 | ms/batch 6189.98 |
| step   119 |  lr: 0.0000500 | loss  1.3801 | ms/batch 6223.18 |
| step   139 |  lr: 0.0000500 | loss  1.3845 | ms/batch 6195.66 |
| step   159 |  lr: 0.0000500 | loss  1.3801 | ms/batch 6228.22 |
| step   179 |  lr: 0.0000500 | loss  1.3781 | ms/batch 6057.92 |
| step   199 |  lr: 0.0000500 | loss  1.3708 | ms/batch 6093.03 |
| step   219 |  lr: 0.0000500 | loss  1.3657 | ms/batch 6069.49 |
| step   239 |  lr: 0.0000500 | loss  1.3595 | ms/batch 5952.19 |
| step   259 |  lr: 0.0000500 | loss  1.3522 | ms/batch 6239.07 |
| step   279 |  lr: 0.0000500 | loss  1.3435 | ms/batch 6427.45 |
| step   299 |  lr: 0.0000500 | loss  1.3488 | ms/batch 6543.77 |
| step   319 |  lr: 0.0000500 | loss  1.3376 | ms/batch 6670.43 |
| step   339 |  lr: 0.0000500 | loss  1.3185 | ms/batch 6413.76 |
| step   359 |  lr: 0.0000500 | loss  1.3495 | ms/batch 6433.30 |
| step   379 |  lr: 0.0000500 | loss  1.3367 | ms/batch 6356.55 |
| step   399 |  lr: 0.0000500 | loss  1.3225 | ms/batch 6513.77 |
| step   419 |  lr: 0.0000500 | loss  1.3167 | ms/batch 6465.36 |
| step   439 |  lr: 0.0000500 | loss  1.3093 | ms/batch 6779.65 |
| step   459 |  lr: 0.0000500 | loss  1.3118 | ms/batch 6226.93 |
| step   479 |  lr: 0.0000500 | loss  1.2996 | ms/batch 6155.63 |
| step   499 |  lr: 0.0000500 | loss  1.3118 | ms/batch 6023.14 |
| step   519 |  lr: 0.0000500 | loss  1.3179 | ms/batch 6378.44 |
| step   539 |  lr: 0.0000500 | loss  1.2903 | ms/batch 6353.31 |
| step   559 |  lr: 0.0000500 | loss  1.3014 | ms/batch 6540.76 |
| step   579 |  lr: 0.0000500 | loss  1.3079 | ms/batch 6352.10 |
| step   599 |  lr: 0.0000500 | loss  1.2966 | ms/batch 6515.32 |
| step   619 |  lr: 0.0000500 | loss  1.2982 | ms/batch 6463.87 |
| step   639 |  lr: 0.0000500 | loss  1.2962 | ms/batch 6521.68 |
| step   659 |  lr: 0.0000500 | loss  1.2905 | ms/batch 6340.42 |
| step   679 |  lr: 0.0000500 | loss  1.2831 | ms/batch 6548.31 |
| step   699 |  lr: 0.0000500 | loss  1.3056 | ms/batch 6139.61 |
| step   719 |  lr: 0.0000500 | loss  1.2779 | ms/batch 6280.18 |
| step   739 |  lr: 0.0000500 | loss  1.2830 | ms/batch 6331.67 |
| step   759 |  lr: 0.0000500 | loss  1.2647 | ms/batch 6186.85 |
| step   779 |  lr: 0.0000500 | loss  1.2858 | ms/batch 6274.58 |
| step   799 |  lr: 0.0000500 | loss  1.2659 | ms/batch 6266.13 |
| step   819 |  lr: 0.0000500 | loss  1.2607 | ms/batch 6256.48 |
| step   839 |  lr: 0.0000500 | loss  1.2660 | ms/batch 6228.05 |
| step   859 |  lr: 0.0000500 | loss  1.2723 | ms/batch 6442.03 |
| step   879 |  lr: 0.0000500 | loss  1.2615 | ms/batch 6477.74 |
| step   899 |  lr: 0.0000500 | loss  1.2381 | ms/batch 6269.23 |
| step   919 |  lr: 0.0000500 | loss  1.2547 | ms/batch 6441.58 |
| step   939 |  lr: 0.0000500 | loss  1.2591 | ms/batch 6415.28 |
| step   959 |  lr: 0.0000500 | loss  1.2650 | ms/batch 6448.01 |
| step   979 |  lr: 0.0000500 | loss  1.2379 | ms/batch 6393.02 |
| step   999 |  lr: 0.0000500 | loss  1.2416 | ms/batch 6243.64 |
| step  1019 |  lr: 0.0000500 | loss  1.2442 | ms/batch 6421.50 |
| step  1039 |  lr: 0.0000500 | loss  1.2444 | ms/batch 6248.49 |
| step  1059 |  lr: 0.0000500 | loss  1.2418 | ms/batch 6217.75 |
| step  1079 |  lr: 0.0000500 | loss  1.2257 | ms/batch 6088.44 |
| step  1099 |  lr: 0.0000500 | loss  1.2474 | ms/batch 6039.45 |
| step  1119 |  lr: 0.0000500 | loss  1.2175 | ms/batch 6243.17 |
| step  1139 |  lr: 0.0000500 | loss  1.2303 | ms/batch 6123.74 |
| step  1159 |  lr: 0.0000500 | loss  1.2421 | ms/batch 6017.12 |
| step  1179 |  lr: 0.0000500 | loss  1.2175 | ms/batch 5976.72 |
| step  1199 |  lr: 0.0000500 | loss  1.2313 | ms/batch 6054.12 |
| step  1219 |  lr: 0.0000500 | loss  1.2345 | ms/batch 6228.29 |
| step  1239 |  lr: 0.0000500 | loss  1.2252 | ms/batch 6699.64 |
| step  1259 |  lr: 0.0000500 | loss  1.2237 | ms/batch 6415.66 |
| step  1279 |  lr: 0.0000500 | loss  1.2258 | ms/batch 6611.62 |
| step  1299 |  lr: 0.0000500 | loss  1.1988 | ms/batch 6565.31 |
| step  1319 |  lr: 0.0000500 | loss  1.2121 | ms/batch 6404.07 |
| step  1339 |  lr: 0.0000500 | loss  1.1905 | ms/batch 6435.80 |
| step  1359 |  lr: 0.0000500 | loss  1.2204 | ms/batch 6500.69 |
| step  1379 |  lr: 0.0000500 | loss  1.1970 | ms/batch 6506.86 |
| step  1399 |  lr: 0.0000500 | loss  1.2206 | ms/batch 6519.56 |
| step  1419 |  lr: 0.0000500 | loss  1.2117 | ms/batch 6461.10 |
-----------------------------------------------------------------------
| step  1429 | dev_acc  0.4007 | test_acc  0.2571 |
train_time : 9048.24 | eval_time : 97.75
-----------------------------------------------------------------------
model saved to ./saved_models/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/medmcqa_best.pt
| step  1439 |  lr: 0.0000500 | loss  1.1693 | ms/batch 3462.08 |
| step  1459 |  lr: 0.0000500 | loss  1.1299 | ms/batch 6312.16 |
| step  1479 |  lr: 0.0000500 | loss  1.1204 | ms/batch 6377.83 |
| step  1499 |  lr: 0.0000500 | loss  1.0903 | ms/batch 6188.54 |
| step  1519 |  lr: 0.0000500 | loss  1.0815 | ms/batch 6169.48 |
| step  1539 |  lr: 0.0000500 | loss  1.1006 | ms/batch 6188.39 |
| step  1559 |  lr: 0.0000500 | loss  1.1278 | ms/batch 6211.69 |
| step  1579 |  lr: 0.0000500 | loss  1.0964 | ms/batch 6173.86 |
| step  1599 |  lr: 0.0000500 | loss  1.0979 | ms/batch 6096.49 |
| step  1619 |  lr: 0.0000500 | loss  1.1326 | ms/batch 6249.09 |
| step  1639 |  lr: 0.0000500 | loss  1.1210 | ms/batch 6172.70 |
| step  1659 |  lr: 0.0000500 | loss  1.1029 | ms/batch 6315.77 |
| step  1679 |  lr: 0.0000500 | loss  1.1052 | ms/batch 6261.51 |
| step  1699 |  lr: 0.0000500 | loss  1.0985 | ms/batch 6246.62 |
| step  1719 |  lr: 0.0000500 | loss  1.1097 | ms/batch 6141.75 |
| step  1739 |  lr: 0.0000500 | loss  1.0890 | ms/batch 6177.03 |
| step  1759 |  lr: 0.0000500 | loss  1.1022 | ms/batch 6151.46 |
| step  1779 |  lr: 0.0000500 | loss  1.0846 | ms/batch 6267.17 |
| step  1799 |  lr: 0.0000500 | loss  1.0805 | ms/batch 6513.63 |
| step  1819 |  lr: 0.0000500 | loss  1.0676 | ms/batch 6644.83 |
| step  1839 |  lr: 0.0000500 | loss  1.1167 | ms/batch 6614.31 |
| step  1859 |  lr: 0.0000500 | loss  1.0917 | ms/batch 6502.25 |
| step  1879 |  lr: 0.0000500 | loss  1.0846 | ms/batch 6392.69 |
| step  1899 |  lr: 0.0000500 | loss  1.0683 | ms/batch 6137.28 |
| step  1919 |  lr: 0.0000500 | loss  1.0816 | ms/batch 6372.71 |
| step  1939 |  lr: 0.0000500 | loss  1.0837 | ms/batch 6075.18 |
| step  1959 |  lr: 0.0000500 | loss  1.0402 | ms/batch 6131.78 |
| step  1979 |  lr: 0.0000500 | loss  1.0796 | ms/batch 6514.19 |
| step  1999 |  lr: 0.0000500 | loss  1.0792 | ms/batch 6310.39 |
| step  2019 |  lr: 0.0000500 | loss  1.0723 | ms/batch 6606.39 |
| step  2039 |  lr: 0.0000500 | loss  1.0541 | ms/batch 6453.66 |
| step  2059 |  lr: 0.0000500 | loss  1.0803 | ms/batch 6489.95 |
| step  2079 |  lr: 0.0000500 | loss  1.0507 | ms/batch 6386.73 |
| step  2099 |  lr: 0.0000500 | loss  1.0631 | ms/batch 6423.23 |
| step  2119 |  lr: 0.0000500 | loss  1.0693 | ms/batch 6453.41 |
| step  2139 |  lr: 0.0000500 | loss  1.0615 | ms/batch 6500.10 |
| step  2159 |  lr: 0.0000500 | loss  1.0593 | ms/batch 6282.30 |
| step  2179 |  lr: 0.0000500 | loss  1.0638 | ms/batch 5976.22 |
| step  2199 |  lr: 0.0000500 | loss  1.0577 | ms/batch 6143.55 |
| step  2219 |  lr: 0.0000500 | loss  1.0703 | ms/batch 6232.19 |
| step  2239 |  lr: 0.0000500 | loss  1.0703 | ms/batch 5960.85 |
| step  2259 |  lr: 0.0000500 | loss  1.0482 | ms/batch 6230.00 |
| step  2279 |  lr: 0.0000500 | loss  1.0371 | ms/batch 6156.21 |
| step  2299 |  lr: 0.0000500 | loss  1.0679 | ms/batch 5886.88 |
| step  2319 |  lr: 0.0000500 | loss  1.0449 | ms/batch 5949.11 |
| step  2339 |  lr: 0.0000500 | loss  1.0413 | ms/batch 6125.40 |
| step  2359 |  lr: 0.0000500 | loss  1.0440 | ms/batch 6559.50 |
| step  2379 |  lr: 0.0000500 | loss  1.0436 | ms/batch 6493.15 |
| step  2399 |  lr: 0.0000500 | loss  1.0552 | ms/batch 6452.77 |
| step  2419 |  lr: 0.0000500 | loss  1.0271 | ms/batch 6510.77 |
| step  2439 |  lr: 0.0000500 | loss  1.0773 | ms/batch 6379.08 |
| step  2459 |  lr: 0.0000500 | loss  1.0270 | ms/batch 6290.08 |
| step  2479 |  lr: 0.0000500 | loss  1.0527 | ms/batch 6286.14 |
| step  2499 |  lr: 0.0000500 | loss  1.0339 | ms/batch 6174.02 |
| step  2519 |  lr: 0.0000500 | loss  1.0454 | ms/batch 6582.90 |
| step  2539 |  lr: 0.0000500 | loss  1.0540 | ms/batch 6331.62 |
| step  2559 |  lr: 0.0000500 | loss  1.0299 | ms/batch 6217.07 |
| step  2579 |  lr: 0.0000500 | loss  1.0185 | ms/batch 6352.95 |
| step  2599 |  lr: 0.0000500 | loss  1.0220 | ms/batch 6326.64 |
| step  2619 |  lr: 0.0000500 | loss  1.0242 | ms/batch 6120.81 |
| step  2639 |  lr: 0.0000500 | loss  1.0363 | ms/batch 6015.11 |
| step  2659 |  lr: 0.0000500 | loss  1.0099 | ms/batch 6221.13 |
| step  2679 |  lr: 0.0000500 | loss  1.0591 | ms/batch 6021.65 |
| step  2699 |  lr: 0.0000500 | loss  1.0268 | ms/batch 6160.49 |
| step  2719 |  lr: 0.0000500 | loss  1.0279 | ms/batch 6100.24 |
| step  2739 |  lr: 0.0000500 | loss  1.0198 | ms/batch 6023.26 |
| step  2759 |  lr: 0.0000500 | loss  1.0143 | ms/batch 6179.72 |
| step  2779 |  lr: 0.0000500 | loss  1.0297 | ms/batch 6054.68 |
| step  2799 |  lr: 0.0000500 | loss  1.0138 | ms/batch 6189.33 |
| step  2819 |  lr: 0.0000500 | loss  0.9957 | ms/batch 6420.41 |
| step  2839 |  lr: 0.0000500 | loss  0.9963 | ms/batch 6425.27 |
-----------------------------------------------------------------------
| step  2858 | dev_acc  0.4231 | test_acc  0.2689 |
train_time : 8957.56 | eval_time : 101.81
-----------------------------------------------------------------------
model saved to ./saved_models/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/medmcqa_best.pt
| step  2859 |  lr: 0.0000500 | loss  1.0121 | ms/batch  659.51 |
| step  2879 |  lr: 0.0000500 | loss  0.8316 | ms/batch 6654.04 |
| step  2899 |  lr: 0.0000500 | loss  0.8568 | ms/batch 6367.46 |
| step  2919 |  lr: 0.0000500 | loss  0.8346 | ms/batch 6130.24 |
| step  2939 |  lr: 0.0000500 | loss  0.8216 | ms/batch 6275.07 |
| step  2959 |  lr: 0.0000500 | loss  0.8397 | ms/batch 6262.34 |
| step  2979 |  lr: 0.0000500 | loss  0.8278 | ms/batch 6348.49 |
| step  2999 |  lr: 0.0000500 | loss  0.8170 | ms/batch 6235.13 |
| step  3019 |  lr: 0.0000500 | loss  0.8756 | ms/batch 6532.73 |
| step  3039 |  lr: 0.0000500 | loss  0.8411 | ms/batch 6510.79 |
| step  3059 |  lr: 0.0000500 | loss  0.8553 | ms/batch 6481.03 |
| step  3079 |  lr: 0.0000500 | loss  0.8222 | ms/batch 6435.23 |
| step  3099 |  lr: 0.0000500 | loss  0.8318 | ms/batch 6378.12 |
| step  3119 |  lr: 0.0000500 | loss  0.8274 | ms/batch 6382.41 |
| step  3139 |  lr: 0.0000500 | loss  0.8285 | ms/batch 6561.76 |
| step  3159 |  lr: 0.0000500 | loss  0.8548 | ms/batch 6403.44 |
| step  3179 |  lr: 0.0000500 | loss  0.8431 | ms/batch 6332.40 |
| step  3199 |  lr: 0.0000500 | loss  0.8543 | ms/batch 6366.31 |
| step  3219 |  lr: 0.0000500 | loss  0.8370 | ms/batch 6395.48 |
| step  3239 |  lr: 0.0000500 | loss  0.8438 | ms/batch 6285.03 |
| step  3259 |  lr: 0.0000500 | loss  0.8580 | ms/batch 6293.03 |
| step  3279 |  lr: 0.0000500 | loss  0.8379 | ms/batch 6280.17 |
| step  3299 |  lr: 0.0000500 | loss  0.8533 | ms/batch 6029.34 |
| step  3319 |  lr: 0.0000500 | loss  0.8430 | ms/batch 6140.98 |
| step  3339 |  lr: 0.0000500 | loss  0.8319 | ms/batch 6080.04 |
| step  3359 |  lr: 0.0000500 | loss  0.8510 | ms/batch 6135.10 |
| step  3379 |  lr: 0.0000500 | loss  0.8399 | ms/batch 6180.16 |
| step  3399 |  lr: 0.0000500 | loss  0.8539 | ms/batch 6486.92 |
| step  3419 |  lr: 0.0000500 | loss  0.8320 | ms/batch 6570.32 |
| step  3439 |  lr: 0.0000500 | loss  0.8317 | ms/batch 6092.91 |
| step  3459 |  lr: 0.0000500 | loss  0.8376 | ms/batch 6120.93 |
| step  3479 |  lr: 0.0000500 | loss  0.8133 | ms/batch 6429.95 |
| step  3499 |  lr: 0.0000500 | loss  0.8428 | ms/batch 6053.56 |
| step  3519 |  lr: 0.0000500 | loss  0.8338 | ms/batch 6206.78 |
| step  3539 |  lr: 0.0000500 | loss  0.8253 | ms/batch 6154.82 |
| step  3559 |  lr: 0.0000500 | loss  0.8136 | ms/batch 6194.68 |
| step  3579 |  lr: 0.0000500 | loss  0.8058 | ms/batch 6132.10 |
| step  3599 |  lr: 0.0000500 | loss  0.8573 | ms/batch 6043.85 |
| step  3619 |  lr: 0.0000500 | loss  0.8456 | ms/batch 6185.63 |
| step  3639 |  lr: 0.0000500 | loss  0.8356 | ms/batch 6189.72 |
| step  3659 |  lr: 0.0000500 | loss  0.8313 | ms/batch 6126.83 |
| step  3679 |  lr: 0.0000500 | loss  0.8254 | ms/batch 6164.01 |
| step  3699 |  lr: 0.0000500 | loss  0.8305 | ms/batch 6085.83 |
| step  3719 |  lr: 0.0000500 | loss  0.8213 | ms/batch 6238.90 |
| step  3739 |  lr: 0.0000500 | loss  0.8150 | ms/batch 6276.18 |
| step  3759 |  lr: 0.0000500 | loss  0.8054 | ms/batch 6121.25 |
| step  3779 |  lr: 0.0000500 | loss  0.8412 | ms/batch 6376.35 |
| step  3799 |  lr: 0.0000500 | loss  0.8373 | ms/batch 6542.80 |
| step  3819 |  lr: 0.0000500 | loss  0.8652 | ms/batch 6547.84 |
| step  3839 |  lr: 0.0000500 | loss  0.8190 | ms/batch 6388.32 |
| step  3859 |  lr: 0.0000500 | loss  0.8479 | ms/batch 6211.38 |
| step  3879 |  lr: 0.0000500 | loss  0.8069 | ms/batch 6571.30 |
| step  3899 |  lr: 0.0000500 | loss  0.8166 | ms/batch 6620.01 |
| step  3919 |  lr: 0.0000500 | loss  0.8243 | ms/batch 6266.90 |
| step  3939 |  lr: 0.0000500 | loss  0.8220 | ms/batch 6436.05 |
| step  3959 |  lr: 0.0000500 | loss  0.8420 | ms/batch 6493.10 |
| step  3979 |  lr: 0.0000500 | loss  0.8391 | ms/batch 6611.89 |
| step  3999 |  lr: 0.0000500 | loss  0.7966 | ms/batch 6499.48 |
| step  4019 |  lr: 0.0000500 | loss  0.8022 | ms/batch 6359.60 |
| step  4039 |  lr: 0.0000500 | loss  0.8201 | ms/batch 6390.30 |
| step  4059 |  lr: 0.0000500 | loss  0.8335 | ms/batch 6258.72 |
| step  4079 |  lr: 0.0000500 | loss  0.8411 | ms/batch 5982.71 |
| step  4099 |  lr: 0.0000500 | loss  0.8527 | ms/batch 6095.91 |
| step  4119 |  lr: 0.0000500 | loss  0.7845 | ms/batch 6151.96 |
| step  4139 |  lr: 0.0000500 | loss  0.8182 | ms/batch 6119.48 |
| step  4159 |  lr: 0.0000500 | loss  0.8270 | ms/batch 6042.91 |
| step  4179 |  lr: 0.0000500 | loss  0.8380 | ms/batch 6190.32 |
| step  4199 |  lr: 0.0000500 | loss  0.8189 | ms/batch 6244.06 |
| step  4219 |  lr: 0.0000500 | loss  0.7910 | ms/batch 6178.48 |
| step  4239 |  lr: 0.0000500 | loss  0.7934 | ms/batch 6275.94 |
| step  4259 |  lr: 0.0000500 | loss  0.8178 | ms/batch 6462.52 |
| step  4279 |  lr: 0.0000500 | loss  0.8292 | ms/batch 6525.22 |
-----------------------------------------------------------------------
| step  4287 | dev_acc  0.4490 | test_acc  0.2793 |
train_time : 8997.13 | eval_time : 98.58
-----------------------------------------------------------------------
model saved to ./saved_models/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/medmcqa_best.pt
| step  4299 |  lr: 0.0000500 | loss  0.7013 | ms/batch 4255.69 |
| step  4319 |  lr: 0.0000500 | loss  0.6157 | ms/batch 6137.14 |
| step  4339 |  lr: 0.0000500 | loss  0.6123 | ms/batch 6097.95 |
| step  4359 |  lr: 0.0000500 | loss  0.6055 | ms/batch 6267.90 |
| step  4379 |  lr: 0.0000500 | loss  0.6056 | ms/batch 6021.80 |
| step  4399 |  lr: 0.0000500 | loss  0.6186 | ms/batch 6010.65 |
| step  4419 |  lr: 0.0000500 | loss  0.6364 | ms/batch 6246.80 |
| step  4439 |  lr: 0.0000500 | loss  0.6392 | ms/batch 6481.07 |
| step  4459 |  lr: 0.0000500 | loss  0.6073 | ms/batch 6316.14 |
| step  4479 |  lr: 0.0000500 | loss  0.6320 | ms/batch 6536.97 |
| step  4499 |  lr: 0.0000500 | loss  0.6368 | ms/batch 6513.71 |
| step  4519 |  lr: 0.0000500 | loss  0.6036 | ms/batch 6332.33 |
| step  4539 |  lr: 0.0000500 | loss  0.6476 | ms/batch 6218.49 |
| step  4559 |  lr: 0.0000500 | loss  0.6273 | ms/batch 6054.37 |
| step  4579 |  lr: 0.0000500 | loss  0.6407 | ms/batch 5994.87 |
| step  4599 |  lr: 0.0000500 | loss  0.6458 | ms/batch 6048.15 |
| step  4619 |  lr: 0.0000500 | loss  0.6352 | ms/batch 6334.92 |
| step  4639 |  lr: 0.0000500 | loss  0.6348 | ms/batch 6263.72 |
| step  4659 |  lr: 0.0000500 | loss  0.6317 | ms/batch 6173.45 |
| step  4679 |  lr: 0.0000500 | loss  0.6556 | ms/batch 6410.17 |
| step  4699 |  lr: 0.0000500 | loss  0.6597 | ms/batch 6359.94 |
| step  4719 |  lr: 0.0000500 | loss  0.6427 | ms/batch 6491.20 |
| step  4739 |  lr: 0.0000500 | loss  0.6132 | ms/batch 6444.73 |
| step  4759 |  lr: 0.0000500 | loss  0.6364 | ms/batch 6396.34 |
| step  4779 |  lr: 0.0000500 | loss  0.6305 | ms/batch 6352.60 |
| step  4799 |  lr: 0.0000500 | loss  0.6151 | ms/batch 6113.61 |
| step  4819 |  lr: 0.0000500 | loss  0.6346 | ms/batch 6373.46 |
| step  4839 |  lr: 0.0000500 | loss  0.6552 | ms/batch 6357.65 |
| step  4859 |  lr: 0.0000500 | loss  0.6725 | ms/batch 6166.41 |
| step  4879 |  lr: 0.0000500 | loss  0.6338 | ms/batch 6205.42 |
| step  4899 |  lr: 0.0000500 | loss  0.6504 | ms/batch 6655.16 |
| step  4919 |  lr: 0.0000500 | loss  0.6473 | ms/batch 6427.93 |
| step  4939 |  lr: 0.0000500 | loss  0.6300 | ms/batch 6343.50 |
| step  4959 |  lr: 0.0000500 | loss  0.6395 | ms/batch 6408.48 |
| step  4979 |  lr: 0.0000500 | loss  0.6681 | ms/batch 6432.89 |
| step  4999 |  lr: 0.0000500 | loss  0.6259 | ms/batch 6125.16 |
| step  5019 |  lr: 0.0000500 | loss  0.6403 | ms/batch 6093.41 |
| step  5039 |  lr: 0.0000500 | loss  0.6390 | ms/batch 6249.98 |
| step  5059 |  lr: 0.0000500 | loss  0.6542 | ms/batch 6320.62 |
| step  5079 |  lr: 0.0000500 | loss  0.6553 | ms/batch 6538.99 |
| step  5099 |  lr: 0.0000500 | loss  0.6442 | ms/batch 6410.69 |
| step  5119 |  lr: 0.0000500 | loss  0.6663 | ms/batch 6279.05 |
| step  5139 |  lr: 0.0000500 | loss  0.6401 | ms/batch 6672.50 |
| step  5159 |  lr: 0.0000500 | loss  0.6691 | ms/batch 6537.59 |
| step  5179 |  lr: 0.0000500 | loss  0.6370 | ms/batch 6527.99 |
| step  5199 |  lr: 0.0000500 | loss  0.6629 | ms/batch 6518.76 |
| step  5219 |  lr: 0.0000500 | loss  0.6546 | ms/batch 6308.18 |
| step  5239 |  lr: 0.0000500 | loss  0.6493 | ms/batch 6556.15 |
| step  5259 |  lr: 0.0000500 | loss  0.6566 | ms/batch 6740.63 |
| step  5279 |  lr: 0.0000500 | loss  0.6427 | ms/batch 6452.40 |
| step  5299 |  lr: 0.0000500 | loss  0.6380 | ms/batch 6418.44 |
| step  5319 |  lr: 0.0000500 | loss  0.6498 | ms/batch 6559.83 |
| step  5339 |  lr: 0.0000500 | loss  0.6699 | ms/batch 6463.60 |
| step  5359 |  lr: 0.0000500 | loss  0.6213 | ms/batch 6200.26 |
| step  5379 |  lr: 0.0000500 | loss  0.6598 | ms/batch 6166.21 |
| step  5399 |  lr: 0.0000500 | loss  0.6516 | ms/batch 6245.56 |
| step  5419 |  lr: 0.0000500 | loss  0.6498 | ms/batch 6177.81 |
| step  5439 |  lr: 0.0000500 | loss  0.6709 | ms/batch 6200.59 |
| step  5459 |  lr: 0.0000500 | loss  0.6493 | ms/batch 6563.78 |
| step  5479 |  lr: 0.0000500 | loss  0.6377 | ms/batch 6350.84 |
| step  5499 |  lr: 0.0000500 | loss  0.6147 | ms/batch 6369.03 |
| step  5519 |  lr: 0.0000500 | loss  0.6778 | ms/batch 6593.42 |
| step  5539 |  lr: 0.0000500 | loss  0.6348 | ms/batch 6450.15 |
| step  5559 |  lr: 0.0000500 | loss  0.6478 | ms/batch 6197.93 |
| step  5579 |  lr: 0.0000500 | loss  0.6448 | ms/batch 6153.74 |
| step  5599 |  lr: 0.0000500 | loss  0.6536 | ms/batch 6179.02 |
| step  5619 |  lr: 0.0000500 | loss  0.6264 | ms/batch 6140.39 |
| step  5639 |  lr: 0.0000500 | loss  0.6412 | ms/batch 6245.91 |
| step  5659 |  lr: 0.0000500 | loss  0.6561 | ms/batch 6271.86 |
| step  5679 |  lr: 0.0000500 | loss  0.6411 | ms/batch 6174.19 |
| step  5699 |  lr: 0.0000500 | loss  0.6605 | ms/batch 6065.47 |
-----------------------------------------------------------------------
| step  5716 | dev_acc  0.4729 | test_acc  0.2792 |
train_time : 9027.30 | eval_time : 97.67
-----------------------------------------------------------------------
model saved to ./saved_models/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/medmcqa_best.pt
| step  5719 |  lr: 0.0000500 | loss  0.6103 | ms/batch 1248.26 |
| step  5739 |  lr: 0.0000500 | loss  0.4792 | ms/batch 6218.72 |
| step  5759 |  lr: 0.0000500 | loss  0.4716 | ms/batch 6178.97 |
| step  5779 |  lr: 0.0000500 | loss  0.4550 | ms/batch 5986.15 |
| step  5799 |  lr: 0.0000500 | loss  0.4667 | ms/batch 6053.90 |
| step  5819 |  lr: 0.0000500 | loss  0.4569 | ms/batch 6076.62 |
| step  5839 |  lr: 0.0000500 | loss  0.4566 | ms/batch 6375.70 |
| step  5859 |  lr: 0.0000500 | loss  0.4779 | ms/batch 6486.48 |
| step  5879 |  lr: 0.0000500 | loss  0.4907 | ms/batch 6321.01 |
| step  5899 |  lr: 0.0000500 | loss  0.4583 | ms/batch 6334.04 |
| step  5919 |  lr: 0.0000500 | loss  0.4738 | ms/batch 6119.52 |
| step  5939 |  lr: 0.0000500 | loss  0.4768 | ms/batch 6022.73 |
| step  5959 |  lr: 0.0000500 | loss  0.4900 | ms/batch 6215.43 |
| step  5979 |  lr: 0.0000500 | loss  0.4767 | ms/batch 6293.83 |
| step  5999 |  lr: 0.0000500 | loss  0.4864 | ms/batch 6207.53 |
| step  6019 |  lr: 0.0000500 | loss  0.4832 | ms/batch 6310.42 |
| step  6039 |  lr: 0.0000500 | loss  0.4639 | ms/batch 6212.23 |
| step  6059 |  lr: 0.0000500 | loss  0.4866 | ms/batch 6422.59 |
| step  6079 |  lr: 0.0000500 | loss  0.4967 | ms/batch 6244.16 |
| step  6099 |  lr: 0.0000500 | loss  0.4953 | ms/batch 6482.26 |
| step  6119 |  lr: 0.0000500 | loss  0.4756 | ms/batch 6121.84 |
| step  6139 |  lr: 0.0000500 | loss  0.4902 | ms/batch 6285.70 |
| step  6159 |  lr: 0.0000500 | loss  0.4700 | ms/batch 6213.25 |
| step  6179 |  lr: 0.0000500 | loss  0.4807 | ms/batch 6187.93 |
| step  6199 |  lr: 0.0000500 | loss  0.4783 | ms/batch 6242.19 |
| step  6219 |  lr: 0.0000500 | loss  0.4937 | ms/batch 6116.19 |
| step  6239 |  lr: 0.0000500 | loss  0.5025 | ms/batch 6065.79 |
| step  6259 |  lr: 0.0000500 | loss  0.5329 | ms/batch 6187.20 |
| step  6279 |  lr: 0.0000500 | loss  0.5096 | ms/batch 6326.82 |
| step  6299 |  lr: 0.0000500 | loss  0.4944 | ms/batch 6359.33 |
| step  6319 |  lr: 0.0000500 | loss  0.4939 | ms/batch 6475.44 |
| step  6339 |  lr: 0.0000500 | loss  0.5070 | ms/batch 6352.33 |
| step  6359 |  lr: 0.0000500 | loss  0.4981 | ms/batch 6245.42 |
| step  6379 |  lr: 0.0000500 | loss  0.5074 | ms/batch 6211.57 |
| step  6399 |  lr: 0.0000500 | loss  0.4794 | ms/batch 6102.13 |
| step  6419 |  lr: 0.0000500 | loss  0.4923 | ms/batch 6293.14 |
| step  6439 |  lr: 0.0000500 | loss  0.5078 | ms/batch 6422.06 |
| step  6459 |  lr: 0.0000500 | loss  0.5051 | ms/batch 6324.13 |
| step  6479 |  lr: 0.0000500 | loss  0.5046 | ms/batch 6349.16 |
| step  6499 |  lr: 0.0000500 | loss  0.4970 | ms/batch 6384.03 |
| step  6519 |  lr: 0.0000500 | loss  0.5133 | ms/batch 6038.15 |
| step  6539 |  lr: 0.0000500 | loss  0.4883 | ms/batch 6102.82 |
| step  6559 |  lr: 0.0000500 | loss  0.4887 | ms/batch 6314.13 |
| step  6579 |  lr: 0.0000500 | loss  0.5242 | ms/batch 6071.46 |
| step  6599 |  lr: 0.0000500 | loss  0.5103 | ms/batch 6270.40 |
| step  6619 |  lr: 0.0000500 | loss  0.5125 | ms/batch 6334.13 |
| step  6639 |  lr: 0.0000500 | loss  0.5004 | ms/batch 6045.24 |
| step  6659 |  lr: 0.0000500 | loss  0.5113 | ms/batch 6334.98 |
| step  6679 |  lr: 0.0000500 | loss  0.4813 | ms/batch 6471.85 |
| step  6699 |  lr: 0.0000500 | loss  0.5058 | ms/batch 6280.29 |
| step  6719 |  lr: 0.0000500 | loss  0.4857 | ms/batch 6590.12 |
| step  6739 |  lr: 0.0000500 | loss  0.4869 | ms/batch 6424.56 |
| step  6759 |  lr: 0.0000500 | loss  0.5123 | ms/batch 6349.72 |
| step  6779 |  lr: 0.0000500 | loss  0.4920 | ms/batch 6309.63 |
| step  6799 |  lr: 0.0000500 | loss  0.5173 | ms/batch 6153.17 |
| step  6819 |  lr: 0.0000500 | loss  0.5038 | ms/batch 6314.52 |
| step  6839 |  lr: 0.0000500 | loss  0.5001 | ms/batch 6294.69 |
| step  6859 |  lr: 0.0000500 | loss  0.5404 | ms/batch 6198.05 |
| step  6879 |  lr: 0.0000500 | loss  0.4838 | ms/batch 6043.01 |
| step  6899 |  lr: 0.0000500 | loss  0.5105 | ms/batch 6111.13 |
| step  6919 |  lr: 0.0000500 | loss  0.4879 | ms/batch 6044.59 |
| step  6939 |  lr: 0.0000500 | loss  0.5140 | ms/batch 6309.55 |
| step  6959 |  lr: 0.0000500 | loss  0.4918 | ms/batch 6281.90 |
| step  6979 |  lr: 0.0000500 | loss  0.4906 | ms/batch 6393.06 |
| step  6999 |  lr: 0.0000500 | loss  0.5018 | ms/batch 6284.36 |
| step  7019 |  lr: 0.0000500 | loss  0.5107 | ms/batch 6336.45 |
| step  7039 |  lr: 0.0000500 | loss  0.5290 | ms/batch 6043.84 |
| step  7059 |  lr: 0.0000500 | loss  0.4928 | ms/batch 6210.52 |
| step  7079 |  lr: 0.0000500 | loss  0.5068 | ms/batch 5775.88 |
| step  7099 |  lr: 0.0000500 | loss  0.4920 | ms/batch 5387.79 |
| step  7119 |  lr: 0.0000500 | loss  0.5209 | ms/batch 5356.13 |
| step  7139 |  lr: 0.0000500 | loss  0.5241 | ms/batch 5288.96 |
-----------------------------------------------------------------------
| step  7145 | dev_acc  0.4745 | test_acc  0.2722 |
train_time : 8859.90 | eval_time : 97.82
-----------------------------------------------------------------------
model saved to ./saved_models/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/medmcqa_best.pt
| step  7159 |  lr: 0.0000500 | loss  0.4083 | ms/batch 4775.09 |
| step  7179 |  lr: 0.0000500 | loss  0.3700 | ms/batch 6332.73 |
| step  7199 |  lr: 0.0000500 | loss  0.3512 | ms/batch 6483.64 |
| step  7219 |  lr: 0.0000500 | loss  0.3372 | ms/batch 6482.16 |
| step  7239 |  lr: 0.0000500 | loss  0.3484 | ms/batch 6367.85 |
| step  7259 |  lr: 0.0000500 | loss  0.3710 | ms/batch 6173.24 |
| step  7279 |  lr: 0.0000500 | loss  0.3249 | ms/batch 6198.95 |
| step  7299 |  lr: 0.0000500 | loss  0.3806 | ms/batch 6169.65 |
| step  7319 |  lr: 0.0000500 | loss  0.3673 | ms/batch 6190.85 |
| step  7339 |  lr: 0.0000500 | loss  0.3635 | ms/batch 6125.20 |
| step  7359 |  lr: 0.0000500 | loss  0.3951 | ms/batch 6211.95 |
| step  7379 |  lr: 0.0000500 | loss  0.3697 | ms/batch 6127.98 |
| step  7399 |  lr: 0.0000500 | loss  0.3754 | ms/batch 5379.26 |
| step  7419 |  lr: 0.0000500 | loss  0.3495 | ms/batch 5293.17 |
| step  7439 |  lr: 0.0000500 | loss  0.3561 | ms/batch 5311.27 |
| step  7459 |  lr: 0.0000500 | loss  0.3458 | ms/batch 5869.94 |
| step  7479 |  lr: 0.0000500 | loss  0.3804 | ms/batch 6657.44 |
| step  7499 |  lr: 0.0000500 | loss  0.3922 | ms/batch 6383.72 |
| step  7519 |  lr: 0.0000500 | loss  0.3661 | ms/batch 6277.73 |
| step  7539 |  lr: 0.0000500 | loss  0.3594 | ms/batch 6496.13 |
| step  7559 |  lr: 0.0000500 | loss  0.3945 | ms/batch 6534.96 |
| step  7579 |  lr: 0.0000500 | loss  0.3686 | ms/batch 6290.69 |
| step  7599 |  lr: 0.0000500 | loss  0.3613 | ms/batch 6064.57 |
| step  7619 |  lr: 0.0000500 | loss  0.3904 | ms/batch 5908.07 |
| step  7639 |  lr: 0.0000500 | loss  0.3705 | ms/batch 5842.31 |
| step  7659 |  lr: 0.0000500 | loss  0.3494 | ms/batch 6348.08 |
| step  7679 |  lr: 0.0000500 | loss  0.3823 | ms/batch 6396.26 |
| step  7699 |  lr: 0.0000500 | loss  0.3513 | ms/batch 6321.78 |
| step  7719 |  lr: 0.0000500 | loss  0.3756 | ms/batch 6300.49 |
| step  7739 |  lr: 0.0000500 | loss  0.3906 | ms/batch 6345.29 |
| step  7759 |  lr: 0.0000500 | loss  0.3926 | ms/batch 6551.68 |
| step  7779 |  lr: 0.0000500 | loss  0.3813 | ms/batch 6472.51 |
| step  7799 |  lr: 0.0000500 | loss  0.3836 | ms/batch 6276.50 |
| step  7819 |  lr: 0.0000500 | loss  0.3638 | ms/batch 6533.85 |
| step  7839 |  lr: 0.0000500 | loss  0.3610 | ms/batch 6375.31 |
| step  7859 |  lr: 0.0000500 | loss  0.3979 | ms/batch 6325.28 |
| step  7879 |  lr: 0.0000500 | loss  0.4080 | ms/batch 6263.68 |
| step  7899 |  lr: 0.0000500 | loss  0.3881 | ms/batch 6113.93 |
| step  7919 |  lr: 0.0000500 | loss  0.3811 | ms/batch 5919.64 |
| step  7939 |  lr: 0.0000500 | loss  0.4117 | ms/batch 6100.26 |
| step  7959 |  lr: 0.0000500 | loss  0.4012 | ms/batch 6314.15 |
| step  7979 |  lr: 0.0000500 | loss  0.3796 | ms/batch 6464.63 |
| step  7999 |  lr: 0.0000500 | loss  0.3843 | ms/batch 6429.30 |
| step  8019 |  lr: 0.0000500 | loss  0.3673 | ms/batch 6222.55 |
| step  8039 |  lr: 0.0000500 | loss  0.4180 | ms/batch 6321.36 |
| step  8059 |  lr: 0.0000500 | loss  0.4142 | ms/batch 6455.28 |
| step  8079 |  lr: 0.0000500 | loss  0.3982 | ms/batch 6302.86 |
| step  8099 |  lr: 0.0000500 | loss  0.4106 | ms/batch 6316.69 |
| step  8119 |  lr: 0.0000500 | loss  0.3989 | ms/batch 6424.59 |
| step  8139 |  lr: 0.0000500 | loss  0.3781 | ms/batch 6421.36 |
| step  8159 |  lr: 0.0000500 | loss  0.4177 | ms/batch 6497.66 |
| step  8179 |  lr: 0.0000500 | loss  0.3999 | ms/batch 6428.51 |
| step  8199 |  lr: 0.0000500 | loss  0.4022 | ms/batch 6410.65 |
| step  8219 |  lr: 0.0000500 | loss  0.4290 | ms/batch 6225.43 |
| step  8239 |  lr: 0.0000500 | loss  0.4006 | ms/batch 6272.20 |
| step  8259 |  lr: 0.0000500 | loss  0.3827 | ms/batch 6256.93 |
| step  8279 |  lr: 0.0000500 | loss  0.4170 | ms/batch 6136.87 |
| step  8299 |  lr: 0.0000500 | loss  0.4153 | ms/batch 6085.78 |
| step  8319 |  lr: 0.0000500 | loss  0.3884 | ms/batch 6295.74 |
| step  8339 |  lr: 0.0000500 | loss  0.3949 | ms/batch 6370.25 |
| step  8359 |  lr: 0.0000500 | loss  0.4041 | ms/batch 6521.29 |
| step  8379 |  lr: 0.0000500 | loss  0.4333 | ms/batch 6426.15 |
| step  8399 |  lr: 0.0000500 | loss  0.4028 | ms/batch 6428.21 |
| step  8419 |  lr: 0.0000500 | loss  0.3994 | ms/batch 6614.55 |
| step  8439 |  lr: 0.0000500 | loss  0.4092 | ms/batch 6502.09 |
| step  8459 |  lr: 0.0000500 | loss  0.4242 | ms/batch 6377.49 |
| step  8479 |  lr: 0.0000500 | loss  0.4062 | ms/batch 6518.11 |
| step  8499 |  lr: 0.0000500 | loss  0.4062 | ms/batch 6374.10 |
| step  8519 |  lr: 0.0000500 | loss  0.4278 | ms/batch 6543.36 |
| step  8539 |  lr: 0.0000500 | loss  0.4123 | ms/batch 6763.91 |
| step  8559 |  lr: 0.0000500 | loss  0.4080 | ms/batch 6410.93 |
-----------------------------------------------------------------------
| step  8574 | dev_acc  0.4729 | test_acc  0.2763 |
train_time : 8980.61 | eval_time : 100.83
-----------------------------------------------------------------------
| step  8579 |  lr: 0.0000500 | loss  0.3702 | ms/batch 1890.45 |
| step  8599 |  lr: 0.0000500 | loss  0.2658 | ms/batch 6367.37 |
| step  8619 |  lr: 0.0000500 | loss  0.2711 | ms/batch 6353.13 |
| step  8639 |  lr: 0.0000500 | loss  0.2761 | ms/batch 6323.25 |
| step  8659 |  lr: 0.0000500 | loss  0.2774 | ms/batch 6267.68 |
| step  8679 |  lr: 0.0000500 | loss  0.2699 | ms/batch 6040.55 |
| step  8699 |  lr: 0.0000500 | loss  0.2893 | ms/batch 6168.58 |
| step  8719 |  lr: 0.0000500 | loss  0.2928 | ms/batch 6202.57 |
| step  8739 |  lr: 0.0000500 | loss  0.2769 | ms/batch 5992.84 |
| step  8759 |  lr: 0.0000500 | loss  0.2944 | ms/batch 6112.23 |
| step  8779 |  lr: 0.0000500 | loss  0.2877 | ms/batch 6469.16 |
| step  8799 |  lr: 0.0000500 | loss  0.2714 | ms/batch 6458.37 |
| step  8819 |  lr: 0.0000500 | loss  0.2946 | ms/batch 6326.06 |
| step  8839 |  lr: 0.0000500 | loss  0.2978 | ms/batch 6381.90 |
| step  8859 |  lr: 0.0000500 | loss  0.2951 | ms/batch 6298.32 |
| step  8879 |  lr: 0.0000500 | loss  0.3241 | ms/batch 5970.25 |
| step  8899 |  lr: 0.0000500 | loss  0.2874 | ms/batch 6130.16 |
| step  8919 |  lr: 0.0000500 | loss  0.3170 | ms/batch 6109.64 |
| step  8939 |  lr: 0.0000500 | loss  0.3016 | ms/batch 6010.88 |
| step  8959 |  lr: 0.0000500 | loss  0.2855 | ms/batch 6229.86 |
| step  8979 |  lr: 0.0000500 | loss  0.3180 | ms/batch 6259.65 |
| step  8999 |  lr: 0.0000500 | loss  0.2904 | ms/batch 6415.17 |
| step  9019 |  lr: 0.0000500 | loss  0.2815 | ms/batch 6363.71 |
| step  9039 |  lr: 0.0000500 | loss  0.3225 | ms/batch 6322.44 |
| step  9059 |  lr: 0.0000500 | loss  0.3084 | ms/batch 6515.42 |
| step  9079 |  lr: 0.0000500 | loss  0.3100 | ms/batch 5777.99 |
| step  9099 |  lr: 0.0000500 | loss  0.3185 | ms/batch 6110.47 |
| step  9119 |  lr: 0.0000500 | loss  0.3116 | ms/batch 6248.65 |
| step  9139 |  lr: 0.0000500 | loss  0.2965 | ms/batch 6050.15 |
| step  9159 |  lr: 0.0000500 | loss  0.3111 | ms/batch 6219.90 |
| step  9179 |  lr: 0.0000500 | loss  0.3145 | ms/batch 6253.11 |
| step  9199 |  lr: 0.0000500 | loss  0.2828 | ms/batch 6365.69 |
| step  9219 |  lr: 0.0000500 | loss  0.3141 | ms/batch 6252.94 |
| step  9239 |  lr: 0.0000500 | loss  0.3208 | ms/batch 6186.72 |
| step  9259 |  lr: 0.0000500 | loss  0.3023 | ms/batch 6088.54 |
| step  9279 |  lr: 0.0000500 | loss  0.3104 | ms/batch 6139.47 |
| step  9299 |  lr: 0.0000500 | loss  0.2867 | ms/batch 5980.45 |
| step  9319 |  lr: 0.0000500 | loss  0.3144 | ms/batch 5892.31 |
| step  9339 |  lr: 0.0000500 | loss  0.3216 | ms/batch 6439.56 |
| step  9359 |  lr: 0.0000500 | loss  0.3242 | ms/batch 6467.44 |
| step  9379 |  lr: 0.0000500 | loss  0.2947 | ms/batch 6342.80 |
| step  9399 |  lr: 0.0000500 | loss  0.3174 | ms/batch 6142.68 |
| step  9419 |  lr: 0.0000500 | loss  0.3319 | ms/batch 6126.83 |
| step  9439 |  lr: 0.0000500 | loss  0.3238 | ms/batch 6199.54 |
| step  9459 |  lr: 0.0000500 | loss  0.3119 | ms/batch 6459.03 |
| step  9479 |  lr: 0.0000500 | loss  0.3101 | ms/batch 6559.66 |
| step  9499 |  lr: 0.0000500 | loss  0.3289 | ms/batch 6385.22 |
| step  9519 |  lr: 0.0000500 | loss  0.3072 | ms/batch 6436.11 |
| step  9539 |  lr: 0.0000500 | loss  0.3086 | ms/batch 6615.91 |
| step  9559 |  lr: 0.0000500 | loss  0.3269 | ms/batch 6480.25 |
| step  9579 |  lr: 0.0000500 | loss  0.3363 | ms/batch 6266.58 |
| step  9599 |  lr: 0.0000500 | loss  0.3236 | ms/batch 6451.84 |
| step  9619 |  lr: 0.0000500 | loss  0.3191 | ms/batch 6065.16 |
| step  9639 |  lr: 0.0000500 | loss  0.3306 | ms/batch 6175.04 |
| step  9659 |  lr: 0.0000500 | loss  0.3176 | ms/batch 6351.74 |
| step  9679 |  lr: 0.0000500 | loss  0.3474 | ms/batch 6187.22 |
| step  9699 |  lr: 0.0000500 | loss  0.3291 | ms/batch 6401.17 |
| step  9719 |  lr: 0.0000500 | loss  0.2971 | ms/batch 6182.60 |
| step  9739 |  lr: 0.0000500 | loss  0.3190 | ms/batch 6422.48 |
| step  9759 |  lr: 0.0000500 | loss  0.3137 | ms/batch 6400.44 |
| step  9779 |  lr: 0.0000500 | loss  0.3371 | ms/batch 6368.88 |
| step  9799 |  lr: 0.0000500 | loss  0.3401 | ms/batch 6631.09 |
| step  9819 |  lr: 0.0000500 | loss  0.3351 | ms/batch 6292.04 |
| step  9839 |  lr: 0.0000500 | loss  0.3436 | ms/batch 6131.57 |
| step  9859 |  lr: 0.0000500 | loss  0.3048 | ms/batch 6381.40 |
| step  9879 |  lr: 0.0000500 | loss  0.2927 | ms/batch 6198.32 |
| step  9899 |  lr: 0.0000500 | loss  0.3281 | ms/batch 6410.65 |
| step  9919 |  lr: 0.0000500 | loss  0.3469 | ms/batch 6113.59 |
| step  9939 |  lr: 0.0000500 | loss  0.2975 | ms/batch 6115.64 |
| step  9959 |  lr: 0.0000500 | loss  0.3520 | ms/batch 6294.43 |
| step  9979 |  lr: 0.0000500 | loss  0.3491 | ms/batch 6187.67 |
| step  9999 |  lr: 0.0000500 | loss  0.3354 | ms/batch 6120.23 |
-----------------------------------------------------------------------
| step 10003 | dev_acc  0.4906 | test_acc  0.2865 |
train_time : 8941.31 | eval_time : 97.95
-----------------------------------------------------------------------
model saved to ./saved_models/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/medmcqa_best.pt
| step 10019 |  lr: 0.0000500 | loss  0.2330 | ms/batch 5483.67 |
| step 10039 |  lr: 0.0000500 | loss  0.2241 | ms/batch 6235.79 |
| step 10059 |  lr: 0.0000500 | loss  0.2199 | ms/batch 6341.82 |
| step 10079 |  lr: 0.0000500 | loss  0.2392 | ms/batch 6282.75 |
| step 10099 |  lr: 0.0000500 | loss  0.2235 | ms/batch 6187.38 |
| step 10119 |  lr: 0.0000500 | loss  0.2336 | ms/batch 6004.76 |
| step 10139 |  lr: 0.0000500 | loss  0.2103 | ms/batch 6243.26 |
| step 10159 |  lr: 0.0000500 | loss  0.2308 | ms/batch 5910.19 |
| step 10179 |  lr: 0.0000500 | loss  0.2433 | ms/batch 6121.56 |
| step 10199 |  lr: 0.0000500 | loss  0.2365 | ms/batch 6063.42 |
| step 10219 |  lr: 0.0000500 | loss  0.2533 | ms/batch 6026.11 |
| step 10239 |  lr: 0.0000500 | loss  0.2425 | ms/batch 6219.08 |
| step 10259 |  lr: 0.0000500 | loss  0.2456 | ms/batch 6109.76 |
| step 10279 |  lr: 0.0000500 | loss  0.2591 | ms/batch 6162.36 |
| step 10299 |  lr: 0.0000500 | loss  0.2564 | ms/batch 6292.68 |
| step 10319 |  lr: 0.0000500 | loss  0.2351 | ms/batch 6298.11 |
| step 10339 |  lr: 0.0000500 | loss  0.2615 | ms/batch 6502.48 |
| step 10359 |  lr: 0.0000500 | loss  0.2178 | ms/batch 6661.56 |
| step 10379 |  lr: 0.0000500 | loss  0.2740 | ms/batch 6495.30 |
| step 10399 |  lr: 0.0000500 | loss  0.2271 | ms/batch 6210.13 |
| step 10419 |  lr: 0.0000500 | loss  0.2431 | ms/batch 6135.86 |
| step 10439 |  lr: 0.0000500 | loss  0.2453 | ms/batch 6225.10 |
| step 10459 |  lr: 0.0000500 | loss  0.2377 | ms/batch 6094.33 |
| step 10479 |  lr: 0.0000500 | loss  0.2701 | ms/batch 6142.71 |
| step 10499 |  lr: 0.0000500 | loss  0.2482 | ms/batch 6203.80 |
| step 10519 |  lr: 0.0000500 | loss  0.2286 | ms/batch 6184.07 |
| step 10539 |  lr: 0.0000500 | loss  0.2425 | ms/batch 6176.67 |
| step 10559 |  lr: 0.0000500 | loss  0.2252 | ms/batch 6084.87 |
| step 10579 |  lr: 0.0000500 | loss  0.2697 | ms/batch 6118.86 |
| step 10599 |  lr: 0.0000500 | loss  0.2510 | ms/batch 6601.31 |
| step 10619 |  lr: 0.0000500 | loss  0.2509 | ms/batch 6441.14 |
| step 10639 |  lr: 0.0000500 | loss  0.2536 | ms/batch 6064.24 |
| step 10659 |  lr: 0.0000500 | loss  0.2844 | ms/batch 6233.98 |
| step 10679 |  lr: 0.0000500 | loss  0.2625 | ms/batch 6074.02 |
| step 10699 |  lr: 0.0000500 | loss  0.2596 | ms/batch 6263.86 |
| step 10719 |  lr: 0.0000500 | loss  0.2392 | ms/batch 6064.03 |
| step 10739 |  lr: 0.0000500 | loss  0.2847 | ms/batch 5944.56 |
| step 10759 |  lr: 0.0000500 | loss  0.2598 | ms/batch 5974.29 |
| step 10779 |  lr: 0.0000500 | loss  0.2584 | ms/batch 6346.55 |
| step 10799 |  lr: 0.0000500 | loss  0.2415 | ms/batch 6501.13 |
| step 10819 |  lr: 0.0000500 | loss  0.2646 | ms/batch 6308.21 |
| step 10839 |  lr: 0.0000500 | loss  0.2281 | ms/batch 6271.65 |
| step 10859 |  lr: 0.0000500 | loss  0.2607 | ms/batch 6466.54 |
| step 10879 |  lr: 0.0000500 | loss  0.2778 | ms/batch 6422.60 |
| step 10899 |  lr: 0.0000500 | loss  0.2721 | ms/batch 6334.01 |
| step 10919 |  lr: 0.0000500 | loss  0.2582 | ms/batch 6512.96 |
| step 10939 |  lr: 0.0000500 | loss  0.2630 | ms/batch 6368.25 |
| step 10959 |  lr: 0.0000500 | loss  0.2647 | ms/batch 6353.72 |
| step 10979 |  lr: 0.0000500 | loss  0.2977 | ms/batch 6349.69 |
| step 10999 |  lr: 0.0000500 | loss  0.3016 | ms/batch 6519.34 |
| step 11019 |  lr: 0.0000500 | loss  0.2737 | ms/batch 6251.36 |
| step 11039 |  lr: 0.0000500 | loss  0.2582 | ms/batch 6134.32 |
| step 11059 |  lr: 0.0000500 | loss  0.2714 | ms/batch 6139.54 |
| step 11079 |  lr: 0.0000500 | loss  0.2782 | ms/batch 6102.69 |
| step 11099 |  lr: 0.0000500 | loss  0.2784 | ms/batch 6156.55 |
| step 11119 |  lr: 0.0000500 | loss  0.2636 | ms/batch 6247.11 |
| step 11139 |  lr: 0.0000500 | loss  0.2415 | ms/batch 6133.85 |
| step 11159 |  lr: 0.0000500 | loss  0.2707 | ms/batch 6113.26 |
| step 11179 |  lr: 0.0000500 | loss  0.2905 | ms/batch 6381.76 |
| step 11199 |  lr: 0.0000500 | loss  0.2603 | ms/batch 6524.59 |
| step 11219 |  lr: 0.0000500 | loss  0.2842 | ms/batch 6219.79 |
| step 11239 |  lr: 0.0000500 | loss  0.2539 | ms/batch 6248.52 |
| step 11259 |  lr: 0.0000500 | loss  0.2740 | ms/batch 6286.12 |
| step 11279 |  lr: 0.0000500 | loss  0.2947 | ms/batch 6429.78 |
| step 11299 |  lr: 0.0000500 | loss  0.2504 | ms/batch 6573.92 |
| step 11319 |  lr: 0.0000500 | loss  0.2890 | ms/batch 6805.69 |
| step 11339 |  lr: 0.0000500 | loss  0.2972 | ms/batch 6384.74 |
| step 11359 |  lr: 0.0000500 | loss  0.2874 | ms/batch 5949.47 |
| step 11379 |  lr: 0.0000500 | loss  0.2745 | ms/batch 5924.65 |
| step 11399 |  lr: 0.0000500 | loss  0.2783 | ms/batch 6163.50 |
| step 11419 |  lr: 0.0000500 | loss  0.2772 | ms/batch 6242.44 |
-----------------------------------------------------------------------
| step 11432 | dev_acc  0.4951 | test_acc  0.2780 |
train_time : 8934.45 | eval_time : 101.89
-----------------------------------------------------------------------
model saved to ./saved_models/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/medmcqa_best.pt
| step 11439 |  lr: 0.0000500 | loss  0.2318 | ms/batch 2667.52 |
| step 11459 |  lr: 0.0000500 | loss  0.1992 | ms/batch 6545.56 |
| step 11479 |  lr: 0.0000500 | loss  0.1907 | ms/batch 6435.68 |
| step 11499 |  lr: 0.0000500 | loss  0.1914 | ms/batch 6580.32 |
| step 11519 |  lr: 0.0000500 | loss  0.1804 | ms/batch 6332.82 |
| step 11539 |  lr: 0.0000500 | loss  0.2013 | ms/batch 5946.22 |
| step 11559 |  lr: 0.0000500 | loss  0.1971 | ms/batch 6100.46 |
| step 11579 |  lr: 0.0000500 | loss  0.2056 | ms/batch 6120.66 |
| step 11599 |  lr: 0.0000500 | loss  0.1828 | ms/batch 6222.10 |
| step 11619 |  lr: 0.0000500 | loss  0.1935 | ms/batch 6038.37 |
| step 11639 |  lr: 0.0000500 | loss  0.2100 | ms/batch 6337.42 |
| step 11659 |  lr: 0.0000500 | loss  0.2038 | ms/batch 6031.36 |
| step 11679 |  lr: 0.0000500 | loss  0.1962 | ms/batch 6193.90 |
| step 11699 |  lr: 0.0000500 | loss  0.2031 | ms/batch 6227.24 |
| step 11719 |  lr: 0.0000500 | loss  0.2330 | ms/batch 6289.14 |
| step 11739 |  lr: 0.0000500 | loss  0.1956 | ms/batch 6316.78 |
| step 11759 |  lr: 0.0000500 | loss  0.1849 | ms/batch 6367.66 |
| step 11779 |  lr: 0.0000500 | loss  0.2052 | ms/batch 6481.54 |
| step 11799 |  lr: 0.0000500 | loss  0.2088 | ms/batch 6476.85 |
| step 11819 |  lr: 0.0000500 | loss  0.1990 | ms/batch 6220.09 |
| step 11839 |  lr: 0.0000500 | loss  0.1983 | ms/batch 6114.99 |
| step 11859 |  lr: 0.0000500 | loss  0.2061 | ms/batch 6065.36 |
| step 11879 |  lr: 0.0000500 | loss  0.1981 | ms/batch 6160.02 |
| step 11899 |  lr: 0.0000500 | loss  0.1973 | ms/batch 6204.45 |
| step 11919 |  lr: 0.0000500 | loss  0.2018 | ms/batch 6030.42 |
| step 11939 |  lr: 0.0000500 | loss  0.2159 | ms/batch 6225.25 |
| step 11959 |  lr: 0.0000500 | loss  0.2205 | ms/batch 6184.85 |
| step 11979 |  lr: 0.0000500 | loss  0.2175 | ms/batch 6251.39 |
| step 11999 |  lr: 0.0000500 | loss  0.2053 | ms/batch 6246.25 |
| step 12019 |  lr: 0.0000500 | loss  0.2147 | ms/batch 6029.45 |
| step 12039 |  lr: 0.0000500 | loss  0.2138 | ms/batch 6060.75 |
| step 12059 |  lr: 0.0000500 | loss  0.2011 | ms/batch 6156.52 |
| step 12079 |  lr: 0.0000500 | loss  0.2217 | ms/batch 6238.30 |
| step 12099 |  lr: 0.0000500 | loss  0.2092 | ms/batch 6350.28 |
| step 12119 |  lr: 0.0000500 | loss  0.2049 | ms/batch 6531.76 |
| step 12139 |  lr: 0.0000500 | loss  0.2072 | ms/batch 6424.22 |
| step 12159 |  lr: 0.0000500 | loss  0.2311 | ms/batch 6279.82 |
| step 12179 |  lr: 0.0000500 | loss  0.2358 | ms/batch 6385.12 |
| step 12199 |  lr: 0.0000500 | loss  0.2346 | ms/batch 6250.35 |
| step 12219 |  lr: 0.0000500 | loss  0.2246 | ms/batch 6190.84 |
| step 12239 |  lr: 0.0000500 | loss  0.2252 | ms/batch 6038.26 |
| step 12259 |  lr: 0.0000500 | loss  0.2215 | ms/batch 5982.34 |
| step 12279 |  lr: 0.0000500 | loss  0.2106 | ms/batch 6075.00 |
| step 12299 |  lr: 0.0000500 | loss  0.2326 | ms/batch 6252.61 |
| step 12319 |  lr: 0.0000500 | loss  0.2328 | ms/batch 6206.11 |
| step 12339 |  lr: 0.0000500 | loss  0.2357 | ms/batch 6287.29 |
| step 12359 |  lr: 0.0000500 | loss  0.2332 | ms/batch 6230.55 |
| step 12379 |  lr: 0.0000500 | loss  0.2295 | ms/batch 6205.80 |
| step 12399 |  lr: 0.0000500 | loss  0.2160 | ms/batch 5958.21 |
| step 12419 |  lr: 0.0000500 | loss  0.2241 | ms/batch 6169.95 |
| step 12439 |  lr: 0.0000500 | loss  0.2384 | ms/batch 5625.85 |
| step 12459 |  lr: 0.0000500 | loss  0.2167 | ms/batch 5012.39 |
| step 12479 |  lr: 0.0000500 | loss  0.2188 | ms/batch 5102.76 |
| step 12499 |  lr: 0.0000500 | loss  0.2355 | ms/batch 5365.45 |
| step 12519 |  lr: 0.0000500 | loss  0.2086 | ms/batch 5192.91 |
| step 12539 |  lr: 0.0000500 | loss  0.2169 | ms/batch 5308.70 |
| step 12559 |  lr: 0.0000500 | loss  0.2083 | ms/batch 5486.73 |
| step 12579 |  lr: 0.0000500 | loss  0.2306 | ms/batch 5272.87 |
| step 12599 |  lr: 0.0000500 | loss  0.2340 | ms/batch 5173.23 |
| step 12619 |  lr: 0.0000500 | loss  0.2174 | ms/batch 5114.66 |
| step 12639 |  lr: 0.0000500 | loss  0.2371 | ms/batch 5110.00 |
| step 12659 |  lr: 0.0000500 | loss  0.2172 | ms/batch 5046.95 |
| step 12679 |  lr: 0.0000500 | loss  0.2417 | ms/batch 5092.32 |
| step 12699 |  lr: 0.0000500 | loss  0.2248 | ms/batch 5129.78 |
| step 12719 |  lr: 0.0000500 | loss  0.2631 | ms/batch 5139.40 |
| step 12739 |  lr: 0.0000500 | loss  0.2231 | ms/batch 5128.07 |
| step 12759 |  lr: 0.0000500 | loss  0.2281 | ms/batch 6143.42 |
| step 12779 |  lr: 0.0000500 | loss  0.2227 | ms/batch 6038.32 |
| step 12799 |  lr: 0.0000500 | loss  0.2723 | ms/batch 6220.03 |
| step 12819 |  lr: 0.0000500 | loss  0.2281 | ms/batch 6086.01 |
| step 12839 |  lr: 0.0000500 | loss  0.2317 | ms/batch 6364.43 |
| step 12859 |  lr: 0.0000500 | loss  0.2209 | ms/batch 6426.66 |
-----------------------------------------------------------------------
| step 12861 | dev_acc  0.4934 | test_acc  0.2807 |
train_time : 8567.64 | eval_time : 98.08
-----------------------------------------------------------------------
| step 12879 |  lr: 0.0000500 | loss  0.1785 | ms/batch 6049.89 |
| step 12899 |  lr: 0.0000500 | loss  0.1724 | ms/batch 6519.51 |
| step 12919 |  lr: 0.0000500 | loss  0.1512 | ms/batch 6246.05 |
| step 12939 |  lr: 0.0000500 | loss  0.1622 | ms/batch 6211.12 |
| step 12959 |  lr: 0.0000500 | loss  0.1613 | ms/batch 6074.36 |
| step 12979 |  lr: 0.0000500 | loss  0.1703 | ms/batch 6300.94 |
| step 12999 |  lr: 0.0000500 | loss  0.1407 | ms/batch 6296.74 |
| step 13019 |  lr: 0.0000500 | loss  0.1733 | ms/batch 6383.56 |
| step 13039 |  lr: 0.0000500 | loss  0.1495 | ms/batch 6462.31 |
| step 13059 |  lr: 0.0000500 | loss  0.1616 | ms/batch 6643.82 |
| step 13079 |  lr: 0.0000500 | loss  0.1580 | ms/batch 6482.79 |
| step 13099 |  lr: 0.0000500 | loss  0.1876 | ms/batch 6270.11 |
| step 13119 |  lr: 0.0000500 | loss  0.1638 | ms/batch 6162.79 |
| step 13139 |  lr: 0.0000500 | loss  0.1639 | ms/batch 6018.18 |
| step 13159 |  lr: 0.0000500 | loss  0.1829 | ms/batch 6140.99 |
| step 13179 |  lr: 0.0000500 | loss  0.1638 | ms/batch 6049.78 |
| step 13199 |  lr: 0.0000500 | loss  0.1701 | ms/batch 6416.95 |
| step 13219 |  lr: 0.0000500 | loss  0.1927 | ms/batch 6461.10 |
| step 13239 |  lr: 0.0000500 | loss  0.1492 | ms/batch 6363.55 |
| step 13259 |  lr: 0.0000500 | loss  0.1886 | ms/batch 6482.26 |
| step 13279 |  lr: 0.0000500 | loss  0.1605 | ms/batch 6352.49 |
| step 13299 |  lr: 0.0000500 | loss  0.1704 | ms/batch 6097.19 |
| step 13319 |  lr: 0.0000500 | loss  0.2068 | ms/batch 5934.09 |
| step 13339 |  lr: 0.0000500 | loss  0.1815 | ms/batch 6023.87 |
| step 13359 |  lr: 0.0000500 | loss  0.1885 | ms/batch 6176.97 |
| step 13379 |  lr: 0.0000500 | loss  0.1900 | ms/batch 6047.51 |
| step 13399 |  lr: 0.0000500 | loss  0.1907 | ms/batch 6460.85 |
| step 13419 |  lr: 0.0000500 | loss  0.1786 | ms/batch 6444.37 |
| step 13439 |  lr: 0.0000500 | loss  0.1811 | ms/batch 6577.65 |
| step 13459 |  lr: 0.0000500 | loss  0.1758 | ms/batch 6327.88 |
| step 13479 |  lr: 0.0000500 | loss  0.1710 | ms/batch 6375.64 |
| step 13499 |  lr: 0.0000500 | loss  0.2012 | ms/batch 6218.37 |
| step 13519 |  lr: 0.0000500 | loss  0.2041 | ms/batch 6414.61 |
| step 13539 |  lr: 0.0000500 | loss  0.2074 | ms/batch 6442.99 |
| step 13559 |  lr: 0.0000500 | loss  0.1934 | ms/batch 6382.98 |
| step 13579 |  lr: 0.0000500 | loss  0.1902 | ms/batch 6454.40 |
| step 13599 |  lr: 0.0000500 | loss  0.2069 | ms/batch 6509.63 |
| step 13619 |  lr: 0.0000500 | loss  0.1796 | ms/batch 6310.23 |
| step 13639 |  lr: 0.0000500 | loss  0.2022 | ms/batch 6597.39 |
| step 13659 |  lr: 0.0000500 | loss  0.1628 | ms/batch 6362.07 |
| step 13679 |  lr: 0.0000500 | loss  0.2132 | ms/batch 6353.46 |
| step 13699 |  lr: 0.0000500 | loss  0.1774 | ms/batch 6531.16 |
| step 13719 |  lr: 0.0000500 | loss  0.1978 | ms/batch 6489.16 |
| step 13739 |  lr: 0.0000500 | loss  0.2073 | ms/batch 6470.91 |
| step 13759 |  lr: 0.0000500 | loss  0.1766 | ms/batch 6340.44 |
| step 13779 |  lr: 0.0000500 | loss  0.1931 | ms/batch 6504.26 |
| step 13799 |  lr: 0.0000500 | loss  0.1962 | ms/batch 6082.98 |
| step 13819 |  lr: 0.0000500 | loss  0.1849 | ms/batch 6146.91 |
| step 13839 |  lr: 0.0000500 | loss  0.2166 | ms/batch 6110.99 |
| step 13859 |  lr: 0.0000500 | loss  0.2087 | ms/batch 6504.23 |
| step 13879 |  lr: 0.0000500 | loss  0.1741 | ms/batch 6628.73 |
| step 13899 |  lr: 0.0000500 | loss  0.2019 | ms/batch 6388.10 |
| step 13919 |  lr: 0.0000500 | loss  0.2014 | ms/batch 6398.24 |
| step 13939 |  lr: 0.0000500 | loss  0.2330 | ms/batch 6478.10 |
| step 13959 |  lr: 0.0000500 | loss  0.2053 | ms/batch 6320.67 |
| step 13979 |  lr: 0.0000500 | loss  0.2055 | ms/batch 5564.77 |
| step 13999 |  lr: 0.0000500 | loss  0.2157 | ms/batch 5472.47 |
| step 14019 |  lr: 0.0000500 | loss  0.1942 | ms/batch 5431.16 |
| step 14039 |  lr: 0.0000500 | loss  0.2402 | ms/batch 5315.21 |
| step 14059 |  lr: 0.0000500 | loss  0.1984 | ms/batch 5108.41 |
| step 14079 |  lr: 0.0000500 | loss  0.1717 | ms/batch 5367.32 |
| step 14099 |  lr: 0.0000500 | loss  0.1934 | ms/batch 6231.65 |
| step 14119 |  lr: 0.0000500 | loss  0.2128 | ms/batch 6157.28 |
| step 14139 |  lr: 0.0000500 | loss  0.2273 | ms/batch 5721.94 |
| step 14159 |  lr: 0.0000500 | loss  0.2137 | ms/batch 6403.40 |
| step 14179 |  lr: 0.0000500 | loss  0.1901 | ms/batch 6670.53 |
| step 14199 |  lr: 0.0000500 | loss  0.1710 | ms/batch 6527.77 |
| step 14219 |  lr: 0.0000500 | loss  0.1947 | ms/batch 6218.82 |
| step 14239 |  lr: 0.0000500 | loss  0.2102 | ms/batch 6576.30 |
| step 14259 |  lr: 0.0000500 | loss  0.1930 | ms/batch 6297.61 |
| step 14279 |  lr: 0.0000500 | loss  0.1830 | ms/batch 6222.41 |
-----------------------------------------------------------------------
| step 14290 | dev_acc  0.4894 | test_acc  0.2761 |
train_time : 8931.08 | eval_time : 97.39
-----------------------------------------------------------------------
| step 14299 |  lr: 0.0000500 | loss  0.1784 | ms/batch 3139.57 |
| step 14319 |  lr: 0.0000500 | loss  0.1207 | ms/batch 6142.79 |
| step 14339 |  lr: 0.0000500 | loss  0.1561 | ms/batch 6375.91 |
| step 14359 |  lr: 0.0000500 | loss  0.1367 | ms/batch 6368.03 |
| step 14379 |  lr: 0.0000500 | loss  0.1479 | ms/batch 6044.69 |
| step 14399 |  lr: 0.0000500 | loss  0.1415 | ms/batch 6284.42 |
| step 14419 |  lr: 0.0000500 | loss  0.1565 | ms/batch 6275.07 |
| step 14439 |  lr: 0.0000500 | loss  0.1343 | ms/batch 6522.81 |
| step 14459 |  lr: 0.0000500 | loss  0.1574 | ms/batch 6436.09 |
| step 14479 |  lr: 0.0000500 | loss  0.1671 | ms/batch 6350.21 |
| step 14499 |  lr: 0.0000500 | loss  0.1522 | ms/batch 6204.76 |
| step 14519 |  lr: 0.0000500 | loss  0.1513 | ms/batch 6484.40 |
| step 14539 |  lr: 0.0000500 | loss  0.1425 | ms/batch 6329.00 |
| step 14559 |  lr: 0.0000500 | loss  0.1443 | ms/batch 6382.15 |
| step 14579 |  lr: 0.0000500 | loss  0.1650 | ms/batch 6018.25 |
| step 14599 |  lr: 0.0000500 | loss  0.1459 | ms/batch 6183.72 |
| step 14619 |  lr: 0.0000500 | loss  0.1576 | ms/batch 6290.91 |
| step 14639 |  lr: 0.0000500 | loss  0.1506 | ms/batch 6527.75 |
| step 14659 |  lr: 0.0000500 | loss  0.1552 | ms/batch 6518.50 |
| step 14679 |  lr: 0.0000500 | loss  0.1372 | ms/batch 6621.62 |
| step 14699 |  lr: 0.0000500 | loss  0.1611 | ms/batch 6452.12 |
| step 14719 |  lr: 0.0000500 | loss  0.1676 | ms/batch 6507.71 |
| step 14739 |  lr: 0.0000500 | loss  0.1473 | ms/batch 6520.42 |
| step 14759 |  lr: 0.0000500 | loss  0.1637 | ms/batch 6395.48 |
| step 14779 |  lr: 0.0000500 | loss  0.1643 | ms/batch 6476.97 |
| step 14799 |  lr: 0.0000500 | loss  0.1612 | ms/batch 6202.47 |
| step 14819 |  lr: 0.0000500 | loss  0.1446 | ms/batch 6099.01 |
| step 14839 |  lr: 0.0000500 | loss  0.1767 | ms/batch 6142.80 |
| step 14859 |  lr: 0.0000500 | loss  0.1629 | ms/batch 6379.97 |
| step 14879 |  lr: 0.0000500 | loss  0.1293 | ms/batch 6306.64 |
| step 14899 |  lr: 0.0000500 | loss  0.1868 | ms/batch 6253.72 |
| step 14919 |  lr: 0.0000500 | loss  0.1570 | ms/batch 6401.98 |
| step 14939 |  lr: 0.0000500 | loss  0.1738 | ms/batch 6267.04 |
| step 14959 |  lr: 0.0000500 | loss  0.1722 | ms/batch 6377.70 |
| step 14979 |  lr: 0.0000500 | loss  0.1746 | ms/batch 6404.37 |
| step 14999 |  lr: 0.0000500 | loss  0.1499 | ms/batch 6249.06 |
| step 15019 |  lr: 0.0000500 | loss  0.1687 | ms/batch 6398.73 |
| step 15039 |  lr: 0.0000500 | loss  0.1645 | ms/batch 6298.34 |
| step 15059 |  lr: 0.0000500 | loss  0.1692 | ms/batch 6251.35 |
| step 15079 |  lr: 0.0000500 | loss  0.1830 | ms/batch 6147.61 |
| step 15099 |  lr: 0.0000500 | loss  0.1873 | ms/batch 6447.36 |
| step 15119 |  lr: 0.0000500 | loss  0.1567 | ms/batch 6594.33 |
| step 15139 |  lr: 0.0000500 | loss  0.1745 | ms/batch 6517.22 |
| step 15159 |  lr: 0.0000500 | loss  0.1710 | ms/batch 6566.77 |
| step 15179 |  lr: 0.0000500 | loss  0.1687 | ms/batch 6440.84 |
| step 15199 |  lr: 0.0000500 | loss  0.1524 | ms/batch 6524.49 |
| step 15219 |  lr: 0.0000500 | loss  0.1755 | ms/batch 6401.19 |
| step 15239 |  lr: 0.0000500 | loss  0.1809 | ms/batch 6520.08 |
| step 15259 |  lr: 0.0000500 | loss  0.1624 | ms/batch 6474.64 |
| step 15279 |  lr: 0.0000500 | loss  0.1651 | ms/batch 6322.79 |
| step 15299 |  lr: 0.0000500 | loss  0.1683 | ms/batch 5872.78 |
| step 15319 |  lr: 0.0000500 | loss  0.1544 | ms/batch 6347.57 |
| step 15339 |  lr: 0.0000500 | loss  0.1464 | ms/batch 6346.23 |
| step 15359 |  lr: 0.0000500 | loss  0.1610 | ms/batch 6302.72 |
| step 15379 |  lr: 0.0000500 | loss  0.1937 | ms/batch 6083.03 |
| step 15399 |  lr: 0.0000500 | loss  0.1899 | ms/batch 5140.07 |
| step 15419 |  lr: 0.0000500 | loss  0.1710 | ms/batch 5133.65 |
| step 15439 |  lr: 0.0000500 | loss  0.1689 | ms/batch 6088.76 |
| step 15459 |  lr: 0.0000500 | loss  0.1674 | ms/batch 6413.39 |
| step 15479 |  lr: 0.0000500 | loss  0.1750 | ms/batch 6397.85 |
| step 15499 |  lr: 0.0000500 | loss  0.1722 | ms/batch 6152.78 |
| step 15519 |  lr: 0.0000500 | loss  0.1524 | ms/batch 6150.18 |
| step 15539 |  lr: 0.0000500 | loss  0.1771 | ms/batch 6319.49 |
| step 15559 |  lr: 0.0000500 | loss  0.1709 | ms/batch 6369.69 |
| step 15579 |  lr: 0.0000500 | loss  0.1905 | ms/batch 6295.89 |
| step 15599 |  lr: 0.0000500 | loss  0.1575 | ms/batch 6195.46 |
| step 15619 |  lr: 0.0000500 | loss  0.1939 | ms/batch 6291.75 |
| step 15639 |  lr: 0.0000500 | loss  0.1610 | ms/batch 6388.95 |
| step 15659 |  lr: 0.0000500 | loss  0.1854 | ms/batch 6298.51 |
| step 15679 |  lr: 0.0000500 | loss  0.1743 | ms/batch 6274.07 |
| step 15699 |  lr: 0.0000500 | loss  0.1785 | ms/batch 6284.80 |
-----------------------------------------------------------------------
| step 15719 | dev_acc  0.4965 | test_acc  0.2800 |
train_time : 8995.10 | eval_time : 97.20
-----------------------------------------------------------------------
model saved to ./saved_models/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/medmcqa_best.pt
| step 15719 |  lr: 0.0000500 | loss  0.1661 | ms/batch  323.18 |
| step 15739 |  lr: 0.0000500 | loss  0.1203 | ms/batch 6016.93 |
| step 15759 |  lr: 0.0000500 | loss  0.1190 | ms/batch 6435.12 |
| step 15779 |  lr: 0.0000500 | loss  0.1438 | ms/batch 6256.05 |
| step 15799 |  lr: 0.0000500 | loss  0.1433 | ms/batch 6373.37 |
| step 15819 |  lr: 0.0000500 | loss  0.1315 | ms/batch 6310.72 |
| step 15839 |  lr: 0.0000500 | loss  0.1193 | ms/batch 6310.85 |
| step 15859 |  lr: 0.0000500 | loss  0.1421 | ms/batch 6076.25 |
| step 15879 |  lr: 0.0000500 | loss  0.1410 | ms/batch 6289.02 |
| step 15899 |  lr: 0.0000500 | loss  0.1205 | ms/batch 6205.67 |
| step 15919 |  lr: 0.0000500 | loss  0.1211 | ms/batch 6069.32 |
| step 15939 |  lr: 0.0000500 | loss  0.1233 | ms/batch 6174.02 |
| step 15959 |  lr: 0.0000500 | loss  0.1344 | ms/batch 6119.61 |
| step 15979 |  lr: 0.0000500 | loss  0.1291 | ms/batch 6219.90 |
| step 15999 |  lr: 0.0000500 | loss  0.1349 | ms/batch 6406.26 |
| step 16019 |  lr: 0.0000500 | loss  0.1247 | ms/batch 6388.60 |
| step 16039 |  lr: 0.0000500 | loss  0.1347 | ms/batch 6269.12 |
| step 16059 |  lr: 0.0000500 | loss  0.1268 | ms/batch 6058.90 |
| step 16079 |  lr: 0.0000500 | loss  0.1179 | ms/batch 6277.81 |
| step 16099 |  lr: 0.0000500 | loss  0.1256 | ms/batch 6146.45 |
| step 16119 |  lr: 0.0000500 | loss  0.1649 | ms/batch 6330.37 |
| step 16139 |  lr: 0.0000500 | loss  0.1396 | ms/batch 6257.12 |
| step 16159 |  lr: 0.0000500 | loss  0.1420 | ms/batch 6470.21 |
| step 16179 |  lr: 0.0000500 | loss  0.1475 | ms/batch 6445.63 |
| step 16199 |  lr: 0.0000500 | loss  0.1314 | ms/batch 6356.32 |
| step 16219 |  lr: 0.0000500 | loss  0.1519 | ms/batch 6440.98 |
| step 16239 |  lr: 0.0000500 | loss  0.1346 | ms/batch 6329.59 |
| step 16259 |  lr: 0.0000500 | loss  0.1341 | ms/batch 6138.94 |
| step 16279 |  lr: 0.0000500 | loss  0.1623 | ms/batch 6109.60 |
| step 16299 |  lr: 0.0000500 | loss  0.1484 | ms/batch 6265.61 |
| step 16319 |  lr: 0.0000500 | loss  0.1382 | ms/batch 6254.98 |
| step 16339 |  lr: 0.0000500 | loss  0.1503 | ms/batch 6464.27 |
| step 16359 |  lr: 0.0000500 | loss  0.1511 | ms/batch 6359.85 |
| step 16379 |  lr: 0.0000500 | loss  0.1382 | ms/batch 6100.98 |
| step 16399 |  lr: 0.0000500 | loss  0.1409 | ms/batch 6262.91 |
| step 16419 |  lr: 0.0000500 | loss  0.1490 | ms/batch 6388.26 |
| step 16439 |  lr: 0.0000500 | loss  0.1631 | ms/batch 6478.18 |
| step 16459 |  lr: 0.0000500 | loss  0.1508 | ms/batch 6451.83 |
| step 16479 |  lr: 0.0000500 | loss  0.1595 | ms/batch 6378.77 |
| step 16499 |  lr: 0.0000500 | loss  0.1348 | ms/batch 6504.80 |
| step 16519 |  lr: 0.0000500 | loss  0.1280 | ms/batch 6100.50 |
| step 16539 |  lr: 0.0000500 | loss  0.1448 | ms/batch 6156.23 |
| step 16559 |  lr: 0.0000500 | loss  0.1550 | ms/batch 6356.47 |
| step 16579 |  lr: 0.0000500 | loss  0.1410 | ms/batch 6111.19 |
| step 16599 |  lr: 0.0000500 | loss  0.1479 | ms/batch 6149.72 |
| step 16619 |  lr: 0.0000500 | loss  0.1627 | ms/batch 6576.76 |
| step 16639 |  lr: 0.0000500 | loss  0.1409 | ms/batch 6520.78 |
| step 16659 |  lr: 0.0000500 | loss  0.1720 | ms/batch 6510.63 |
| step 16679 |  lr: 0.0000500 | loss  0.1608 | ms/batch 6347.74 |
| step 16699 |  lr: 0.0000500 | loss  0.1516 | ms/batch 6464.44 |
| step 16719 |  lr: 0.0000500 | loss  0.1453 | ms/batch 6502.85 |
| step 16739 |  lr: 0.0000500 | loss  0.1456 | ms/batch 6470.24 |
| step 16759 |  lr: 0.0000500 | loss  0.1545 | ms/batch 6252.61 |
| step 16779 |  lr: 0.0000500 | loss  0.1907 | ms/batch 6475.65 |
| step 16799 |  lr: 0.0000500 | loss  0.1627 | ms/batch 6209.56 |
| step 16819 |  lr: 0.0000500 | loss  0.1715 | ms/batch 6387.99 |
| step 16839 |  lr: 0.0000500 | loss  0.1619 | ms/batch 6302.69 |
| step 16859 |  lr: 0.0000500 | loss  0.1613 | ms/batch 6669.66 |
| step 16879 |  lr: 0.0000500 | loss  0.1724 | ms/batch 6429.28 |
| step 16899 |  lr: 0.0000500 | loss  0.1288 | ms/batch 6243.26 |
| step 16919 |  lr: 0.0000500 | loss  0.1787 | ms/batch 6203.65 |
| step 16939 |  lr: 0.0000500 | loss  0.1607 | ms/batch 6477.16 |
| step 16959 |  lr: 0.0000500 | loss  0.1776 | ms/batch 6083.94 |
| step 16979 |  lr: 0.0000500 | loss  0.1518 | ms/batch 6126.85 |
| step 16999 |  lr: 0.0000500 | loss  0.1510 | ms/batch 6230.92 |
| step 17019 |  lr: 0.0000500 | loss  0.1520 | ms/batch 6324.54 |
| step 17039 |  lr: 0.0000500 | loss  0.1591 | ms/batch 6317.75 |
| step 17059 |  lr: 0.0000500 | loss  0.1662 | ms/batch 6486.16 |
| step 17079 |  lr: 0.0000500 | loss  0.1611 | ms/batch 6305.75 |
| step 17099 |  lr: 0.0000500 | loss  0.1648 | ms/batch 6523.93 |
| step 17119 |  lr: 0.0000500 | loss  0.1454 | ms/batch 5577.18 |
| step 17139 |  lr: 0.0000500 | loss  0.1464 | ms/batch 6496.51 |
-----------------------------------------------------------------------
| step 17148 | dev_acc  0.4877 | test_acc  0.2798 |
train_time : 9005.09 | eval_time : 98.16
-----------------------------------------------------------------------
| step 17159 |  lr: 0.0000500 | loss  0.1214 | ms/batch 3760.12 |
| step 17179 |  lr: 0.0000500 | loss  0.0983 | ms/batch 6238.19 |
| step 17199 |  lr: 0.0000500 | loss  0.1029 | ms/batch 6242.39 |
| step 17219 |  lr: 0.0000500 | loss  0.1189 | ms/batch 6232.30 |
| step 17239 |  lr: 0.0000500 | loss  0.1207 | ms/batch 6364.66 |
| step 17259 |  lr: 0.0000500 | loss  0.1143 | ms/batch 6271.01 |
| step 17279 |  lr: 0.0000500 | loss  0.1122 | ms/batch 6062.69 |
| step 17299 |  lr: 0.0000500 | loss  0.1243 | ms/batch 6059.31 |
| step 17319 |  lr: 0.0000500 | loss  0.1214 | ms/batch 6124.06 |
| step 17339 |  lr: 0.0000500 | loss  0.1144 | ms/batch 5968.86 |
| step 17359 |  lr: 0.0000500 | loss  0.1184 | ms/batch 6260.46 |
| step 17379 |  lr: 0.0000500 | loss  0.1337 | ms/batch 6275.43 |
| step 17399 |  lr: 0.0000500 | loss  0.1297 | ms/batch 6047.24 |
| step 17419 |  lr: 0.0000500 | loss  0.1118 | ms/batch 6235.39 |
| step 17439 |  lr: 0.0000500 | loss  0.1010 | ms/batch 6298.07 |
| step 17459 |  lr: 0.0000500 | loss  0.1290 | ms/batch 6544.52 |
| step 17479 |  lr: 0.0000500 | loss  0.1267 | ms/batch 6436.77 |
| step 17499 |  lr: 0.0000500 | loss  0.1219 | ms/batch 6519.33 |
| step 17519 |  lr: 0.0000500 | loss  0.1155 | ms/batch 6503.96 |
| step 17539 |  lr: 0.0000500 | loss  0.1262 | ms/batch 6578.47 |
| step 17559 |  lr: 0.0000500 | loss  0.1371 | ms/batch 6261.99 |
| step 17579 |  lr: 0.0000500 | loss  0.1160 | ms/batch 6367.15 |
| step 17599 |  lr: 0.0000500 | loss  0.1323 | ms/batch 6504.30 |
| step 17619 |  lr: 0.0000500 | loss  0.1306 | ms/batch 6544.94 |
| step 17639 |  lr: 0.0000500 | loss  0.1292 | ms/batch 6483.63 |
| step 17659 |  lr: 0.0000500 | loss  0.1256 | ms/batch 6246.26 |
| step 17679 |  lr: 0.0000500 | loss  0.1423 | ms/batch 6149.75 |
| step 17699 |  lr: 0.0000500 | loss  0.1270 | ms/batch 6117.27 |
| step 17719 |  lr: 0.0000500 | loss  0.1326 | ms/batch 6138.58 |
| step 17739 |  lr: 0.0000500 | loss  0.1299 | ms/batch 6553.70 |
| step 17759 |  lr: 0.0000500 | loss  0.1259 | ms/batch 6331.44 |
| step 17779 |  lr: 0.0000500 | loss  0.1323 | ms/batch 6274.12 |
| step 17799 |  lr: 0.0000500 | loss  0.1378 | ms/batch 6451.68 |
| step 17819 |  lr: 0.0000500 | loss  0.1232 | ms/batch 6610.19 |
| step 17839 |  lr: 0.0000500 | loss  0.1332 | ms/batch 6430.25 |
| step 17859 |  lr: 0.0000500 | loss  0.1355 | ms/batch 6520.94 |
| step 17879 |  lr: 0.0000500 | loss  0.1210 | ms/batch 6343.55 |
| step 17899 |  lr: 0.0000500 | loss  0.1311 | ms/batch 6587.13 |
| step 17919 |  lr: 0.0000500 | loss  0.1410 | ms/batch 6182.38 |
| step 17939 |  lr: 0.0000500 | loss  0.1385 | ms/batch 6201.01 |
| step 17959 |  lr: 0.0000500 | loss  0.1199 | ms/batch 6122.21 |
| step 17979 |  lr: 0.0000500 | loss  0.1280 | ms/batch 6145.51 |
| step 17999 |  lr: 0.0000500 | loss  0.1347 | ms/batch 6250.93 |
| step 18019 |  lr: 0.0000500 | loss  0.1537 | ms/batch 6411.61 |
| step 18039 |  lr: 0.0000500 | loss  0.1465 | ms/batch 6222.85 |
| step 18059 |  lr: 0.0000500 | loss  0.1505 | ms/batch 6084.57 |
| step 18079 |  lr: 0.0000500 | loss  0.1374 | ms/batch 6068.87 |
| step 18099 |  lr: 0.0000500 | loss  0.1440 | ms/batch 5976.80 |
| step 18119 |  lr: 0.0000500 | loss  0.1547 | ms/batch 6513.11 |
| step 18139 |  lr: 0.0000500 | loss  0.1400 | ms/batch 6623.19 |
| step 18159 |  lr: 0.0000500 | loss  0.1506 | ms/batch 6505.42 |
| step 18179 |  lr: 0.0000500 | loss  0.1353 | ms/batch 6288.93 |
| step 18199 |  lr: 0.0000500 | loss  0.1309 | ms/batch 6368.49 |
| step 18219 |  lr: 0.0000500 | loss  0.1419 | ms/batch 6315.86 |
| step 18239 |  lr: 0.0000500 | loss  0.1465 | ms/batch 6212.11 |
| step 18259 |  lr: 0.0000500 | loss  0.1550 | ms/batch 6433.30 |
| step 18279 |  lr: 0.0000500 | loss  0.1421 | ms/batch 6256.22 |
| step 18299 |  lr: 0.0000500 | loss  0.1453 | ms/batch 6311.96 |
| step 18319 |  lr: 0.0000500 | loss  0.1568 | ms/batch 6255.48 |
| step 18339 |  lr: 0.0000500 | loss  0.1266 | ms/batch 6413.38 |
| step 18359 |  lr: 0.0000500 | loss  0.1330 | ms/batch 6441.47 |
| step 18379 |  lr: 0.0000500 | loss  0.1521 | ms/batch 6259.14 |
| step 18399 |  lr: 0.0000500 | loss  0.1722 | ms/batch 6513.89 |
| step 18419 |  lr: 0.0000500 | loss  0.1284 | ms/batch 6718.57 |
| step 18439 |  lr: 0.0000500 | loss  0.1433 | ms/batch 6518.01 |
| step 18459 |  lr: 0.0000500 | loss  0.1442 | ms/batch 6300.09 |
| step 18479 |  lr: 0.0000500 | loss  0.1515 | ms/batch 6516.59 |
| step 18499 |  lr: 0.0000500 | loss  0.1467 | ms/batch 6341.33 |
| step 18519 |  lr: 0.0000500 | loss  0.1314 | ms/batch 6332.58 |
| step 18539 |  lr: 0.0000500 | loss  0.1542 | ms/batch 6101.39 |
| step 18559 |  lr: 0.0000500 | loss  0.1567 | ms/batch 6324.36 |
-----------------------------------------------------------------------
| step 18577 | dev_acc  0.4851 | test_acc  0.2831 |
train_time : 9028.52 | eval_time : 96.81
-----------------------------------------------------------------------
| step 18579 |  lr: 0.0000500 | loss  0.1439 | ms/batch  964.30 |
| step 18599 |  lr: 0.0000500 | loss  0.1101 | ms/batch 6004.38 |
| step 18619 |  lr: 0.0000500 | loss  0.1081 | ms/batch 6163.89 |
| step 18639 |  lr: 0.0000500 | loss  0.0930 | ms/batch 6038.34 |
| step 18659 |  lr: 0.0000500 | loss  0.0998 | ms/batch 6304.13 |
| step 18679 |  lr: 0.0000500 | loss  0.1186 | ms/batch 6070.63 |
| step 18699 |  lr: 0.0000500 | loss  0.1128 | ms/batch 6062.46 |
| step 18719 |  lr: 0.0000500 | loss  0.1145 | ms/batch 6045.23 |
| step 18739 |  lr: 0.0000500 | loss  0.1133 | ms/batch 6338.79 |
| step 18759 |  lr: 0.0000500 | loss  0.0976 | ms/batch 6186.65 |
| step 18779 |  lr: 0.0000500 | loss  0.1098 | ms/batch 6246.17 |
| step 18799 |  lr: 0.0000500 | loss  0.1195 | ms/batch 6408.80 |
| step 18819 |  lr: 0.0000500 | loss  0.1037 | ms/batch 6216.51 |
| step 18839 |  lr: 0.0000500 | loss  0.1244 | ms/batch 6188.95 |
| step 18859 |  lr: 0.0000500 | loss  0.1225 | ms/batch 6258.12 |
| step 18879 |  lr: 0.0000500 | loss  0.1073 | ms/batch 6058.84 |
| step 18899 |  lr: 0.0000500 | loss  0.1032 | ms/batch 6167.32 |
| step 18919 |  lr: 0.0000500 | loss  0.1237 | ms/batch 6024.32 |
| step 18939 |  lr: 0.0000500 | loss  0.1073 | ms/batch 6099.75 |
| step 18959 |  lr: 0.0000500 | loss  0.1301 | ms/batch 6357.84 |
| step 18979 |  lr: 0.0000500 | loss  0.1059 | ms/batch 6018.16 |
| step 18999 |  lr: 0.0000500 | loss  0.1140 | ms/batch 6380.63 |
| step 19019 |  lr: 0.0000500 | loss  0.1113 | ms/batch 6079.41 |
| step 19039 |  lr: 0.0000500 | loss  0.1182 | ms/batch 6227.45 |
| step 19059 |  lr: 0.0000500 | loss  0.1010 | ms/batch 6587.16 |
| step 19079 |  lr: 0.0000500 | loss  0.1233 | ms/batch 6348.93 |
| step 19099 |  lr: 0.0000500 | loss  0.1275 | ms/batch 6492.31 |
| step 19119 |  lr: 0.0000500 | loss  0.1236 | ms/batch 6380.68 |
| step 19139 |  lr: 0.0000500 | loss  0.1119 | ms/batch 6567.89 |
| step 19159 |  lr: 0.0000500 | loss  0.0963 | ms/batch 6329.46 |
| step 19179 |  lr: 0.0000500 | loss  0.1288 | ms/batch 6483.03 |
| step 19199 |  lr: 0.0000500 | loss  0.1241 | ms/batch 6457.61 |
| step 19219 |  lr: 0.0000500 | loss  0.1328 | ms/batch 6439.42 |
| step 19239 |  lr: 0.0000500 | loss  0.1163 | ms/batch 6320.09 |
| step 19259 |  lr: 0.0000500 | loss  0.1185 | ms/batch 6291.89 |
| step 19279 |  lr: 0.0000500 | loss  0.1171 | ms/batch 6117.53 |
| step 19299 |  lr: 0.0000500 | loss  0.1079 | ms/batch 6076.08 |
| step 19319 |  lr: 0.0000500 | loss  0.1199 | ms/batch 5973.40 |
| step 19339 |  lr: 0.0000500 | loss  0.1179 | ms/batch 6199.37 |
| step 19359 |  lr: 0.0000500 | loss  0.1445 | ms/batch 6287.90 |
| step 19379 |  lr: 0.0000500 | loss  0.1313 | ms/batch 6494.55 |
| step 19399 |  lr: 0.0000500 | loss  0.1206 | ms/batch 6330.22 |
| step 19419 |  lr: 0.0000500 | loss  0.1222 | ms/batch 5910.77 |
| step 19439 |  lr: 0.0000500 | loss  0.1133 | ms/batch 6166.35 |
| step 19459 |  lr: 0.0000500 | loss  0.1190 | ms/batch 6140.77 |
| step 19479 |  lr: 0.0000500 | loss  0.1392 | ms/batch 6216.80 |
| step 19499 |  lr: 0.0000500 | loss  0.1255 | ms/batch 6199.55 |
| step 19519 |  lr: 0.0000500 | loss  0.1203 | ms/batch 5977.45 |
| step 19539 |  lr: 0.0000500 | loss  0.1375 | ms/batch 6576.34 |
| step 19559 |  lr: 0.0000500 | loss  0.1440 | ms/batch 6504.26 |
| step 19579 |  lr: 0.0000500 | loss  0.1150 | ms/batch 6402.05 |
| step 19599 |  lr: 0.0000500 | loss  0.1299 | ms/batch 6396.25 |
| step 19619 |  lr: 0.0000500 | loss  0.1282 | ms/batch 6323.13 |
| step 19639 |  lr: 0.0000500 | loss  0.1252 | ms/batch 6522.57 |
| step 19659 |  lr: 0.0000500 | loss  0.1214 | ms/batch 6532.34 |
| step 19679 |  lr: 0.0000500 | loss  0.1295 | ms/batch 6544.09 |
| step 19699 |  lr: 0.0000500 | loss  0.1210 | ms/batch 6469.40 |
| step 19719 |  lr: 0.0000500 | loss  0.1251 | ms/batch 6305.07 |
| step 19739 |  lr: 0.0000500 | loss  0.1215 | ms/batch 6501.88 |
| step 19759 |  lr: 0.0000500 | loss  0.1338 | ms/batch 6447.81 |
| step 19779 |  lr: 0.0000500 | loss  0.1233 | ms/batch 6529.93 |
| step 19799 |  lr: 0.0000500 | loss  0.1463 | ms/batch 6433.09 |
| step 19819 |  lr: 0.0000500 | loss  0.1338 | ms/batch 6123.43 |
| step 19839 |  lr: 0.0000500 | loss  0.1376 | ms/batch 6085.17 |
| step 19859 |  lr: 0.0000500 | loss  0.1405 | ms/batch 6173.20 |
| step 19879 |  lr: 0.0000500 | loss  0.1578 | ms/batch 5959.96 |
| step 19899 |  lr: 0.0000500 | loss  0.1511 | ms/batch 5912.11 |
| step 19919 |  lr: 0.0000500 | loss  0.1223 | ms/batch 5993.56 |
| step 19939 |  lr: 0.0000500 | loss  0.1498 | ms/batch 5964.73 |
| step 19959 |  lr: 0.0000500 | loss  0.1306 | ms/batch 6317.37 |
| step 19979 |  lr: 0.0000500 | loss  0.1440 | ms/batch 6375.83 |
| step 19999 |  lr: 0.0000500 | loss  0.1386 | ms/batch 6353.82 |
-----------------------------------------------------------------------
| step 20006 | dev_acc  0.4906 | test_acc  0.2776 |
train_time : 8940.67 | eval_time : 97.20
-----------------------------------------------------------------------
| step 20019 |  lr: 0.0000500 | loss  0.1002 | ms/batch 4339.47 |
| step 20039 |  lr: 0.0000500 | loss  0.0975 | ms/batch 5895.66 |
| step 20059 |  lr: 0.0000500 | loss  0.0928 | ms/batch 5870.07 |
| step 20079 |  lr: 0.0000500 | loss  0.0757 | ms/batch 6045.22 |
| step 20099 |  lr: 0.0000500 | loss  0.1177 | ms/batch 6364.30 |
| step 20119 |  lr: 0.0000500 | loss  0.0991 | ms/batch 6415.27 |
| step 20139 |  lr: 0.0000500 | loss  0.1050 | ms/batch 6466.84 |
| step 20159 |  lr: 0.0000500 | loss  0.0925 | ms/batch 6290.88 |
| step 20179 |  lr: 0.0000500 | loss  0.1124 | ms/batch 6510.35 |
| step 20199 |  lr: 0.0000500 | loss  0.0996 | ms/batch 6154.45 |
| step 20219 |  lr: 0.0000500 | loss  0.0907 | ms/batch 6293.28 |
| step 20239 |  lr: 0.0000500 | loss  0.1168 | ms/batch 6142.26 |
| step 20259 |  lr: 0.0000500 | loss  0.0935 | ms/batch 6080.00 |
| step 20279 |  lr: 0.0000500 | loss  0.1217 | ms/batch 6097.22 |
| step 20299 |  lr: 0.0000500 | loss  0.0946 | ms/batch 6326.99 |
| step 20319 |  lr: 0.0000500 | loss  0.1077 | ms/batch 6357.52 |
| step 20339 |  lr: 0.0000500 | loss  0.1096 | ms/batch 6377.23 |
| step 20359 |  lr: 0.0000500 | loss  0.1102 | ms/batch 6449.24 |
| step 20379 |  lr: 0.0000500 | loss  0.1100 | ms/batch 6625.98 |
| step 20399 |  lr: 0.0000500 | loss  0.1088 | ms/batch 6255.46 |
| step 20419 |  lr: 0.0000500 | loss  0.1047 | ms/batch 6547.99 |
| step 20439 |  lr: 0.0000500 | loss  0.1222 | ms/batch 6407.09 |
| step 20459 |  lr: 0.0000500 | loss  0.1134 | ms/batch 6247.74 |
| step 20479 |  lr: 0.0000500 | loss  0.1110 | ms/batch 6431.29 |
| step 20499 |  lr: 0.0000500 | loss  0.1069 | ms/batch 6544.03 |
| step 20519 |  lr: 0.0000500 | loss  0.1077 | ms/batch 6342.20 |
| step 20539 |  lr: 0.0000500 | loss  0.0973 | ms/batch 6419.95 |
| step 20559 |  lr: 0.0000500 | loss  0.1082 | ms/batch 6454.57 |
| step 20579 |  lr: 0.0000500 | loss  0.1280 | ms/batch 6430.71 |
| step 20599 |  lr: 0.0000500 | loss  0.1212 | ms/batch 6580.38 |
| step 20619 |  lr: 0.0000500 | loss  0.1037 | ms/batch 6482.99 |
| step 20639 |  lr: 0.0000500 | loss  0.1143 | ms/batch 6250.29 |
| step 20659 |  lr: 0.0000500 | loss  0.1160 | ms/batch 6339.37 |
| step 20679 |  lr: 0.0000500 | loss  0.1152 | ms/batch 6458.61 |
| step 20699 |  lr: 0.0000500 | loss  0.1089 | ms/batch 5985.54 |
| step 20719 |  lr: 0.0000500 | loss  0.1090 | ms/batch 5999.28 |
| step 20739 |  lr: 0.0000500 | loss  0.1003 | ms/batch 6100.91 |
| step 20759 |  lr: 0.0000500 | loss  0.1221 | ms/batch 6095.42 |
| step 20779 |  lr: 0.0000500 | loss  0.1088 | ms/batch 6291.91 |
| step 20799 |  lr: 0.0000500 | loss  0.0982 | ms/batch 6103.92 |
| step 20819 |  lr: 0.0000500 | loss  0.1124 | ms/batch 6208.03 |
| step 20839 |  lr: 0.0000500 | loss  0.1015 | ms/batch 6087.72 |
| step 20859 |  lr: 0.0000500 | loss  0.1031 | ms/batch 6325.21 |
| step 20879 |  lr: 0.0000500 | loss  0.1087 | ms/batch 6110.19 |
| step 20899 |  lr: 0.0000500 | loss  0.1191 | ms/batch 6436.41 |
| step 20919 |  lr: 0.0000500 | loss  0.1201 | ms/batch 6059.80 |
| step 20939 |  lr: 0.0000500 | loss  0.1169 | ms/batch 6260.51 |
| step 20959 |  lr: 0.0000500 | loss  0.1301 | ms/batch 5986.84 |
| step 20979 |  lr: 0.0000500 | loss  0.1168 | ms/batch 6386.94 |
| step 20999 |  lr: 0.0000500 | loss  0.0988 | ms/batch 6071.17 |
| step 21019 |  lr: 0.0000500 | loss  0.1365 | ms/batch 6208.01 |
| step 21039 |  lr: 0.0000500 | loss  0.1332 | ms/batch 6183.41 |
| step 21059 |  lr: 0.0000500 | loss  0.1300 | ms/batch 5936.99 |
| step 21079 |  lr: 0.0000500 | loss  0.1182 | ms/batch 6213.67 |
| step 21099 |  lr: 0.0000500 | loss  0.1254 | ms/batch 6189.43 |
| step 21119 |  lr: 0.0000500 | loss  0.1067 | ms/batch 6055.20 |
| step 21139 |  lr: 0.0000500 | loss  0.1145 | ms/batch 5942.82 |
| step 21159 |  lr: 0.0000500 | loss  0.1207 | ms/batch 6089.80 |
| step 21179 |  lr: 0.0000500 | loss  0.1155 | ms/batch 6079.13 |
| step 21199 |  lr: 0.0000500 | loss  0.1220 | ms/batch 5989.30 |
| step 21219 |  lr: 0.0000500 | loss  0.1402 | ms/batch 6072.88 |
| step 21239 |  lr: 0.0000500 | loss  0.1262 | ms/batch 6342.42 |
| step 21259 |  lr: 0.0000500 | loss  0.1194 | ms/batch 6149.44 |
| step 21279 |  lr: 0.0000500 | loss  0.1322 | ms/batch 6243.94 |
| step 21299 |  lr: 0.0000500 | loss  0.1183 | ms/batch 6147.55 |
| step 21319 |  lr: 0.0000500 | loss  0.1059 | ms/batch 6285.71 |
| step 21339 |  lr: 0.0000500 | loss  0.1137 | ms/batch 6274.52 |
| step 21359 |  lr: 0.0000500 | loss  0.1193 | ms/batch 6212.66 |
| step 21379 |  lr: 0.0000500 | loss  0.1254 | ms/batch 6069.71 |
| step 21399 |  lr: 0.0000500 | loss  0.1160 | ms/batch 6100.38 |
| step 21419 |  lr: 0.0000500 | loss  0.1275 | ms/batch 5166.36 |
-----------------------------------------------------------------------
| step 21435 | dev_acc  0.4956 | test_acc  0.2763 |
train_time : 8872.46 | eval_time : 97.89
-----------------------------------------------------------------------
| step 21439 |  lr: 0.0000500 | loss  0.1261 | ms/batch 1689.74 |
| step 21459 |  lr: 0.0000500 | loss  0.0821 | ms/batch 6219.35 |
| step 21479 |  lr: 0.0000500 | loss  0.0859 | ms/batch 6220.65 |
| step 21499 |  lr: 0.0000500 | loss  0.0897 | ms/batch 6222.78 |
| step 21519 |  lr: 0.0000500 | loss  0.0867 | ms/batch 6147.19 |
| step 21539 |  lr: 0.0000500 | loss  0.0923 | ms/batch 6304.34 |
| step 21559 |  lr: 0.0000500 | loss  0.0967 | ms/batch 6208.56 |
| step 21579 |  lr: 0.0000500 | loss  0.1102 | ms/batch 6219.20 |
| step 21599 |  lr: 0.0000500 | loss  0.1029 | ms/batch 6208.66 |
| step 21619 |  lr: 0.0000500 | loss  0.0948 | ms/batch 6541.03 |
| step 21639 |  lr: 0.0000500 | loss  0.1173 | ms/batch 6180.70 |
| step 21659 |  lr: 0.0000500 | loss  0.0925 | ms/batch 5775.99 |
| step 21679 |  lr: 0.0000500 | loss  0.0914 | ms/batch 6383.95 |
| step 21699 |  lr: 0.0000500 | loss  0.1243 | ms/batch 6182.36 |
| step 21719 |  lr: 0.0000500 | loss  0.1031 | ms/batch 6278.11 |
| step 21739 |  lr: 0.0000500 | loss  0.0965 | ms/batch 6032.36 |
| step 21759 |  lr: 0.0000500 | loss  0.0985 | ms/batch 6209.95 |
| step 21779 |  lr: 0.0000500 | loss  0.1056 | ms/batch 6478.19 |
| step 21799 |  lr: 0.0000500 | loss  0.0949 | ms/batch 6153.37 |
| step 21819 |  lr: 0.0000500 | loss  0.0964 | ms/batch 6337.45 |
| step 21839 |  lr: 0.0000500 | loss  0.1062 | ms/batch 6194.22 |
| step 21859 |  lr: 0.0000500 | loss  0.1108 | ms/batch 6239.12 |
| step 21879 |  lr: 0.0000500 | loss  0.0957 | ms/batch 6350.54 |
| step 21899 |  lr: 0.0000500 | loss  0.0698 | ms/batch 6276.19 |
| step 21919 |  lr: 0.0000500 | loss  0.1002 | ms/batch 6069.94 |
| step 21939 |  lr: 0.0000500 | loss  0.0987 | ms/batch 5912.50 |
| step 21959 |  lr: 0.0000500 | loss  0.1005 | ms/batch 6137.63 |
| step 21979 |  lr: 0.0000500 | loss  0.0868 | ms/batch 6034.92 |
| step 21999 |  lr: 0.0000500 | loss  0.1014 | ms/batch 6109.15 |
| step 22019 |  lr: 0.0000500 | loss  0.1105 | ms/batch 6568.39 |
| step 22039 |  lr: 0.0000500 | loss  0.0916 | ms/batch 6517.34 |
| step 22059 |  lr: 0.0000500 | loss  0.0921 | ms/batch 6406.98 |
| step 22079 |  lr: 0.0000500 | loss  0.1118 | ms/batch 6397.92 |
| step 22099 |  lr: 0.0000500 | loss  0.0978 | ms/batch 6118.17 |
| step 22119 |  lr: 0.0000500 | loss  0.1015 | ms/batch 6204.47 |
| step 22139 |  lr: 0.0000500 | loss  0.1007 | ms/batch 6246.42 |
| step 22159 |  lr: 0.0000500 | loss  0.1165 | ms/batch 6395.93 |
| step 22179 |  lr: 0.0000500 | loss  0.1235 | ms/batch 6320.83 |
| step 22199 |  lr: 0.0000500 | loss  0.1033 | ms/batch 6509.09 |
| step 22219 |  lr: 0.0000500 | loss  0.1025 | ms/batch 6313.51 |
| step 22239 |  lr: 0.0000500 | loss  0.0979 | ms/batch 6294.30 |
| step 22259 |  lr: 0.0000500 | loss  0.1012 | ms/batch 6370.05 |
| step 22279 |  lr: 0.0000500 | loss  0.1061 | ms/batch 6476.65 |
| step 22299 |  lr: 0.0000500 | loss  0.1219 | ms/batch 6580.94 |
| step 22319 |  lr: 0.0000500 | loss  0.1233 | ms/batch 6359.51 |
| step 22339 |  lr: 0.0000500 | loss  0.0982 | ms/batch 6416.10 |
| step 22359 |  lr: 0.0000500 | loss  0.1277 | ms/batch 6379.29 |
| step 22379 |  lr: 0.0000500 | loss  0.1019 | ms/batch 6137.13 |
| step 22399 |  lr: 0.0000500 | loss  0.1099 | ms/batch 6363.68 |
| step 22419 |  lr: 0.0000500 | loss  0.1187 | ms/batch 6265.41 |
| step 22439 |  lr: 0.0000500 | loss  0.1115 | ms/batch 6269.41 |
| step 22459 |  lr: 0.0000500 | loss  0.1080 | ms/batch 6098.72 |
| step 22479 |  lr: 0.0000500 | loss  0.1068 | ms/batch 6257.39 |
| step 22499 |  lr: 0.0000500 | loss  0.1078 | ms/batch 6578.67 |
| step 22519 |  lr: 0.0000500 | loss  0.0970 | ms/batch 6430.85 |
| step 22539 |  lr: 0.0000500 | loss  0.0987 | ms/batch 6478.18 |
| step 22559 |  lr: 0.0000500 | loss  0.1063 | ms/batch 6404.91 |
| step 22579 |  lr: 0.0000500 | loss  0.1187 | ms/batch 6011.40 |
| step 22599 |  lr: 0.0000500 | loss  0.1153 | ms/batch 6049.79 |
| step 22619 |  lr: 0.0000500 | loss  0.1237 | ms/batch 6132.25 |
| step 22639 |  lr: 0.0000500 | loss  0.1096 | ms/batch 5834.85 |
| step 22659 |  lr: 0.0000500 | loss  0.1195 | ms/batch 6231.20 |
| step 22679 |  lr: 0.0000500 | loss  0.1311 | ms/batch 6414.63 |
| step 22699 |  lr: 0.0000500 | loss  0.1109 | ms/batch 6170.63 |
| step 22719 |  lr: 0.0000500 | loss  0.1095 | ms/batch 6195.85 |
| step 22739 |  lr: 0.0000500 | loss  0.1112 | ms/batch 6146.55 |
| step 22759 |  lr: 0.0000500 | loss  0.1217 | ms/batch 6329.28 |
| step 22779 |  lr: 0.0000500 | loss  0.1054 | ms/batch 6183.82 |
| step 22799 |  lr: 0.0000500 | loss  0.1034 | ms/batch 6192.70 |
| step 22819 |  lr: 0.0000500 | loss  0.1116 | ms/batch 6206.55 |
| step 22839 |  lr: 0.0000500 | loss  0.1311 | ms/batch 6293.61 |
| step 22859 |  lr: 0.0000500 | loss  0.0976 | ms/batch 6084.80 |
-----------------------------------------------------------------------
| step 22864 | dev_acc  0.4870 | test_acc  0.2698 |
train_time : 8940.71 | eval_time : 99.06
-----------------------------------------------------------------------
| step 22879 |  lr: 0.0000500 | loss  0.0913 | ms/batch 5057.82 |
| step 22899 |  lr: 0.0000500 | loss  0.0693 | ms/batch 6617.81 |
| step 22919 |  lr: 0.0000500 | loss  0.0886 | ms/batch 6532.01 |
| step 22939 |  lr: 0.0000500 | loss  0.0896 | ms/batch 6318.79 |
| step 22959 |  lr: 0.0000500 | loss  0.0835 | ms/batch 6026.59 |
| step 22979 |  lr: 0.0000500 | loss  0.0904 | ms/batch 6001.47 |
| step 22999 |  lr: 0.0000500 | loss  0.0939 | ms/batch 6221.49 |
| step 23019 |  lr: 0.0000500 | loss  0.0846 | ms/batch 6291.32 |
| step 23039 |  lr: 0.0000500 | loss  0.0912 | ms/batch 6410.35 |
| step 23059 |  lr: 0.0000500 | loss  0.0937 | ms/batch 6506.74 |
| step 23079 |  lr: 0.0000500 | loss  0.0917 | ms/batch 6484.27 |
| step 23099 |  lr: 0.0000500 | loss  0.1080 | ms/batch 6528.77 |
| step 23119 |  lr: 0.0000500 | loss  0.0872 | ms/batch 6637.86 |
| step 23139 |  lr: 0.0000500 | loss  0.0903 | ms/batch 6242.47 |
| step 23159 |  lr: 0.0000500 | loss  0.0972 | ms/batch 6082.10 |
| step 23179 |  lr: 0.0000500 | loss  0.1083 | ms/batch 6500.38 |
| step 23199 |  lr: 0.0000500 | loss  0.0974 | ms/batch 6441.38 |
| step 23219 |  lr: 0.0000500 | loss  0.0909 | ms/batch 6191.79 |
| step 23239 |  lr: 0.0000500 | loss  0.0935 | ms/batch 6434.59 |
| step 23259 |  lr: 0.0000500 | loss  0.0873 | ms/batch 6240.28 |
| step 23279 |  lr: 0.0000500 | loss  0.0818 | ms/batch 6322.12 |
| step 23299 |  lr: 0.0000500 | loss  0.0939 | ms/batch 6347.77 |
| step 23319 |  lr: 0.0000500 | loss  0.0951 | ms/batch 6130.15 |
| step 23339 |  lr: 0.0000500 | loss  0.0776 | ms/batch 6091.64 |
| step 23359 |  lr: 0.0000500 | loss  0.0876 | ms/batch 6327.84 |
| step 23379 |  lr: 0.0000500 | loss  0.1009 | ms/batch 6323.02 |
| step 23399 |  lr: 0.0000500 | loss  0.0847 | ms/batch 6250.05 |
| step 23419 |  lr: 0.0000500 | loss  0.0973 | ms/batch 6606.58 |
| step 23439 |  lr: 0.0000500 | loss  0.0882 | ms/batch 6356.20 |
| step 23459 |  lr: 0.0000500 | loss  0.1191 | ms/batch 6207.85 |
| step 23479 |  lr: 0.0000500 | loss  0.0997 | ms/batch 6649.64 |
| step 23499 |  lr: 0.0000500 | loss  0.1044 | ms/batch 6312.50 |
| step 23519 |  lr: 0.0000500 | loss  0.1160 | ms/batch 6264.67 |
| step 23539 |  lr: 0.0000500 | loss  0.0723 | ms/batch 6348.93 |
| step 23559 |  lr: 0.0000500 | loss  0.1024 | ms/batch 6217.41 |
| step 23579 |  lr: 0.0000500 | loss  0.1003 | ms/batch 6353.75 |
| step 23599 |  lr: 0.0000500 | loss  0.0814 | ms/batch 6220.63 |
| step 23619 |  lr: 0.0000500 | loss  0.0930 | ms/batch 6532.60 |
| step 23639 |  lr: 0.0000500 | loss  0.0880 | ms/batch 6533.25 |
| step 23659 |  lr: 0.0000500 | loss  0.1166 | ms/batch 6165.95 |
| step 23679 |  lr: 0.0000500 | loss  0.0891 | ms/batch 6686.85 |
| step 23699 |  lr: 0.0000500 | loss  0.1018 | ms/batch 6700.92 |
| step 23719 |  lr: 0.0000500 | loss  0.1092 | ms/batch 6686.73 |
| step 23739 |  lr: 0.0000500 | loss  0.0908 | ms/batch 6491.48 |
| step 23759 |  lr: 0.0000500 | loss  0.1069 | ms/batch 6529.78 |
| step 23779 |  lr: 0.0000500 | loss  0.0959 | ms/batch 6264.80 |
| step 23799 |  lr: 0.0000500 | loss  0.0969 | ms/batch 6414.93 |
| step 23819 |  lr: 0.0000500 | loss  0.1002 | ms/batch 6423.43 |
| step 23839 |  lr: 0.0000500 | loss  0.1063 | ms/batch 6408.41 |
| step 23859 |  lr: 0.0000500 | loss  0.1041 | ms/batch 6465.34 |
| step 23879 |  lr: 0.0000500 | loss  0.1012 | ms/batch 6097.41 |
| step 23899 |  lr: 0.0000500 | loss  0.1019 | ms/batch 6099.44 |
| step 23919 |  lr: 0.0000500 | loss  0.0913 | ms/batch 6044.33 |
| step 23939 |  lr: 0.0000500 | loss  0.1099 | ms/batch 6159.49 |
| step 23959 |  lr: 0.0000500 | loss  0.1142 | ms/batch 6293.71 |
| step 23979 |  lr: 0.0000500 | loss  0.1086 | ms/batch 6215.94 |
| step 23999 |  lr: 0.0000500 | loss  0.1193 | ms/batch 6346.53 |
| step 24019 |  lr: 0.0000500 | loss  0.1013 | ms/batch 6249.67 |
| step 24039 |  lr: 0.0000500 | loss  0.1013 | ms/batch 6208.62 |
| step 24059 |  lr: 0.0000500 | loss  0.0937 | ms/batch 6212.58 |
| step 24079 |  lr: 0.0000500 | loss  0.0951 | ms/batch 6118.18 |
| step 24099 |  lr: 0.0000500 | loss  0.1088 | ms/batch 5953.96 |
| step 24119 |  lr: 0.0000500 | loss  0.1112 | ms/batch 6199.80 |
| step 24139 |  lr: 0.0000500 | loss  0.1010 | ms/batch 6251.13 |
| step 24159 |  lr: 0.0000500 | loss  0.1105 | ms/batch 6175.14 |
| step 24179 |  lr: 0.0000500 | loss  0.0978 | ms/batch 6416.49 |
| step 24199 |  lr: 0.0000500 | loss  0.1178 | ms/batch 6442.09 |
| step 24219 |  lr: 0.0000500 | loss  0.1034 | ms/batch 6330.25 |
| step 24239 |  lr: 0.0000500 | loss  0.0940 | ms/batch 6281.81 |
| step 24259 |  lr: 0.0000500 | loss  0.0985 | ms/batch 6499.30 |
| step 24279 |  lr: 0.0000500 | loss  0.1047 | ms/batch 6379.64 |
-----------------------------------------------------------------------
| step 24293 | dev_acc  0.4937 | test_acc  0.2750 |
train_time : 9047.93 | eval_time : 101.98
-----------------------------------------------------------------------
| step 24299 |  lr: 0.0000500 | loss  0.1069 | ms/batch 2205.57 |
| step 24319 |  lr: 0.0000500 | loss  0.0742 | ms/batch 6471.27 |
| step 24339 |  lr: 0.0000500 | loss  0.0863 | ms/batch 6529.88 |
| step 24359 |  lr: 0.0000500 | loss  0.0716 | ms/batch 6242.69 |
| step 24379 |  lr: 0.0000500 | loss  0.0836 | ms/batch 6349.83 |
| step 24399 |  lr: 0.0000500 | loss  0.0799 | ms/batch 6491.21 |
| step 24419 |  lr: 0.0000500 | loss  0.0831 | ms/batch 6460.21 |
| step 24439 |  lr: 0.0000500 | loss  0.0904 | ms/batch 6351.01 |
| step 24459 |  lr: 0.0000500 | loss  0.0892 | ms/batch 6305.87 |
| step 24479 |  lr: 0.0000500 | loss  0.0870 | ms/batch 6529.48 |
| step 24499 |  lr: 0.0000500 | loss  0.0876 | ms/batch 6531.20 |
| step 24519 |  lr: 0.0000500 | loss  0.0902 | ms/batch 6589.97 |
| step 24539 |  lr: 0.0000500 | loss  0.0781 | ms/batch 6273.59 |
| step 24559 |  lr: 0.0000500 | loss  0.0685 | ms/batch 6261.41 |
| step 24579 |  lr: 0.0000500 | loss  0.0858 | ms/batch 6100.34 |
| step 24599 |  lr: 0.0000500 | loss  0.0893 | ms/batch 6227.47 |
| step 24619 |  lr: 0.0000500 | loss  0.0909 | ms/batch 6305.33 |
| step 24639 |  lr: 0.0000500 | loss  0.0806 | ms/batch 6394.46 |
| step 24659 |  lr: 0.0000500 | loss  0.0791 | ms/batch 6522.75 |
| step 24679 |  lr: 0.0000500 | loss  0.0742 | ms/batch 6461.32 |
| step 24699 |  lr: 0.0000500 | loss  0.0794 | ms/batch 6148.28 |
| step 24719 |  lr: 0.0000500 | loss  0.0941 | ms/batch 6419.64 |
| step 24739 |  lr: 0.0000500 | loss  0.0874 | ms/batch 6356.96 |
| step 24759 |  lr: 0.0000500 | loss  0.1015 | ms/batch 6290.62 |
| step 24779 |  lr: 0.0000500 | loss  0.0865 | ms/batch 6136.39 |
| step 24799 |  lr: 0.0000500 | loss  0.0892 | ms/batch 6596.17 |
| step 24819 |  lr: 0.0000500 | loss  0.0867 | ms/batch 6362.88 |
| step 24839 |  lr: 0.0000500 | loss  0.0892 | ms/batch 6163.12 |
| step 24859 |  lr: 0.0000500 | loss  0.0942 | ms/batch 6108.66 |
| step 24879 |  lr: 0.0000500 | loss  0.0780 | ms/batch 6203.94 |
| step 24899 |  lr: 0.0000500 | loss  0.0926 | ms/batch 6223.36 |
| step 24919 |  lr: 0.0000500 | loss  0.0955 | ms/batch 6111.12 |
| step 24939 |  lr: 0.0000500 | loss  0.1247 | ms/batch 6182.80 |
| step 24959 |  lr: 0.0000500 | loss  0.0871 | ms/batch 5846.04 |
| step 24979 |  lr: 0.0000500 | loss  0.0914 | ms/batch 6027.93 |
| step 24999 |  lr: 0.0000500 | loss  0.0874 | ms/batch 6122.63 |
| step 25019 |  lr: 0.0000500 | loss  0.0812 | ms/batch 6486.23 |
| step 25039 |  lr: 0.0000500 | loss  0.0881 | ms/batch 6442.93 |
| step 25059 |  lr: 0.0000500 | loss  0.1030 | ms/batch 6506.65 |
| step 25079 |  lr: 0.0000500 | loss  0.0950 | ms/batch 6495.25 |
| step 25099 |  lr: 0.0000500 | loss  0.0776 | ms/batch 6572.86 |
| step 25119 |  lr: 0.0000500 | loss  0.0958 | ms/batch 6260.51 |
| step 25139 |  lr: 0.0000500 | loss  0.0794 | ms/batch 6222.51 |
| step 25159 |  lr: 0.0000500 | loss  0.0966 | ms/batch 6493.89 |
| step 25179 |  lr: 0.0000500 | loss  0.1034 | ms/batch 6551.61 |
| step 25199 |  lr: 0.0000500 | loss  0.1024 | ms/batch 6384.65 |
| step 25219 |  lr: 0.0000500 | loss  0.1033 | ms/batch 5960.27 |
| step 25239 |  lr: 0.0000500 | loss  0.1033 | ms/batch 6076.38 |
| step 25259 |  lr: 0.0000500 | loss  0.0857 | ms/batch 6137.37 |
| step 25279 |  lr: 0.0000500 | loss  0.0902 | ms/batch 6206.06 |
| step 25299 |  lr: 0.0000500 | loss  0.0807 | ms/batch 6348.09 |
| step 25319 |  lr: 0.0000500 | loss  0.0860 | ms/batch 6391.28 |
| step 25339 |  lr: 0.0000500 | loss  0.0920 | ms/batch 6541.72 |
| step 25359 |  lr: 0.0000500 | loss  0.0796 | ms/batch 6350.20 |
| step 25379 |  lr: 0.0000500 | loss  0.1075 | ms/batch 6323.02 |
| step 25399 |  lr: 0.0000500 | loss  0.0974 | ms/batch 5320.06 |
| step 25419 |  lr: 0.0000500 | loss  0.1017 | ms/batch 5409.76 |
| step 25439 |  lr: 0.0000500 | loss  0.1003 | ms/batch 5391.19 |
| step 25459 |  lr: 0.0000500 | loss  0.0989 | ms/batch 5309.78 |
| step 25479 |  lr: 0.0000500 | loss  0.0986 | ms/batch 5231.44 |
| step 25499 |  lr: 0.0000500 | loss  0.1013 | ms/batch 5332.38 |
| step 25519 |  lr: 0.0000500 | loss  0.0863 | ms/batch 5070.49 |
| step 25539 |  lr: 0.0000500 | loss  0.1046 | ms/batch 4999.18 |
| step 25559 |  lr: 0.0000500 | loss  0.0935 | ms/batch 5150.80 |
| step 25579 |  lr: 0.0000500 | loss  0.0873 | ms/batch 5266.57 |
| step 25599 |  lr: 0.0000500 | loss  0.0905 | ms/batch 5151.61 |
| step 25619 |  lr: 0.0000500 | loss  0.0951 | ms/batch 5296.92 |
| step 25639 |  lr: 0.0000500 | loss  0.1062 | ms/batch 5345.49 |
| step 25659 |  lr: 0.0000500 | loss  0.0896 | ms/batch 5482.74 |
| step 25679 |  lr: 0.0000500 | loss  0.1071 | ms/batch 5357.39 |
| step 25699 |  lr: 0.0000500 | loss  0.0850 | ms/batch 5284.71 |
| step 25719 |  lr: 0.0000500 | loss  0.1087 | ms/batch 5359.46 |
-----------------------------------------------------------------------
| step 25722 | dev_acc  0.5035 | test_acc  0.2738 |
train_time : 8675.38 | eval_time : 97.90
-----------------------------------------------------------------------
model saved to ./saved_models/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/medmcqa_best.pt
| step 25739 |  lr: 0.0000500 | loss  0.0850 | ms/batch 5889.31 |
| step 25759 |  lr: 0.0000500 | loss  0.0791 | ms/batch 6342.83 |
| step 25779 |  lr: 0.0000500 | loss  0.0819 | ms/batch 6401.07 |
| step 25799 |  lr: 0.0000500 | loss  0.0849 | ms/batch 6501.11 |
| step 25819 |  lr: 0.0000500 | loss  0.0672 | ms/batch 6287.39 |
| step 25839 |  lr: 0.0000500 | loss  0.0828 | ms/batch 6361.11 |
| step 25859 |  lr: 0.0000500 | loss  0.0720 | ms/batch 6495.84 |
| step 25879 |  lr: 0.0000500 | loss  0.0824 | ms/batch 6276.82 |
| step 25899 |  lr: 0.0000500 | loss  0.0620 | ms/batch 6354.04 |
| step 25919 |  lr: 0.0000500 | loss  0.0680 | ms/batch 6111.74 |
| step 25939 |  lr: 0.0000500 | loss  0.0751 | ms/batch 6103.23 |
| step 25959 |  lr: 0.0000500 | loss  0.0943 | ms/batch 6041.02 |
| step 25979 |  lr: 0.0000500 | loss  0.0764 | ms/batch 6420.53 |
| step 25999 |  lr: 0.0000500 | loss  0.0665 | ms/batch 6243.72 |
| step 26019 |  lr: 0.0000500 | loss  0.0814 | ms/batch 6562.21 |
| step 26039 |  lr: 0.0000500 | loss  0.0833 | ms/batch 6459.99 |
| step 26059 |  lr: 0.0000500 | loss  0.0894 | ms/batch 6510.00 |
| step 26079 |  lr: 0.0000500 | loss  0.0826 | ms/batch 6590.21 |
| step 26099 |  lr: 0.0000500 | loss  0.0675 | ms/batch 6201.85 |
| step 26119 |  lr: 0.0000500 | loss  0.0815 | ms/batch 6216.76 |
| step 26139 |  lr: 0.0000500 | loss  0.0834 | ms/batch 6193.36 |
| step 26159 |  lr: 0.0000500 | loss  0.0828 | ms/batch 6374.45 |
| step 26179 |  lr: 0.0000500 | loss  0.0930 | ms/batch 6100.64 |
| step 26199 |  lr: 0.0000500 | loss  0.0790 | ms/batch 6632.61 |
| step 26219 |  lr: 0.0000500 | loss  0.0700 | ms/batch 6596.84 |
| step 26239 |  lr: 0.0000500 | loss  0.0937 | ms/batch 6410.44 |
| step 26259 |  lr: 0.0000500 | loss  0.0814 | ms/batch 6566.65 |
| step 26279 |  lr: 0.0000500 | loss  0.0670 | ms/batch 6301.70 |
| step 26299 |  lr: 0.0000500 | loss  0.0868 | ms/batch 6477.76 |
| step 26319 |  lr: 0.0000500 | loss  0.0844 | ms/batch 6450.95 |
| step 26339 |  lr: 0.0000500 | loss  0.0914 | ms/batch 6412.69 |
| step 26359 |  lr: 0.0000500 | loss  0.0928 | ms/batch 6535.83 |
| step 26379 |  lr: 0.0000500 | loss  0.0933 | ms/batch 6556.25 |
| step 26399 |  lr: 0.0000500 | loss  0.0865 | ms/batch 6430.91 |
| step 26419 |  lr: 0.0000500 | loss  0.0820 | ms/batch 6311.88 |
| step 26439 |  lr: 0.0000500 | loss  0.0780 | ms/batch 6271.56 |
| step 26459 |  lr: 0.0000500 | loss  0.0819 | ms/batch 6511.88 |
| step 26479 |  lr: 0.0000500 | loss  0.0691 | ms/batch 6335.13 |
| step 26499 |  lr: 0.0000500 | loss  0.0841 | ms/batch 6531.26 |
| step 26519 |  lr: 0.0000500 | loss  0.0959 | ms/batch 6333.91 |
| step 26539 |  lr: 0.0000500 | loss  0.0741 | ms/batch 6430.31 |
| step 26559 |  lr: 0.0000500 | loss  0.0817 | ms/batch 6193.01 |
| step 26579 |  lr: 0.0000500 | loss  0.0892 | ms/batch 6147.45 |
| step 26599 |  lr: 0.0000500 | loss  0.1006 | ms/batch 6267.62 |
| step 26619 |  lr: 0.0000500 | loss  0.1071 | ms/batch 6454.49 |
| step 26639 |  lr: 0.0000500 | loss  0.0820 | ms/batch 6449.88 |
| step 26659 |  lr: 0.0000500 | loss  0.0849 | ms/batch 6393.45 |
| step 26679 |  lr: 0.0000500 | loss  0.1004 | ms/batch 6401.36 |
| step 26699 |  lr: 0.0000500 | loss  0.0866 | ms/batch 6445.90 |
| step 26719 |  lr: 0.0000500 | loss  0.0947 | ms/batch 6541.99 |
| step 26739 |  lr: 0.0000500 | loss  0.0921 | ms/batch 6400.80 |
| step 26759 |  lr: 0.0000500 | loss  0.1023 | ms/batch 6292.76 |
| step 26779 |  lr: 0.0000500 | loss  0.0803 | ms/batch 6150.58 |
| step 26799 |  lr: 0.0000500 | loss  0.0965 | ms/batch 6124.44 |
| step 26819 |  lr: 0.0000500 | loss  0.0935 | ms/batch 6167.48 |
| step 26839 |  lr: 0.0000500 | loss  0.1056 | ms/batch 6071.57 |
| step 26859 |  lr: 0.0000500 | loss  0.1010 | ms/batch 6245.24 |
| step 26879 |  lr: 0.0000500 | loss  0.1032 | ms/batch 6445.94 |
| step 26899 |  lr: 0.0000500 | loss  0.0867 | ms/batch 6318.02 |
| step 26919 |  lr: 0.0000500 | loss  0.1144 | ms/batch 6312.67 |
| step 26939 |  lr: 0.0000500 | loss  0.0897 | ms/batch 6453.10 |
| step 26959 |  lr: 0.0000500 | loss  0.0942 | ms/batch 6568.04 |
| step 26979 |  lr: 0.0000500 | loss  0.0837 | ms/batch 6362.85 |
| step 26999 |  lr: 0.0000500 | loss  0.1048 | ms/batch 6566.14 |
| step 27019 |  lr: 0.0000500 | loss  0.0946 | ms/batch 6528.71 |
| step 27039 |  lr: 0.0000500 | loss  0.0973 | ms/batch 6542.58 |
| step 27059 |  lr: 0.0000500 | loss  0.0999 | ms/batch 6343.66 |
| step 27079 |  lr: 0.0000500 | loss  0.0904 | ms/batch 6251.03 |
| step 27099 |  lr: 0.0000500 | loss  0.0982 | ms/batch 6440.25 |
| step 27119 |  lr: 0.0000500 | loss  0.0783 | ms/batch 6485.37 |
| step 27139 |  lr: 0.0000500 | loss  0.1047 | ms/batch 6450.75 |
-----------------------------------------------------------------------
| step 27151 | dev_acc  0.4961 | test_acc  0.2722 |
train_time : 9105.56 | eval_time : 97.75
-----------------------------------------------------------------------
| step 27159 |  lr: 0.0000500 | loss  0.0626 | ms/batch 2961.17 |
| step 27179 |  lr: 0.0000500 | loss  0.0709 | ms/batch 6591.89 |
| step 27199 |  lr: 0.0000500 | loss  0.0727 | ms/batch 6587.27 |
| step 27219 |  lr: 0.0000500 | loss  0.0535 | ms/batch 6469.91 |
| step 27239 |  lr: 0.0000500 | loss  0.0827 | ms/batch 6355.59 |
| step 27259 |  lr: 0.0000500 | loss  0.0651 | ms/batch 6278.73 |
| step 27279 |  lr: 0.0000500 | loss  0.0826 | ms/batch 6282.74 |
| step 27299 |  lr: 0.0000500 | loss  0.0586 | ms/batch 6280.64 |
| step 27319 |  lr: 0.0000500 | loss  0.0832 | ms/batch 6338.81 |
| step 27339 |  lr: 0.0000500 | loss  0.0836 | ms/batch 6352.24 |
| step 27359 |  lr: 0.0000500 | loss  0.0841 | ms/batch 5964.09 |
| step 27379 |  lr: 0.0000500 | loss  0.0675 | ms/batch 6134.29 |
| step 27399 |  lr: 0.0000500 | loss  0.0738 | ms/batch 6270.39 |
| step 27419 |  lr: 0.0000500 | loss  0.0627 | ms/batch 6310.94 |
| step 27439 |  lr: 0.0000500 | loss  0.0889 | ms/batch 6048.06 |
| step 27459 |  lr: 0.0000500 | loss  0.0801 | ms/batch 6219.27 |
| step 27479 |  lr: 0.0000500 | loss  0.0679 | ms/batch 6490.59 |
| step 27499 |  lr: 0.0000500 | loss  0.0796 | ms/batch 6175.67 |
| step 27519 |  lr: 0.0000500 | loss  0.0835 | ms/batch 6170.27 |
| step 27539 |  lr: 0.0000500 | loss  0.0796 | ms/batch 6189.32 |
| step 27559 |  lr: 0.0000500 | loss  0.0776 | ms/batch 6451.51 |
| step 27579 |  lr: 0.0000500 | loss  0.0816 | ms/batch 6136.73 |
| step 27599 |  lr: 0.0000500 | loss  0.0706 | ms/batch 6087.43 |
| step 27619 |  lr: 0.0000500 | loss  0.0758 | ms/batch 6085.25 |
| step 27639 |  lr: 0.0000500 | loss  0.0755 | ms/batch 6245.42 |
| step 27659 |  lr: 0.0000500 | loss  0.0612 | ms/batch 6064.82 |
| step 27679 |  lr: 0.0000500 | loss  0.0836 | ms/batch 5973.16 |
| step 27699 |  lr: 0.0000500 | loss  0.0878 | ms/batch 6365.61 |
| step 27719 |  lr: 0.0000500 | loss  0.0864 | ms/batch 6320.34 |
| step 27739 |  lr: 0.0000500 | loss  0.0771 | ms/batch 6599.77 |
| step 27759 |  lr: 0.0000500 | loss  0.0817 | ms/batch 6477.27 |
| step 27779 |  lr: 0.0000500 | loss  0.0843 | ms/batch 6448.77 |
| step 27799 |  lr: 0.0000500 | loss  0.0818 | ms/batch 6409.90 |
| step 27819 |  lr: 0.0000500 | loss  0.0809 | ms/batch 6496.95 |
| step 27839 |  lr: 0.0000500 | loss  0.0799 | ms/batch 6551.01 |
| step 27859 |  lr: 0.0000500 | loss  0.0847 | ms/batch 6212.01 |
| step 27879 |  lr: 0.0000500 | loss  0.0877 | ms/batch 6186.75 |
| step 27899 |  lr: 0.0000500 | loss  0.0811 | ms/batch 6124.13 |
| step 27919 |  lr: 0.0000500 | loss  0.0801 | ms/batch 5977.22 |
| step 27939 |  lr: 0.0000500 | loss  0.0852 | ms/batch 5930.88 |
| step 27959 |  lr: 0.0000500 | loss  0.0772 | ms/batch 6197.68 |
| step 27979 |  lr: 0.0000500 | loss  0.0858 | ms/batch 6415.33 |
| step 27999 |  lr: 0.0000500 | loss  0.0891 | ms/batch 6333.43 |
| step 28019 |  lr: 0.0000500 | loss  0.0890 | ms/batch 6278.53 |
| step 28039 |  lr: 0.0000500 | loss  0.0666 | ms/batch 6419.63 |
| step 28059 |  lr: 0.0000500 | loss  0.0910 | ms/batch 6281.75 |
| step 28079 |  lr: 0.0000500 | loss  0.0986 | ms/batch 6299.83 |
| step 28099 |  lr: 0.0000500 | loss  0.0817 | ms/batch 6409.10 |
| step 28119 |  lr: 0.0000500 | loss  0.0893 | ms/batch 6273.46 |
| step 28139 |  lr: 0.0000500 | loss  0.0787 | ms/batch 6273.02 |
| step 28159 |  lr: 0.0000500 | loss  0.0870 | ms/batch 6173.84 |
| step 28179 |  lr: 0.0000500 | loss  0.0882 | ms/batch 6489.15 |
| step 28199 |  lr: 0.0000500 | loss  0.0958 | ms/batch 6586.95 |
| step 28219 |  lr: 0.0000500 | loss  0.0787 | ms/batch 6421.52 |
| step 28239 |  lr: 0.0000500 | loss  0.1033 | ms/batch 6649.72 |
| step 28259 |  lr: 0.0000500 | loss  0.0877 | ms/batch 6483.74 |
| step 28279 |  lr: 0.0000500 | loss  0.0836 | ms/batch 6391.92 |
| step 28299 |  lr: 0.0000500 | loss  0.1004 | ms/batch 6287.06 |
| step 28319 |  lr: 0.0000500 | loss  0.0738 | ms/batch 6032.52 |
| step 28339 |  lr: 0.0000500 | loss  0.0880 | ms/batch 6490.16 |
| step 28359 |  lr: 0.0000500 | loss  0.0911 | ms/batch 6531.05 |
| step 28379 |  lr: 0.0000500 | loss  0.0963 | ms/batch 6354.52 |
| step 28399 |  lr: 0.0000500 | loss  0.0958 | ms/batch 6415.49 |
| step 28419 |  lr: 0.0000500 | loss  0.0808 | ms/batch 6392.09 |
| step 28439 |  lr: 0.0000500 | loss  0.0865 | ms/batch 6531.32 |
| step 28459 |  lr: 0.0000500 | loss  0.0829 | ms/batch 6136.47 |
| step 28479 |  lr: 0.0000500 | loss  0.1089 | ms/batch 5946.03 |
| step 28499 |  lr: 0.0000500 | loss  0.0778 | ms/batch 6097.09 |
| step 28519 |  lr: 0.0000500 | loss  0.0837 | ms/batch 5796.00 |
| step 28539 |  lr: 0.0000500 | loss  0.0767 | ms/batch 5937.99 |
| step 28559 |  lr: 0.0000500 | loss  0.0978 | ms/batch 5734.89 |
| step 28579 |  lr: 0.0000500 | loss  0.1047 | ms/batch 5829.27 |
-----------------------------------------------------------------------
| step 28580 | dev_acc  0.5037 | test_acc  0.2678 |
train_time : 8970.15 | eval_time : 97.03
-----------------------------------------------------------------------
model saved to ./saved_models/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/medmcqa_best.pt
| step 28599 |  lr: 0.0000500 | loss  0.0598 | ms/batch 6296.59 |
| step 28619 |  lr: 0.0000500 | loss  0.0644 | ms/batch 6202.02 |
| step 28639 |  lr: 0.0000500 | loss  0.0633 | ms/batch 6326.72 |
| step 28659 |  lr: 0.0000500 | loss  0.0740 | ms/batch 6198.56 |
| step 28679 |  lr: 0.0000500 | loss  0.0674 | ms/batch 6038.24 |
| step 28699 |  lr: 0.0000500 | loss  0.0748 | ms/batch 6251.51 |
| step 28719 |  lr: 0.0000500 | loss  0.0756 | ms/batch 6251.88 |
| step 28739 |  lr: 0.0000500 | loss  0.0645 | ms/batch 6201.75 |
| step 28759 |  lr: 0.0000500 | loss  0.0608 | ms/batch 6165.57 |
| step 28779 |  lr: 0.0000500 | loss  0.0767 | ms/batch 6285.45 |
| step 28799 |  lr: 0.0000500 | loss  0.0800 | ms/batch 6239.45 |
| step 28819 |  lr: 0.0000500 | loss  0.0581 | ms/batch 6177.42 |
| step 28839 |  lr: 0.0000500 | loss  0.0621 | ms/batch 6230.63 |
| step 28859 |  lr: 0.0000500 | loss  0.0488 | ms/batch 6228.38 |
| step 28879 |  lr: 0.0000500 | loss  0.0796 | ms/batch 5991.02 |
| step 28899 |  lr: 0.0000500 | loss  0.0591 | ms/batch 6060.55 |
| step 28919 |  lr: 0.0000500 | loss  0.0785 | ms/batch 6300.52 |
| step 28939 |  lr: 0.0000500 | loss  0.0754 | ms/batch 6295.19 |
| step 28959 |  lr: 0.0000500 | loss  0.0761 | ms/batch 6141.27 |
| step 28979 |  lr: 0.0000500 | loss  0.0693 | ms/batch 6041.44 |
| step 28999 |  lr: 0.0000500 | loss  0.0771 | ms/batch 6158.56 |
| step 29019 |  lr: 0.0000500 | loss  0.0629 | ms/batch 6208.22 |
| step 29039 |  lr: 0.0000500 | loss  0.0832 | ms/batch 6169.73 |
| step 29059 |  lr: 0.0000500 | loss  0.0811 | ms/batch 6404.76 |
| step 29079 |  lr: 0.0000500 | loss  0.0711 | ms/batch 6508.35 |
| step 29099 |  lr: 0.0000500 | loss  0.0852 | ms/batch 6057.60 |
| step 29119 |  lr: 0.0000500 | loss  0.0766 | ms/batch 6020.40 |
| step 29139 |  lr: 0.0000500 | loss  0.0670 | ms/batch 5894.22 |
| step 29159 |  lr: 0.0000500 | loss  0.0771 | ms/batch 5964.23 |
| step 29179 |  lr: 0.0000500 | loss  0.0761 | ms/batch 6006.23 |
| step 29199 |  lr: 0.0000500 | loss  0.0916 | ms/batch 5879.71 |
| step 29219 |  lr: 0.0000500 | loss  0.0852 | ms/batch 5882.81 |
| step 29239 |  lr: 0.0000500 | loss  0.0913 | ms/batch 6097.81 |
| step 29259 |  lr: 0.0000500 | loss  0.0693 | ms/batch 6122.26 |
| step 29279 |  lr: 0.0000500 | loss  0.0806 | ms/batch 6143.54 |
| step 29299 |  lr: 0.0000500 | loss  0.0777 | ms/batch 6182.37 |
| step 29319 |  lr: 0.0000500 | loss  0.0806 | ms/batch 6296.33 |
| step 29339 |  lr: 0.0000500 | loss  0.0746 | ms/batch 6285.63 |
| step 29359 |  lr: 0.0000500 | loss  0.0839 | ms/batch 6411.45 |
| step 29379 |  lr: 0.0000500 | loss  0.0823 | ms/batch 6123.88 |
| step 29399 |  lr: 0.0000500 | loss  0.0800 | ms/batch 6481.21 |
| step 29419 |  lr: 0.0000500 | loss  0.0955 | ms/batch 6125.84 |
| step 29439 |  lr: 0.0000500 | loss  0.0793 | ms/batch 6184.99 |
| step 29459 |  lr: 0.0000500 | loss  0.0791 | ms/batch 6011.30 |
| step 29479 |  lr: 0.0000500 | loss  0.0795 | ms/batch 6095.92 |
| step 29499 |  lr: 0.0000500 | loss  0.0768 | ms/batch 6295.96 |
| step 29519 |  lr: 0.0000500 | loss  0.0752 | ms/batch 6053.73 |
| step 29539 |  lr: 0.0000500 | loss  0.0729 | ms/batch 6288.15 |
| step 29559 |  lr: 0.0000500 | loss  0.0953 | ms/batch 6328.07 |
| step 29579 |  lr: 0.0000500 | loss  0.0907 | ms/batch 6325.92 |
| step 29599 |  lr: 0.0000500 | loss  0.0742 | ms/batch 6244.60 |
| step 29619 |  lr: 0.0000500 | loss  0.0758 | ms/batch 6505.29 |
| step 29639 |  lr: 0.0000500 | loss  0.0806 | ms/batch 6392.43 |
| step 29659 |  lr: 0.0000500 | loss  0.0903 | ms/batch 6259.15 |
| step 29679 |  lr: 0.0000500 | loss  0.0884 | ms/batch 6484.56 |
| step 29699 |  lr: 0.0000500 | loss  0.0852 | ms/batch 5467.78 |
| step 29719 |  lr: 0.0000500 | loss  0.0775 | ms/batch 5271.08 |
| step 29739 |  lr: 0.0000500 | loss  0.0790 | ms/batch 5067.88 |
| step 29759 |  lr: 0.0000500 | loss  0.1010 | ms/batch 5144.86 |
| step 29779 |  lr: 0.0000500 | loss  0.0722 | ms/batch 5216.00 |
| step 29799 |  lr: 0.0000500 | loss  0.0882 | ms/batch 5244.84 |
| step 29819 |  lr: 0.0000500 | loss  0.0929 | ms/batch 5130.67 |
| step 29839 |  lr: 0.0000500 | loss  0.0857 | ms/batch 5223.67 |
| step 29859 |  lr: 0.0000500 | loss  0.0809 | ms/batch 5193.29 |
| step 29879 |  lr: 0.0000500 | loss  0.0965 | ms/batch 5166.91 |
| step 29899 |  lr: 0.0000500 | loss  0.0814 | ms/batch 5140.39 |
| step 29919 |  lr: 0.0000500 | loss  0.0858 | ms/batch 5296.11 |
| step 29939 |  lr: 0.0000500 | loss  0.0855 | ms/batch 5325.46 |
| step 29959 |  lr: 0.0000500 | loss  0.1047 | ms/batch 5236.18 |
| step 29979 |  lr: 0.0000500 | loss  0.0899 | ms/batch 5120.22 |
| step 29999 |  lr: 0.0000500 | loss  0.0795 | ms/batch 5332.05 |
-----------------------------------------------------------------------
| step 30009 | dev_acc  0.5018 | test_acc  0.2763 |
train_time : 8531.74 | eval_time : 98.13
-----------------------------------------------------------------------
| step 30019 |  lr: 0.0000500 | loss  0.0803 | ms/batch 2919.07 |
| step 30039 |  lr: 0.0000500 | loss  0.0591 | ms/batch 5310.81 |
| step 30059 |  lr: 0.0000500 | loss  0.0623 | ms/batch 5405.39 |
| step 30079 |  lr: 0.0000500 | loss  0.0532 | ms/batch 5350.37 |
| step 30099 |  lr: 0.0000500 | loss  0.0513 | ms/batch 5312.35 |
| step 30119 |  lr: 0.0000500 | loss  0.0620 | ms/batch 5371.84 |
| step 30139 |  lr: 0.0000500 | loss  0.0639 | ms/batch 5505.60 |
| step 30159 |  lr: 0.0000500 | loss  0.0630 | ms/batch 5426.98 |
| step 30179 |  lr: 0.0000500 | loss  0.0532 | ms/batch 5877.41 |
| step 30199 |  lr: 0.0000500 | loss  0.0633 | ms/batch 6409.98 |
| step 30219 |  lr: 0.0000500 | loss  0.0772 | ms/batch 6385.56 |
| step 30239 |  lr: 0.0000500 | loss  0.0654 | ms/batch 6233.86 |
| step 30259 |  lr: 0.0000500 | loss  0.0710 | ms/batch 6394.21 |
| step 30279 |  lr: 0.0000500 | loss  0.0647 | ms/batch 6522.19 |
| step 30299 |  lr: 0.0000500 | loss  0.0613 | ms/batch 6088.22 |
| step 30319 |  lr: 0.0000500 | loss  0.0601 | ms/batch 6283.15 |
| step 30339 |  lr: 0.0000500 | loss  0.0824 | ms/batch 6159.53 |
| step 30359 |  lr: 0.0000500 | loss  0.0835 | ms/batch 6144.00 |
| step 30379 |  lr: 0.0000500 | loss  0.0631 | ms/batch 6374.87 |
| step 30399 |  lr: 0.0000500 | loss  0.0738 | ms/batch 6068.64 |
| step 30419 |  lr: 0.0000500 | loss  0.0708 | ms/batch 6016.48 |
| step 30439 |  lr: 0.0000500 | loss  0.0755 | ms/batch 6049.98 |
| step 30459 |  lr: 0.0000500 | loss  0.0650 | ms/batch 6192.27 |
| step 30479 |  lr: 0.0000500 | loss  0.0705 | ms/batch 6110.60 |
| step 30499 |  lr: 0.0000500 | loss  0.0753 | ms/batch 6041.18 |
| step 30519 |  lr: 0.0000500 | loss  0.0782 | ms/batch 6197.12 |
| step 30539 |  lr: 0.0000500 | loss  0.0542 | ms/batch 6350.23 |
| step 30559 |  lr: 0.0000500 | loss  0.0684 | ms/batch 6538.78 |
| step 30579 |  lr: 0.0000500 | loss  0.0878 | ms/batch 6174.28 |
| step 30599 |  lr: 0.0000500 | loss  0.0794 | ms/batch 6483.36 |
| step 30619 |  lr: 0.0000500 | loss  0.0654 | ms/batch 6357.07 |
| step 30639 |  lr: 0.0000500 | loss  0.0765 | ms/batch 6363.82 |
| step 30659 |  lr: 0.0000500 | loss  0.0866 | ms/batch 6392.66 |
| step 30679 |  lr: 0.0000500 | loss  0.0742 | ms/batch 6315.15 |
| step 30699 |  lr: 0.0000500 | loss  0.0741 | ms/batch 6340.35 |
| step 30719 |  lr: 0.0000500 | loss  0.0645 | ms/batch 6388.54 |
| step 30739 |  lr: 0.0000500 | loss  0.0748 | ms/batch 6588.50 |
| step 30759 |  lr: 0.0000500 | loss  0.0712 | ms/batch 6577.67 |
| step 30779 |  lr: 0.0000500 | loss  0.0786 | ms/batch 6442.99 |
| step 30799 |  lr: 0.0000500 | loss  0.0810 | ms/batch 6478.69 |
| step 30819 |  lr: 0.0000500 | loss  0.0889 | ms/batch 6130.95 |
| step 30839 |  lr: 0.0000500 | loss  0.0818 | ms/batch 6274.09 |
| step 30859 |  lr: 0.0000500 | loss  0.0679 | ms/batch 6339.33 |
| step 30879 |  lr: 0.0000500 | loss  0.0770 | ms/batch 6218.00 |
| step 30899 |  lr: 0.0000500 | loss  0.0627 | ms/batch 6277.93 |
| step 30919 |  lr: 0.0000500 | loss  0.0799 | ms/batch 6475.36 |
| step 30939 |  lr: 0.0000500 | loss  0.0804 | ms/batch 6409.91 |
| step 30959 |  lr: 0.0000500 | loss  0.0752 | ms/batch 6530.48 |
| step 30979 |  lr: 0.0000500 | loss  0.0713 | ms/batch 6640.49 |
| step 30999 |  lr: 0.0000500 | loss  0.0806 | ms/batch 5989.34 |
| step 31019 |  lr: 0.0000500 | loss  0.0962 | ms/batch 6035.21 |
| step 31039 |  lr: 0.0000500 | loss  0.0798 | ms/batch 6201.82 |
| step 31059 |  lr: 0.0000500 | loss  0.0709 | ms/batch 6134.77 |
| step 31079 |  lr: 0.0000500 | loss  0.0657 | ms/batch 6019.14 |
| step 31099 |  lr: 0.0000500 | loss  0.0904 | ms/batch 6351.22 |
| step 31119 |  lr: 0.0000500 | loss  0.0762 | ms/batch 6284.43 |
| step 31139 |  lr: 0.0000500 | loss  0.0910 | ms/batch 6047.02 |
| step 31159 |  lr: 0.0000500 | loss  0.0894 | ms/batch 6254.51 |
| step 31179 |  lr: 0.0000500 | loss  0.0866 | ms/batch 6263.14 |
| step 31199 |  lr: 0.0000500 | loss  0.0762 | ms/batch 6414.30 |
| step 31219 |  lr: 0.0000500 | loss  0.0791 | ms/batch 6502.42 |
| step 31239 |  lr: 0.0000500 | loss  0.0814 | ms/batch 6599.67 |
| step 31259 |  lr: 0.0000500 | loss  0.0730 | ms/batch 6424.76 |
| step 31279 |  lr: 0.0000500 | loss  0.0726 | ms/batch 6501.46 |
| step 31299 |  lr: 0.0000500 | loss  0.0913 | ms/batch 6528.17 |
| step 31319 |  lr: 0.0000500 | loss  0.0873 | ms/batch 6508.03 |
| step 31339 |  lr: 0.0000500 | loss  0.0800 | ms/batch 6457.16 |
| step 31359 |  lr: 0.0000500 | loss  0.0732 | ms/batch 6534.31 |
| step 31379 |  lr: 0.0000500 | loss  0.0820 | ms/batch 6551.57 |
| step 31399 |  lr: 0.0000500 | loss  0.0855 | ms/batch 6488.30 |
| step 31419 |  lr: 0.0000500 | loss  0.0830 | ms/batch 6389.95 |
-----------------------------------------------------------------------
| step 31438 | dev_acc  0.4956 | test_acc  0.2753 |
train_time : 8886.86 | eval_time : 102.17
-----------------------------------------------------------------------
| step 31439 |  lr: 0.0000500 | loss  0.0901 | ms/batch  656.25 |
| step 31459 |  lr: 0.0000500 | loss  0.0405 | ms/batch 6783.04 |
| step 31479 |  lr: 0.0000500 | loss  0.0547 | ms/batch 6413.81 |
| step 31499 |  lr: 0.0000500 | loss  0.0559 | ms/batch 6393.31 |
| step 31519 |  lr: 0.0000500 | loss  0.0687 | ms/batch 6327.37 |
| step 31539 |  lr: 0.0000500 | loss  0.0633 | ms/batch 6406.16 |
| step 31559 |  lr: 0.0000500 | loss  0.0675 | ms/batch 6016.25 |
| step 31579 |  lr: 0.0000500 | loss  0.0497 | ms/batch 6141.20 |
| step 31599 |  lr: 0.0000500 | loss  0.0752 | ms/batch 6192.25 |
| step 31619 |  lr: 0.0000500 | loss  0.0673 | ms/batch 6184.45 |
| step 31639 |  lr: 0.0000500 | loss  0.0708 | ms/batch 6132.56 |
| step 31659 |  lr: 0.0000500 | loss  0.0743 | ms/batch 6243.06 |
| step 31679 |  lr: 0.0000500 | loss  0.0632 | ms/batch 6286.16 |
| step 31699 |  lr: 0.0000500 | loss  0.0625 | ms/batch 6390.09 |
| step 31719 |  lr: 0.0000500 | loss  0.0626 | ms/batch 6449.71 |
| step 31739 |  lr: 0.0000500 | loss  0.0861 | ms/batch 6377.06 |
| step 31759 |  lr: 0.0000500 | loss  0.0721 | ms/batch 6127.38 |
| step 31779 |  lr: 0.0000500 | loss  0.0629 | ms/batch 5917.52 |
| step 31799 |  lr: 0.0000500 | loss  0.0653 | ms/batch 6161.02 |
| step 31819 |  lr: 0.0000500 | loss  0.0589 | ms/batch 6313.51 |
| step 31839 |  lr: 0.0000500 | loss  0.0674 | ms/batch 6534.13 |
| step 31859 |  lr: 0.0000500 | loss  0.0860 | ms/batch 6397.24 |
| step 31879 |  lr: 0.0000500 | loss  0.0646 | ms/batch 6556.56 |
| step 31899 |  lr: 0.0000500 | loss  0.0661 | ms/batch 6637.50 |
| step 31919 |  lr: 0.0000500 | loss  0.0578 | ms/batch 6166.57 |
| step 31939 |  lr: 0.0000500 | loss  0.0690 | ms/batch 6124.41 |
| step 31959 |  lr: 0.0000500 | loss  0.0648 | ms/batch 6215.16 |
| step 31979 |  lr: 0.0000500 | loss  0.0761 | ms/batch 6198.50 |
| step 31999 |  lr: 0.0000500 | loss  0.0710 | ms/batch 6069.82 |
| step 32019 |  lr: 0.0000500 | loss  0.0694 | ms/batch 6346.25 |
| step 32039 |  lr: 0.0000500 | loss  0.0641 | ms/batch 5885.52 |
| step 32059 |  lr: 0.0000500 | loss  0.0679 | ms/batch 5967.16 |
| step 32079 |  lr: 0.0000500 | loss  0.0703 | ms/batch 5952.42 |
| step 32099 |  lr: 0.0000500 | loss  0.0660 | ms/batch 6326.19 |
| step 32119 |  lr: 0.0000500 | loss  0.0901 | ms/batch 6117.94 |
| step 32139 |  lr: 0.0000500 | loss  0.0810 | ms/batch 6229.83 |
| step 32159 |  lr: 0.0000500 | loss  0.0616 | ms/batch 6170.28 |
| step 32179 |  lr: 0.0000500 | loss  0.0769 | ms/batch 6303.82 |
| step 32199 |  lr: 0.0000500 | loss  0.0723 | ms/batch 6300.91 |
| step 32219 |  lr: 0.0000500 | loss  0.0755 | ms/batch 6337.20 |
| step 32239 |  lr: 0.0000500 | loss  0.0874 | ms/batch 6265.59 |
| step 32259 |  lr: 0.0000500 | loss  0.0685 | ms/batch 6260.56 |
| step 32279 |  lr: 0.0000500 | loss  0.0816 | ms/batch 6444.17 |
| step 32299 |  lr: 0.0000500 | loss  0.0812 | ms/batch 6144.64 |
| step 32319 |  lr: 0.0000500 | loss  0.0759 | ms/batch 5917.57 |
| step 32339 |  lr: 0.0000500 | loss  0.0738 | ms/batch 6257.20 |
| step 32359 |  lr: 0.0000500 | loss  0.0617 | ms/batch 6133.47 |
| step 32379 |  lr: 0.0000500 | loss  0.0680 | ms/batch 6390.54 |
| step 32399 |  lr: 0.0000500 | loss  0.0760 | ms/batch 6442.45 |
| step 32419 |  lr: 0.0000500 | loss  0.0663 | ms/batch 6102.15 |
| step 32439 |  lr: 0.0000500 | loss  0.0839 | ms/batch 6128.95 |
| step 32459 |  lr: 0.0000500 | loss  0.0715 | ms/batch 6138.92 |
| step 32479 |  lr: 0.0000500 | loss  0.0726 | ms/batch 6141.48 |
| step 32499 |  lr: 0.0000500 | loss  0.0623 | ms/batch 6164.70 |
| step 32519 |  lr: 0.0000500 | loss  0.0716 | ms/batch 6612.07 |
| step 32539 |  lr: 0.0000500 | loss  0.0817 | ms/batch 6419.54 |
| step 32559 |  lr: 0.0000500 | loss  0.0888 | ms/batch 6559.65 |
| step 32579 |  lr: 0.0000500 | loss  0.0720 | ms/batch 6429.39 |
| step 32599 |  lr: 0.0000500 | loss  0.0588 | ms/batch 6077.21 |
| step 32619 |  lr: 0.0000500 | loss  0.0717 | ms/batch 6268.05 |
| step 32639 |  lr: 0.0000500 | loss  0.0837 | ms/batch 6406.80 |
| step 32659 |  lr: 0.0000500 | loss  0.0699 | ms/batch 6221.29 |
| step 32679 |  lr: 0.0000500 | loss  0.0805 | ms/batch 6322.89 |
| step 32699 |  lr: 0.0000500 | loss  0.0694 | ms/batch 5983.09 |
| step 32719 |  lr: 0.0000500 | loss  0.0635 | ms/batch 6043.95 |
| step 32739 |  lr: 0.0000500 | loss  0.0677 | ms/batch 6390.23 |
| step 32759 |  lr: 0.0000500 | loss  0.0870 | ms/batch 6115.21 |
| step 32779 |  lr: 0.0000500 | loss  0.0916 | ms/batch 6136.38 |
| step 32799 |  lr: 0.0000500 | loss  0.0726 | ms/batch 6026.56 |
| step 32819 |  lr: 0.0000500 | loss  0.0892 | ms/batch 6333.32 |
| step 32839 |  lr: 0.0000500 | loss  0.0801 | ms/batch 6232.80 |
| step 32859 |  lr: 0.0000500 | loss  0.0772 | ms/batch 6372.59 |
-----------------------------------------------------------------------
| step 32867 | dev_acc  0.5035 | test_acc  0.2709 |
train_time : 8932.48 | eval_time : 97.99
-----------------------------------------------------------------------
| step 32879 |  lr: 0.0000500 | loss  0.0713 | ms/batch 4331.46 |
| step 32899 |  lr: 0.0000500 | loss  0.0492 | ms/batch 6329.29 |
| step 32919 |  lr: 0.0000500 | loss  0.0653 | ms/batch 6493.80 |
| step 32939 |  lr: 0.0000500 | loss  0.0589 | ms/batch 6365.54 |
| step 32959 |  lr: 0.0000500 | loss  0.0504 | ms/batch 6418.23 |
| step 32979 |  lr: 0.0000500 | loss  0.0625 | ms/batch 6545.79 |
| step 32999 |  lr: 0.0000500 | loss  0.0471 | ms/batch 6320.80 |
| step 33019 |  lr: 0.0000500 | loss  0.0457 | ms/batch 6319.13 |
| step 33039 |  lr: 0.0000500 | loss  0.0735 | ms/batch 6308.79 |
| step 33059 |  lr: 0.0000500 | loss  0.0559 | ms/batch 6400.11 |
| step 33079 |  lr: 0.0000500 | loss  0.0605 | ms/batch 6517.61 |
| step 33099 |  lr: 0.0000500 | loss  0.0661 | ms/batch 6460.49 |
| step 33119 |  lr: 0.0000500 | loss  0.0636 | ms/batch 6573.21 |
| step 33139 |  lr: 0.0000500 | loss  0.0570 | ms/batch 6419.54 |
| step 33159 |  lr: 0.0000500 | loss  0.0661 | ms/batch 6280.36 |
| step 33179 |  lr: 0.0000500 | loss  0.0696 | ms/batch 6603.27 |
| step 33199 |  lr: 0.0000500 | loss  0.0576 | ms/batch 6286.42 |
| step 33219 |  lr: 0.0000500 | loss  0.0669 | ms/batch 6462.78 |
| step 33239 |  lr: 0.0000500 | loss  0.0648 | ms/batch 6345.71 |
| step 33259 |  lr: 0.0000500 | loss  0.0628 | ms/batch 6530.71 |
| step 33279 |  lr: 0.0000500 | loss  0.0690 | ms/batch 6345.23 |
| step 33299 |  lr: 0.0000500 | loss  0.0663 | ms/batch 6419.17 |
| step 33319 |  lr: 0.0000500 | loss  0.0704 | ms/batch 6495.38 |
| step 33339 |  lr: 0.0000500 | loss  0.0622 | ms/batch 6374.16 |
| step 33359 |  lr: 0.0000500 | loss  0.0676 | ms/batch 6279.19 |
| step 33379 |  lr: 0.0000500 | loss  0.0679 | ms/batch 6269.86 |
| step 33399 |  lr: 0.0000500 | loss  0.0693 | ms/batch 6334.40 |
| step 33419 |  lr: 0.0000500 | loss  0.0699 | ms/batch 6319.15 |
| step 33439 |  lr: 0.0000500 | loss  0.0800 | ms/batch 6344.32 |
| step 33459 |  lr: 0.0000500 | loss  0.0784 | ms/batch 6338.58 |
| step 33479 |  lr: 0.0000500 | loss  0.0725 | ms/batch 6241.02 |
| step 33499 |  lr: 0.0000500 | loss  0.0760 | ms/batch 6385.56 |
| step 33519 |  lr: 0.0000500 | loss  0.0627 | ms/batch 6072.82 |
| step 33539 |  lr: 0.0000500 | loss  0.0653 | ms/batch 6583.31 |
| step 33559 |  lr: 0.0000500 | loss  0.0728 | ms/batch 6465.92 |
| step 33579 |  lr: 0.0000500 | loss  0.0774 | ms/batch 6263.73 |
| step 33599 |  lr: 0.0000500 | loss  0.0679 | ms/batch 6584.54 |
| step 33619 |  lr: 0.0000500 | loss  0.0732 | ms/batch 6408.47 |
| step 33639 |  lr: 0.0000500 | loss  0.0821 | ms/batch 5795.19 |
| step 33659 |  lr: 0.0000500 | loss  0.0670 | ms/batch 6047.28 |
| step 33679 |  lr: 0.0000500 | loss  0.0884 | ms/batch 6356.67 |
| step 33699 |  lr: 0.0000500 | loss  0.0757 | ms/batch 6161.48 |
| step 33719 |  lr: 0.0000500 | loss  0.0623 | ms/batch 6033.78 |
| step 33739 |  lr: 0.0000500 | loss  0.0685 | ms/batch 6116.51 |
| step 33759 |  lr: 0.0000500 | loss  0.0847 | ms/batch 6170.06 |
| step 33779 |  lr: 0.0000500 | loss  0.0758 | ms/batch 6035.81 |
| step 33799 |  lr: 0.0000500 | loss  0.0646 | ms/batch 6227.80 |
| step 33819 |  lr: 0.0000500 | loss  0.0480 | ms/batch 6319.51 |
| step 33839 |  lr: 0.0000500 | loss  0.0670 | ms/batch 6293.40 |
| step 33859 |  lr: 0.0000500 | loss  0.0778 | ms/batch 6155.11 |
| step 33879 |  lr: 0.0000500 | loss  0.0618 | ms/batch 6124.52 |
| step 33899 |  lr: 0.0000500 | loss  0.0857 | ms/batch 6439.74 |
| step 33919 |  lr: 0.0000500 | loss  0.0616 | ms/batch 6361.87 |
| step 33939 |  lr: 0.0000500 | loss  0.0652 | ms/batch 6232.39 |
| step 33959 |  lr: 0.0000500 | loss  0.0708 | ms/batch 6095.11 |
| step 33979 |  lr: 0.0000500 | loss  0.0752 | ms/batch 5317.12 |
| step 33999 |  lr: 0.0000500 | loss  0.0773 | ms/batch 5296.87 |
| step 34019 |  lr: 0.0000500 | loss  0.0745 | ms/batch 6304.01 |
| step 34039 |  lr: 0.0000500 | loss  0.0661 | ms/batch 6005.18 |
| step 34059 |  lr: 0.0000500 | loss  0.0854 | ms/batch 5995.50 |
| step 34079 |  lr: 0.0000500 | loss  0.0782 | ms/batch 6208.16 |
| step 34099 |  lr: 0.0000500 | loss  0.0652 | ms/batch 5985.23 |
| step 34119 |  lr: 0.0000500 | loss  0.0758 | ms/batch 5981.01 |
| step 34139 |  lr: 0.0000500 | loss  0.0830 | ms/batch 6186.17 |
| step 34159 |  lr: 0.0000500 | loss  0.0774 | ms/batch 6272.88 |
| step 34179 |  lr: 0.0000500 | loss  0.0904 | ms/batch 6423.87 |
| step 34199 |  lr: 0.0000500 | loss  0.0694 | ms/batch 6297.68 |
| step 34219 |  lr: 0.0000500 | loss  0.0798 | ms/batch 6383.81 |
| step 34239 |  lr: 0.0000500 | loss  0.0718 | ms/batch 6227.53 |
| step 34259 |  lr: 0.0000500 | loss  0.0748 | ms/batch 6179.10 |
| step 34279 |  lr: 0.0000500 | loss  0.0780 | ms/batch 6076.22 |
-----------------------------------------------------------------------
| step 34296 | dev_acc  0.5106 | test_acc  0.2665 |
train_time : 8952.60 | eval_time : 97.21
-----------------------------------------------------------------------
model saved to ./saved_models/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/medmcqa_best.pt
| step 34299 |  lr: 0.0000500 | loss  0.0726 | ms/batch 1283.91 |
| step 34319 |  lr: 0.0000500 | loss  0.0513 | ms/batch 6301.20 |
| step 34339 |  lr: 0.0000500 | loss  0.0797 | ms/batch 6339.64 |
| step 34359 |  lr: 0.0000500 | loss  0.0471 | ms/batch 6447.39 |
| step 34379 |  lr: 0.0000500 | loss  0.0636 | ms/batch 6276.84 |
| step 34399 |  lr: 0.0000500 | loss  0.0710 | ms/batch 6432.55 |
| step 34419 |  lr: 0.0000500 | loss  0.0514 | ms/batch 6552.49 |
| step 34439 |  lr: 0.0000500 | loss  0.0790 | ms/batch 6453.71 |
| step 34459 |  lr: 0.0000500 | loss  0.0568 | ms/batch 6474.91 |
| step 34479 |  lr: 0.0000500 | loss  0.0515 | ms/batch 6333.45 |
| step 34499 |  lr: 0.0000500 | loss  0.0586 | ms/batch 6288.37 |
| step 34519 |  lr: 0.0000500 | loss  0.0547 | ms/batch 6478.10 |
| step 34539 |  lr: 0.0000500 | loss  0.0687 | ms/batch 6772.78 |
| step 34559 |  lr: 0.0000500 | loss  0.0456 | ms/batch 6539.46 |
| step 34579 |  lr: 0.0000500 | loss  0.0551 | ms/batch 6303.65 |
| step 34599 |  lr: 0.0000500 | loss  0.0484 | ms/batch 5970.04 |
| step 34619 |  lr: 0.0000500 | loss  0.0545 | ms/batch 5984.17 |
| step 34639 |  lr: 0.0000500 | loss  0.0565 | ms/batch 6078.26 |
| step 34659 |  lr: 0.0000500 | loss  0.0735 | ms/batch 5916.72 |
| step 34679 |  lr: 0.0000500 | loss  0.0670 | ms/batch 6263.14 |
| step 34699 |  lr: 0.0000500 | loss  0.0596 | ms/batch 6306.10 |
| step 34719 |  lr: 0.0000500 | loss  0.0622 | ms/batch 6324.70 |
| step 34739 |  lr: 0.0000500 | loss  0.0795 | ms/batch 6419.96 |
| step 34759 |  lr: 0.0000500 | loss  0.0622 | ms/batch 6451.65 |
| step 34779 |  lr: 0.0000500 | loss  0.0618 | ms/batch 6130.49 |
| step 34799 |  lr: 0.0000500 | loss  0.0704 | ms/batch 6128.72 |
| step 34819 |  lr: 0.0000500 | loss  0.0593 | ms/batch 6056.58 |
| step 34839 |  lr: 0.0000500 | loss  0.0722 | ms/batch 6210.08 |
| step 34859 |  lr: 0.0000500 | loss  0.0774 | ms/batch 6188.52 |
| step 34879 |  lr: 0.0000500 | loss  0.0544 | ms/batch 6332.18 |
| step 34899 |  lr: 0.0000500 | loss  0.0726 | ms/batch 6445.37 |
| step 34919 |  lr: 0.0000500 | loss  0.0734 | ms/batch 6315.59 |
| step 34939 |  lr: 0.0000500 | loss  0.0707 | ms/batch 6234.82 |
| step 34959 |  lr: 0.0000500 | loss  0.0580 | ms/batch 6315.02 |
| step 34979 |  lr: 0.0000500 | loss  0.0740 | ms/batch 6183.29 |
| step 34999 |  lr: 0.0000500 | loss  0.0559 | ms/batch 6288.17 |
| step 35019 |  lr: 0.0000500 | loss  0.0813 | ms/batch 6447.32 |
| step 35039 |  lr: 0.0000500 | loss  0.0616 | ms/batch 6139.70 |
| step 35059 |  lr: 0.0000500 | loss  0.0646 | ms/batch 6467.81 |
| step 35079 |  lr: 0.0000500 | loss  0.0631 | ms/batch 6516.22 |
| step 35099 |  lr: 0.0000500 | loss  0.0621 | ms/batch 6450.64 |
| step 35119 |  lr: 0.0000500 | loss  0.0688 | ms/batch 6389.57 |
| step 35139 |  lr: 0.0000500 | loss  0.0642 | ms/batch 6419.32 |
| step 35159 |  lr: 0.0000500 | loss  0.0662 | ms/batch 6187.89 |
| step 35179 |  lr: 0.0000500 | loss  0.0721 | ms/batch 6399.85 |
| step 35199 |  lr: 0.0000500 | loss  0.0756 | ms/batch 6533.05 |
| step 35219 |  lr: 0.0000500 | loss  0.0593 | ms/batch 6530.34 |
| step 35239 |  lr: 0.0000500 | loss  0.0664 | ms/batch 6402.12 |
| step 35259 |  lr: 0.0000500 | loss  0.0687 | ms/batch 6294.79 |
| step 35279 |  lr: 0.0000500 | loss  0.0553 | ms/batch 6293.84 |
| step 35299 |  lr: 0.0000500 | loss  0.1010 | ms/batch 6378.75 |
| step 35319 |  lr: 0.0000500 | loss  0.0829 | ms/batch 6351.89 |
| step 35339 |  lr: 0.0000500 | loss  0.0590 | ms/batch 6384.46 |
| step 35359 |  lr: 0.0000500 | loss  0.0674 | ms/batch 6377.27 |
| step 35379 |  lr: 0.0000500 | loss  0.0757 | ms/batch 6515.72 |
| step 35399 |  lr: 0.0000500 | loss  0.0832 | ms/batch 6656.28 |
| step 35419 |  lr: 0.0000500 | loss  0.0664 | ms/batch 6470.04 |
| step 35439 |  lr: 0.0000500 | loss  0.0801 | ms/batch 6161.63 |
| step 35459 |  lr: 0.0000500 | loss  0.0793 | ms/batch 6202.05 |
| step 35479 |  lr: 0.0000500 | loss  0.0648 | ms/batch 6002.49 |
| step 35499 |  lr: 0.0000500 | loss  0.0571 | ms/batch 6204.31 |
| step 35519 |  lr: 0.0000500 | loss  0.0663 | ms/batch 6274.30 |
| step 35539 |  lr: 0.0000500 | loss  0.0844 | ms/batch 6038.61 |
| step 35559 |  lr: 0.0000500 | loss  0.0726 | ms/batch 6256.07 |
| step 35579 |  lr: 0.0000500 | loss  0.0662 | ms/batch 6222.08 |
| step 35599 |  lr: 0.0000500 | loss  0.0632 | ms/batch 6123.65 |
| step 35619 |  lr: 0.0000500 | loss  0.0694 | ms/batch 6491.15 |
| step 35639 |  lr: 0.0000500 | loss  0.0754 | ms/batch 6322.69 |
| step 35659 |  lr: 0.0000500 | loss  0.0733 | ms/batch 6641.00 |
| step 35679 |  lr: 0.0000500 | loss  0.0557 | ms/batch 6395.77 |
| step 35699 |  lr: 0.0000500 | loss  0.0744 | ms/batch 6577.71 |
| step 35719 |  lr: 0.0000500 | loss  0.0588 | ms/batch 6507.17 |
-----------------------------------------------------------------------
| step 35725 | dev_acc  0.5025 | test_acc  0.2711 |
train_time : 9045.63 | eval_time : 101.72
-----------------------------------------------------------------------
| step 35739 |  lr: 0.0000500 | loss  0.0693 | ms/batch 4944.73 |
| step 35759 |  lr: 0.0000500 | loss  0.0478 | ms/batch 6442.69 |
| step 35779 |  lr: 0.0000500 | loss  0.0642 | ms/batch 6294.64 |
| step 35799 |  lr: 0.0000500 | loss  0.0513 | ms/batch 6369.64 |
| step 35819 |  lr: 0.0000500 | loss  0.0521 | ms/batch 6311.15 |
| step 35839 |  lr: 0.0000500 | loss  0.0570 | ms/batch 6618.23 |
| step 35859 |  lr: 0.0000500 | loss  0.0533 | ms/batch 6345.15 |
| step 35879 |  lr: 0.0000500 | loss  0.0569 | ms/batch 6247.89 |
| step 35899 |  lr: 0.0000500 | loss  0.0605 | ms/batch 6163.12 |
| step 35919 |  lr: 0.0000500 | loss  0.0612 | ms/batch 6012.36 |
| step 35939 |  lr: 0.0000500 | loss  0.0614 | ms/batch 6047.68 |
| step 35959 |  lr: 0.0000500 | loss  0.0558 | ms/batch 6033.42 |
| step 35979 |  lr: 0.0000500 | loss  0.0566 | ms/batch 6066.78 |
| step 35999 |  lr: 0.0000500 | loss  0.0680 | ms/batch 6004.49 |
| step 36019 |  lr: 0.0000500 | loss  0.0597 | ms/batch 6096.62 |
| step 36039 |  lr: 0.0000500 | loss  0.0521 | ms/batch 6103.92 |
| step 36059 |  lr: 0.0000500 | loss  0.0542 | ms/batch 6189.17 |
| step 36079 |  lr: 0.0000500 | loss  0.0657 | ms/batch 6063.94 |
| step 36099 |  lr: 0.0000500 | loss  0.0547 | ms/batch 6251.14 |
| step 36119 |  lr: 0.0000500 | loss  0.0616 | ms/batch 6303.70 |
| step 36139 |  lr: 0.0000500 | loss  0.0561 | ms/batch 6236.07 |
| step 36159 |  lr: 0.0000500 | loss  0.0478 | ms/batch 6021.93 |
| step 36179 |  lr: 0.0000500 | loss  0.0608 | ms/batch 6200.28 |
| step 36199 |  lr: 0.0000500 | loss  0.0685 | ms/batch 6089.32 |
| step 36219 |  lr: 0.0000500 | loss  0.0602 | ms/batch 6100.49 |
| step 36239 |  lr: 0.0000500 | loss  0.0628 | ms/batch 6155.61 |
| step 36259 |  lr: 0.0000500 | loss  0.0592 | ms/batch 6047.84 |
| step 36279 |  lr: 0.0000500 | loss  0.0683 | ms/batch 6371.75 |
| step 36299 |  lr: 0.0000500 | loss  0.0596 | ms/batch 6271.58 |
| step 36319 |  lr: 0.0000500 | loss  0.0833 | ms/batch 6381.81 |
| step 36339 |  lr: 0.0000500 | loss  0.0440 | ms/batch 6113.68 |
| step 36359 |  lr: 0.0000500 | loss  0.0838 | ms/batch 6188.27 |
| step 36379 |  lr: 0.0000500 | loss  0.0562 | ms/batch 6341.08 |
| step 36399 |  lr: 0.0000500 | loss  0.0596 | ms/batch 6351.62 |
| step 36419 |  lr: 0.0000500 | loss  0.0605 | ms/batch 6431.12 |
| step 36439 |  lr: 0.0000500 | loss  0.0793 | ms/batch 6569.21 |
| step 36459 |  lr: 0.0000500 | loss  0.0669 | ms/batch 6381.55 |
| step 36479 |  lr: 0.0000500 | loss  0.0658 | ms/batch 6416.98 |
| step 36499 |  lr: 0.0000500 | loss  0.0608 | ms/batch 6427.85 |
| step 36519 |  lr: 0.0000500 | loss  0.0555 | ms/batch 6370.66 |
| step 36539 |  lr: 0.0000500 | loss  0.0692 | ms/batch 6488.06 |
| step 36559 |  lr: 0.0000500 | loss  0.0622 | ms/batch 6428.24 |
| step 36579 |  lr: 0.0000500 | loss  0.0705 | ms/batch 6449.05 |
| step 36599 |  lr: 0.0000500 | loss  0.0614 | ms/batch 6639.93 |
| step 36619 |  lr: 0.0000500 | loss  0.0606 | ms/batch 6419.38 |
| step 36639 |  lr: 0.0000500 | loss  0.0611 | ms/batch 6546.51 |
| step 36659 |  lr: 0.0000500 | loss  0.0638 | ms/batch 6123.17 |
| step 36679 |  lr: 0.0000500 | loss  0.0629 | ms/batch 6272.02 |
| step 36699 |  lr: 0.0000500 | loss  0.0726 | ms/batch 6204.99 |
| step 36719 |  lr: 0.0000500 | loss  0.0492 | ms/batch 5908.97 |
| step 36739 |  lr: 0.0000500 | loss  0.0729 | ms/batch 6179.78 |
| step 36759 |  lr: 0.0000500 | loss  0.0599 | ms/batch 6247.83 |
| step 36779 |  lr: 0.0000500 | loss  0.0625 | ms/batch 6122.07 |
| step 36799 |  lr: 0.0000500 | loss  0.0639 | ms/batch 6135.31 |
| step 36819 |  lr: 0.0000500 | loss  0.0704 | ms/batch 6175.79 |
| step 36839 |  lr: 0.0000500 | loss  0.0660 | ms/batch 6087.05 |
| step 36859 |  lr: 0.0000500 | loss  0.0669 | ms/batch 6120.36 |
| step 36879 |  lr: 0.0000500 | loss  0.0603 | ms/batch 6048.17 |
| step 36899 |  lr: 0.0000500 | loss  0.0662 | ms/batch 6077.98 |
| step 36919 |  lr: 0.0000500 | loss  0.0811 | ms/batch 6200.11 |
| step 36939 |  lr: 0.0000500 | loss  0.0792 | ms/batch 5914.38 |
| step 36959 |  lr: 0.0000500 | loss  0.0676 | ms/batch 6364.84 |
| step 36979 |  lr: 0.0000500 | loss  0.0757 | ms/batch 6492.94 |
| step 36999 |  lr: 0.0000500 | loss  0.0787 | ms/batch 6499.42 |
| step 37019 |  lr: 0.0000500 | loss  0.0707 | ms/batch 6653.90 |
| step 37039 |  lr: 0.0000500 | loss  0.0697 | ms/batch 6438.69 |
| step 37059 |  lr: 0.0000500 | loss  0.0804 | ms/batch 6513.47 |
| step 37079 |  lr: 0.0000500 | loss  0.0720 | ms/batch 6471.66 |
| step 37099 |  lr: 0.0000500 | loss  0.0695 | ms/batch 6471.07 |
| step 37119 |  lr: 0.0000500 | loss  0.0766 | ms/batch 6411.35 |
| step 37139 |  lr: 0.0000500 | loss  0.0681 | ms/batch 6532.54 |
-----------------------------------------------------------------------
| step 37154 | dev_acc  0.5164 | test_acc  0.2706 |
train_time : 8966.12 | eval_time : 98.01
-----------------------------------------------------------------------
model saved to ./saved_models/medmcqa/drlk__ds_medmcqa__enc_cambridgeltl--SapBERT-from-PubMedBERT-fulltext__gnn_4__sd_0__20220814_105350/medmcqa_best.pt
| step 37159 |  lr: 0.0000500 | loss  0.0595 | ms/batch 1895.20 |
| step 37179 |  lr: 0.0000500 | loss  0.0558 | ms/batch 6370.27 |
| step 37199 |  lr: 0.0000500 | loss  0.0452 | ms/batch 6559.08 |
| step 37219 |  lr: 0.0000500 | loss  0.0489 | ms/batch 6315.53 |
| step 37239 |  lr: 0.0000500 | loss  0.0448 | ms/batch 6148.59 |
| step 37259 |  lr: 0.0000500 | loss  0.0483 | ms/batch 6151.59 |
| step 37279 |  lr: 0.0000500 | loss  0.0550 | ms/batch 6296.90 |
| step 37299 |  lr: 0.0000500 | loss  0.0544 | ms/batch 6137.22 |
| step 37319 |  lr: 0.0000500 | loss  0.0590 | ms/batch 6412.65 |
| step 37339 |  lr: 0.0000500 | loss  0.0670 | ms/batch 6528.04 |
| step 37359 |  lr: 0.0000500 | loss  0.0536 | ms/batch 6353.43 |
| step 37379 |  lr: 0.0000500 | loss  0.0661 | ms/batch 6441.36 |
| step 37399 |  lr: 0.0000500 | loss  0.0589 | ms/batch 6324.21 |
| step 37419 |  lr: 0.0000500 | loss  0.0524 | ms/batch 6104.58 |
| step 37439 |  lr: 0.0000500 | loss  0.0595 | ms/batch 6114.93 |
| step 37459 |  lr: 0.0000500 | loss  0.0536 | ms/batch 6094.71 |
| step 37479 |  lr: 0.0000500 | loss  0.0786 | ms/batch 6173.21 |
| step 37499 |  lr: 0.0000500 | loss  0.0668 | ms/batch 6093.70 |
| step 37519 |  lr: 0.0000500 | loss  0.0442 | ms/batch 6307.40 |
| step 37539 |  lr: 0.0000500 | loss  0.0463 | ms/batch 6168.86 |
| step 37559 |  lr: 0.0000500 | loss  0.0557 | ms/batch 6162.44 |
| step 37579 |  lr: 0.0000500 | loss  0.0603 | ms/batch 6067.86 |
| step 37599 |  lr: 0.0000500 | loss  0.0623 | ms/batch 6060.10 |
| step 37619 |  lr: 0.0000500 | loss  0.0577 | ms/batch 5934.46 |
| step 37639 |  lr: 0.0000500 | loss  0.0583 | ms/batch 6097.21 |
| step 37659 |  lr: 0.0000500 | loss  0.0557 | ms/batch 6327.49 |
| step 37679 |  lr: 0.0000500 | loss  0.0577 | ms/batch 6190.95 |
| step 37699 |  lr: 0.0000500 | loss  0.0743 | ms/batch 6023.92 |
| step 37719 |  lr: 0.0000500 | loss  0.0674 | ms/batch 6366.63 |
| step 37739 |  lr: 0.0000500 | loss  0.0527 | ms/batch 6526.48 |
| step 37759 |  lr: 0.0000500 | loss  0.0758 | ms/batch 6436.41 |
| step 37779 |  lr: 0.0000500 | loss  0.0558 | ms/batch 6406.93 |
| step 37799 |  lr: 0.0000500 | loss  0.0589 | ms/batch 6320.44 |
| step 37819 |  lr: 0.0000500 | loss  0.0594 | ms/batch 6379.21 |
| step 37839 |  lr: 0.0000500 | loss  0.0688 | ms/batch 6428.21 |
| step 37859 |  lr: 0.0000500 | loss  0.0602 | ms/batch 6535.71 |
| step 37879 |  lr: 0.0000500 | loss  0.0574 | ms/batch 6321.42 |
| step 37899 |  lr: 0.0000500 | loss  0.0518 | ms/batch 6386.70 |
| step 37919 |  lr: 0.0000500 | loss  0.0699 | ms/batch 6285.73 |
| step 37939 |  lr: 0.0000500 | loss  0.0610 | ms/batch 6246.54 |
| step 37959 |  lr: 0.0000500 | loss  0.0472 | ms/batch 6148.83 |
| step 37979 |  lr: 0.0000500 | loss  0.0680 | ms/batch 6273.49 |
| step 37999 |  lr: 0.0000500 | loss  0.0583 | ms/batch 6319.01 |
| step 38019 |  lr: 0.0000500 | loss  0.0616 | ms/batch 6353.63 |
| step 38039 |  lr: 0.0000500 | loss  0.0489 | ms/batch 6169.27 |
| step 38059 |  lr: 0.0000500 | loss  0.0743 | ms/batch 6236.86 |
| step 38079 |  lr: 0.0000500 | loss  0.0649 | ms/batch 6171.27 |
| step 38099 |  lr: 0.0000500 | loss  0.0558 | ms/batch 6162.83 |
| step 38119 |  lr: 0.0000500 | loss  0.0713 | ms/batch 6105.43 |
| step 38139 |  lr: 0.0000500 | loss  0.0774 | ms/batch 5986.48 |
| step 38159 |  lr: 0.0000500 | loss  0.0783 | ms/batch 6190.39 |
| step 38179 |  lr: 0.0000500 | loss  0.0588 | ms/batch 6116.31 |
| step 38199 |  lr: 0.0000500 | loss  0.0651 | ms/batch 6302.98 |
| step 38219 |  lr: 0.0000500 | loss  0.0597 | ms/batch 6440.19 |
| step 38239 |  lr: 0.0000500 | loss  0.0528 | ms/batch 6611.34 |
| step 38259 |  lr: 0.0000500 | loss  0.0740 | ms/batch 6583.38 |
| step 38279 |  lr: 0.0000500 | loss  0.0688 | ms/batch 6450.43 |
| step 38299 |  lr: 0.0000500 | loss  0.0626 | ms/batch 6279.34 |
| step 38319 |  lr: 0.0000500 | loss  0.0847 | ms/batch 6489.42 |
| step 38339 |  lr: 0.0000500 | loss  0.0601 | ms/batch 6382.81 |
| step 38359 |  lr: 0.0000500 | loss  0.0648 | ms/batch 6584.37 |
| step 38379 |  lr: 0.0000500 | loss  0.0814 | ms/batch 6567.95 |
| step 38399 |  lr: 0.0000500 | loss  0.0621 | ms/batch 6609.76 |
| step 38419 |  lr: 0.0000500 | loss  0.0571 | ms/batch 6363.25 |
| step 38439 |  lr: 0.0000500 | loss  0.0513 | ms/batch 6346.56 |
| step 38459 |  lr: 0.0000500 | loss  0.0750 | ms/batch 6173.03 |
| step 38479 |  lr: 0.0000500 | loss  0.0557 | ms/batch 6169.36 |
| step 38499 |  lr: 0.0000500 | loss  0.0720 | ms/batch 6104.25 |
| step 38519 |  lr: 0.0000500 | loss  0.0636 | ms/batch 6179.56 |
| step 38539 |  lr: 0.0000500 | loss  0.0646 | ms/batch 6199.05 |
| step 38559 |  lr: 0.0000500 | loss  0.0736 | ms/batch 6156.88 |
| step 38579 |  lr: 0.0000500 | loss  0.0663 | ms/batch 6066.48 |
-----------------------------------------------------------------------
| step 38583 | dev_acc  0.5071 | test_acc  0.2662 |
train_time : 8970.02 | eval_time : 96.82
-----------------------------------------------------------------------
| step 38599 |  lr: 0.0000500 | loss  0.0661 | ms/batch 5187.05 |
| step 38619 |  lr: 0.0000500 | loss  0.0444 | ms/batch 6291.56 |
| step 38639 |  lr: 0.0000500 | loss  0.0463 | ms/batch 6482.83 |
| step 38659 |  lr: 0.0000500 | loss  0.0464 | ms/batch 6436.80 |
| step 38679 |  lr: 0.0000500 | loss  0.0451 | ms/batch 6353.46 |
| step 38699 |  lr: 0.0000500 | loss  0.0374 | ms/batch 6238.53 |
| step 38719 |  lr: 0.0000500 | loss  0.0598 | ms/batch 6151.09 |
| step 38739 |  lr: 0.0000500 | loss  0.0554 | ms/batch 6570.22 |
| step 38759 |  lr: 0.0000500 | loss  0.0544 | ms/batch 6407.49 |
| step 38779 |  lr: 0.0000500 | loss  0.0510 | ms/batch 6473.53 |
| step 38799 |  lr: 0.0000500 | loss  0.0671 | ms/batch 6548.38 |
| step 38819 |  lr: 0.0000500 | loss  0.0535 | ms/batch 6319.80 |
| step 38839 |  lr: 0.0000500 | loss  0.0601 | ms/batch 6164.36 |
| step 38859 |  lr: 0.0000500 | loss  0.0637 | ms/batch 5923.25 |
| step 38879 |  lr: 0.0000500 | loss  0.0626 | ms/batch 6117.87 |
| step 38899 |  lr: 0.0000500 | loss  0.0443 | ms/batch 6315.26 |
| step 38919 |  lr: 0.0000500 | loss  0.0544 | ms/batch 6567.73 |
| step 38939 |  lr: 0.0000500 | loss  0.0603 | ms/batch 6464.12 |
| step 38959 |  lr: 0.0000500 | loss  0.0436 | ms/batch 6475.22 |
| step 38979 |  lr: 0.0000500 | loss  0.0543 | ms/batch 6544.95 |
| step 38999 |  lr: 0.0000500 | loss  0.0491 | ms/batch 6485.96 |
| step 39019 |  lr: 0.0000500 | loss  0.0599 | ms/batch 6336.83 |
| step 39039 |  lr: 0.0000500 | loss  0.0592 | ms/batch 6207.05 |
| step 39059 |  lr: 0.0000500 | loss  0.0631 | ms/batch 6241.40 |
| step 39079 |  lr: 0.0000500 | loss  0.0564 | ms/batch 5577.13 |
| step 39099 |  lr: 0.0000500 | loss  0.0480 | ms/batch 5199.89 |
| step 39119 |  lr: 0.0000500 | loss  0.0709 | ms/batch 5290.27 |
| step 39139 |  lr: 0.0000500 | loss  0.0529 | ms/batch 5226.03 |
| step 39159 |  lr: 0.0000500 | loss  0.0617 | ms/batch 5238.08 |
| step 39179 |  lr: 0.0000500 | loss  0.0587 | ms/batch 5018.99 |
| step 39199 |  lr: 0.0000500 | loss  0.0573 | ms/batch 5152.12 |
| step 39219 |  lr: 0.0000500 | loss  0.0582 | ms/batch 5158.80 |
| step 39239 |  lr: 0.0000500 | loss  0.0704 | ms/batch 5202.03 |
| step 39259 |  lr: 0.0000500 | loss  0.0642 | ms/batch 5154.66 |
| step 39279 |  lr: 0.0000500 | loss  0.0489 | ms/batch 5087.19 |
| step 39299 |  lr: 0.0000500 | loss  0.0669 | ms/batch 5116.08 |
| step 39319 |  lr: 0.0000500 | loss  0.0601 | ms/batch 5107.01 |
| step 39339 |  lr: 0.0000500 | loss  0.0631 | ms/batch 5130.76 |
| step 39359 |  lr: 0.0000500 | loss  0.0561 | ms/batch 5431.00 |
| step 39379 |  lr: 0.0000500 | loss  0.0699 | ms/batch 6106.07 |
| step 39399 |  lr: 0.0000500 | loss  0.0474 | ms/batch 6448.31 |
| step 39419 |  lr: 0.0000500 | loss  0.0661 | ms/batch 6204.76 |
| step 39439 |  lr: 0.0000500 | loss  0.0601 | ms/batch 6439.29 |
| step 39459 |  lr: 0.0000500 | loss  0.0574 | ms/batch 6312.98 |
| step 39479 |  lr: 0.0000500 | loss  0.0536 | ms/batch 6214.19 |
| step 39499 |  lr: 0.0000500 | loss  0.0569 | ms/batch 6038.01 |
| step 39519 |  lr: 0.0000500 | loss  0.0583 | ms/batch 6197.27 |
| step 39539 |  lr: 0.0000500 | loss  0.0538 | ms/batch 6220.91 |
| step 39559 |  lr: 0.0000500 | loss  0.0751 | ms/batch 6500.69 |
| step 39579 |  lr: 0.0000500 | loss  0.0778 | ms/batch 6526.88 |
| step 39599 |  lr: 0.0000500 | loss  0.0662 | ms/batch 6470.06 |
| step 39619 |  lr: 0.0000500 | loss  0.0622 | ms/batch 6478.56 |
| step 39639 |  lr: 0.0000500 | loss  0.0584 | ms/batch 6345.18 |
| step 39659 |  lr: 0.0000500 | loss  0.0769 | ms/batch 6619.59 |
| step 39679 |  lr: 0.0000500 | loss  0.0464 | ms/batch 6290.36 |
| step 39699 |  lr: 0.0000500 | loss  0.0845 | ms/batch 6360.76 |
| step 39719 |  lr: 0.0000500 | loss  0.0663 | ms/batch 6681.71 |
| step 39739 |  lr: 0.0000500 | loss  0.0853 | ms/batch 5985.87 |
| step 39759 |  lr: 0.0000500 | loss  0.0667 | ms/batch 5944.86 |
| step 39779 |  lr: 0.0000500 | loss  0.0679 | ms/batch 5900.71 |
| step 39799 |  lr: 0.0000500 | loss  0.0690 | ms/batch 6151.77 |
| step 39819 |  lr: 0.0000500 | loss  0.0642 | ms/batch 6267.77 |
| step 39839 |  lr: 0.0000500 | loss  0.0537 | ms/batch 6286.12 |
| step 39859 |  lr: 0.0000500 | loss  0.0608 | ms/batch 6330.29 |
| step 39879 |  lr: 0.0000500 | loss  0.0589 | ms/batch 6345.64 |
| step 39899 |  lr: 0.0000500 | loss  0.0778 | ms/batch 6480.13 |
| step 39919 |  lr: 0.0000500 | loss  0.0624 | ms/batch 6537.30 |
| step 39939 |  lr: 0.0000500 | loss  0.0681 | ms/batch 5981.38 |
| step 39959 |  lr: 0.0000500 | loss  0.0595 | ms/batch 6288.54 |
| step 39979 |  lr: 0.0000500 | loss  0.0600 | ms/batch 6257.10 |
| step 39999 |  lr: 0.0000500 | loss  0.0702 | ms/batch 6251.10 |
-----------------------------------------------------------------------
| step 40012 | dev_acc  0.5097 | test_acc  0.2737 |
train_time : 8685.65 | eval_time : 96.65
-----------------------------------------------------------------------
| step 40019 |  lr: 0.0000500 | loss  0.0690 | ms/batch 2406.62 |
| step 40039 |  lr: 0.0000500 | loss  0.0428 | ms/batch 6129.03 |
| step 40059 |  lr: 0.0000500 | loss  0.0505 | ms/batch 5817.95 |
| step 40079 |  lr: 0.0000500 | loss  0.0426 | ms/batch 5994.90 |
| step 40099 |  lr: 0.0000500 | loss  0.0560 | ms/batch 6206.99 |
| step 40119 |  lr: 0.0000500 | loss  0.0395 | ms/batch 6457.12 |
| step 40139 |  lr: 0.0000500 | loss  0.0482 | ms/batch 6490.20 |
| step 40159 |  lr: 0.0000500 | loss  0.0658 | ms/batch 6361.72 |
| step 40179 |  lr: 0.0000500 | loss  0.0772 | ms/batch 6487.07 |
| step 40199 |  lr: 0.0000500 | loss  0.0441 | ms/batch 6076.61 |
| step 40219 |  lr: 0.0000500 | loss  0.0443 | ms/batch 6216.80 |
| step 40239 |  lr: 0.0000500 | loss  0.0503 | ms/batch 6047.82 |
| step 40259 |  lr: 0.0000500 | loss  0.0561 | ms/batch 6197.02 |
| step 40279 |  lr: 0.0000500 | loss  0.0484 | ms/batch 6384.41 |
| step 40299 |  lr: 0.0000500 | loss  0.0419 | ms/batch 6400.94 |
| step 40319 |  lr: 0.0000500 | loss  0.0649 | ms/batch 6478.81 |
| step 40339 |  lr: 0.0000500 | loss  0.0451 | ms/batch 6477.43 |
| step 40359 |  lr: 0.0000500 | loss  0.0553 | ms/batch 6152.37 |
| step 40379 |  lr: 0.0000500 | loss  0.0477 | ms/batch 6155.66 |
| step 40399 |  lr: 0.0000500 | loss  0.0548 | ms/batch 6123.25 |
| step 40419 |  lr: 0.0000500 | loss  0.0526 | ms/batch 6057.04 |
| step 40439 |  lr: 0.0000500 | loss  0.0573 | ms/batch 5990.88 |
| step 40459 |  lr: 0.0000500 | loss  0.0485 | ms/batch 6321.64 |
| step 40479 |  lr: 0.0000500 | loss  0.0611 | ms/batch 6228.30 |
| step 40499 |  lr: 0.0000500 | loss  0.0584 | ms/batch 5965.72 |
| step 40519 |  lr: 0.0000500 | loss  0.0498 | ms/batch 6275.00 |
| step 40539 |  lr: 0.0000500 | loss  0.0674 | ms/batch 6000.83 |
| step 40559 |  lr: 0.0000500 | loss  0.0584 | ms/batch 6276.33 |
| step 40579 |  lr: 0.0000500 | loss  0.0573 | ms/batch 6073.10 |
| step 40599 |  lr: 0.0000500 | loss  0.0648 | ms/batch 6273.08 |
| step 40619 |  lr: 0.0000500 | loss  0.0595 | ms/batch 6385.50 |
| step 40639 |  lr: 0.0000500 | loss  0.0532 | ms/batch 6332.81 |
| step 40659 |  lr: 0.0000500 | loss  0.0485 | ms/batch 6520.88 |
| step 40679 |  lr: 0.0000500 | loss  0.0629 | ms/batch 6505.13 |
| step 40699 |  lr: 0.0000500 | loss  0.0521 | ms/batch 6457.62 |
| step 40719 |  lr: 0.0000500 | loss  0.0589 | ms/batch 6390.54 |
| step 40739 |  lr: 0.0000500 | loss  0.0508 | ms/batch 6585.51 |
| step 40759 |  lr: 0.0000500 | loss  0.0547 | ms/batch 6545.34 |
| step 40779 |  lr: 0.0000500 | loss  0.0569 | ms/batch 6234.49 |
| step 40799 |  lr: 0.0000500 | loss  0.0536 | ms/batch 6434.68 |
| step 40819 |  lr: 0.0000500 | loss  0.0650 | ms/batch 6593.22 |
| step 40839 |  lr: 0.0000500 | loss  0.0731 | ms/batch 6400.00 |
| step 40859 |  lr: 0.0000500 | loss  0.0442 | ms/batch 6523.72 |
| step 40879 |  lr: 0.0000500 | loss  0.0552 | ms/batch 6307.38 |
| step 40899 |  lr: 0.0000500 | loss  0.0591 | ms/batch 6284.83 |
| step 40919 |  lr: 0.0000500 | loss  0.0514 | ms/batch 6250.38 |
| step 40939 |  lr: 0.0000500 | loss  0.0594 | ms/batch 6309.47 |
| step 40959 |  lr: 0.0000500 | loss  0.0590 | ms/batch 6375.42 |
| step 40979 |  lr: 0.0000500 | loss  0.0608 | ms/batch 6274.28 |
| step 40999 |  lr: 0.0000500 | loss  0.0460 | ms/batch 8304.18 |
| step 41019 |  lr: 0.0000500 | loss  0.0614 | ms/batch 13695.85 |
| step 41039 |  lr: 0.0000500 | loss  0.0704 | ms/batch 12950.29 |
| step 41059 |  lr: 0.0000500 | loss  0.0526 | ms/batch 12823.37 |
| step 41079 |  lr: 0.0000500 | loss  0.0679 | ms/batch 13800.40 |
| step 41099 |  lr: 0.0000500 | loss  0.0497 | ms/batch 12206.67 |
| step 41119 |  lr: 0.0000500 | loss  0.0493 | ms/batch 12351.26 |
| step 41139 |  lr: 0.0000500 | loss  0.0576 | ms/batch 10514.03 |
| step 41159 |  lr: 0.0000500 | loss  0.0591 | ms/batch 12655.90 |
| step 41179 |  lr: 0.0000500 | loss  0.0529 | ms/batch 10486.30 |
| step 41199 |  lr: 0.0000500 | loss  0.0639 | ms/batch 8198.56 |
| step 41219 |  lr: 0.0000500 | loss  0.0586 | ms/batch 8294.87 |
| step 41239 |  lr: 0.0000500 | loss  0.0560 | ms/batch 11783.09 |
| step 41259 |  lr: 0.0000500 | loss  0.0728 | ms/batch 12693.10 |
| step 41279 |  lr: 0.0000500 | loss  0.0626 | ms/batch 12672.60 |
| step 41299 |  lr: 0.0000500 | loss  0.0853 | ms/batch 12603.11 |
| step 41319 |  lr: 0.0000500 | loss  0.0713 | ms/batch 13502.32 |
| step 41339 |  lr: 0.0000500 | loss  0.0625 | ms/batch 12818.37 |
| step 41359 |  lr: 0.0000500 | loss  0.0617 | ms/batch 14801.73 |
| step 41379 |  lr: 0.0000500 | loss  0.0750 | ms/batch 12883.55 |
| step 41399 |  lr: 0.0000500 | loss  0.0604 | ms/batch 11274.75 |
| step 41419 |  lr: 0.0000500 | loss  0.0597 | ms/batch 8621.71 |
| step 41439 |  lr: 0.0000500 | loss  0.0807 | ms/batch 9519.86 |
-----------------------------------------------------------------------
| step 41441 | dev_acc  0.5123 | test_acc  0.2672 |
train_time : 11483.27 | eval_time : 923.26
-----------------------------------------------------------------------
| step 41459 |  lr: 0.0000500 | loss  0.0402 | ms/batch 11707.22 |
| step 41479 |  lr: 0.0000500 | loss  0.0504 | ms/batch 13342.36 |
| step 41499 |  lr: 0.0000500 | loss  0.0458 | ms/batch 12715.15 |
| step 41519 |  lr: 0.0000500 | loss  0.0461 | ms/batch 11111.41 |
| step 41539 |  lr: 0.0000500 | loss  0.0401 | ms/batch 8384.79 |
| step 41559 |  lr: 0.0000500 | loss  0.0434 | ms/batch 8498.49 |
| step 41579 |  lr: 0.0000500 | loss  0.0465 | ms/batch 12902.47 |
| step 41599 |  lr: 0.0000500 | loss  0.0523 | ms/batch 13732.05 |
| step 41619 |  lr: 0.0000500 | loss  0.0447 | ms/batch 14234.14 |
| step 41639 |  lr: 0.0000500 | loss  0.0637 | ms/batch 12948.81 |
| step 41659 |  lr: 0.0000500 | loss  0.0498 | ms/batch 12984.92 |
| step 41679 |  lr: 0.0000500 | loss  0.0624 | ms/batch 12154.58 |
| step 41699 |  lr: 0.0000500 | loss  0.0520 | ms/batch 13223.66 |
| step 41719 |  lr: 0.0000500 | loss  0.0539 | ms/batch 12699.32 |
| step 41739 |  lr: 0.0000500 | loss  0.0527 | ms/batch 9698.23 |
| step 41759 |  lr: 0.0000500 | loss  0.0586 | ms/batch 7601.28 |
| step 41779 |  lr: 0.0000500 | loss  0.0610 | ms/batch 7264.32 |
| step 41799 |  lr: 0.0000500 | loss  0.0510 | ms/batch 9435.86 |
| step 41819 |  lr: 0.0000500 | loss  0.0612 | ms/batch 13054.81 |
| step 41839 |  lr: 0.0000500 | loss  0.0557 | ms/batch 12450.97 |
| step 41859 |  lr: 0.0000500 | loss  0.0477 | ms/batch 12873.65 |
| step 41879 |  lr: 0.0000500 | loss  0.0534 | ms/batch 12667.88 |
| step 41899 |  lr: 0.0000500 | loss  0.0542 | ms/batch 13650.09 |
| step 41919 |  lr: 0.0000500 | loss  0.0593 | ms/batch 11795.83 |
| step 41939 |  lr: 0.0000500 | loss  0.0460 | ms/batch 11700.16 |
| step 41959 |  lr: 0.0000500 | loss  0.0572 | ms/batch 11468.87 |
| step 41979 |  lr: 0.0000500 | loss  0.0540 | ms/batch 11174.71 |
| step 41999 |  lr: 0.0000500 | loss  0.0617 | ms/batch 8763.25 |
| step 42019 |  lr: 0.0000500 | loss  0.0510 | ms/batch 10777.24 |
| step 42039 |  lr: 0.0000500 | loss  0.0573 | ms/batch 14614.88 |
| step 42059 |  lr: 0.0000500 | loss  0.0623 | ms/batch 13700.33 |
| step 42079 |  lr: 0.0000500 | loss  0.0676 | ms/batch 7045.09 |
| step 42099 |  lr: 0.0000500 | loss  0.0530 | ms/batch 6336.08 |
| step 42119 |  lr: 0.0000500 | loss  0.0519 | ms/batch 6164.67 |
| step 42139 |  lr: 0.0000500 | loss  0.0532 | ms/batch 6317.10 |
| step 42159 |  lr: 0.0000500 | loss  0.0598 | ms/batch 6346.32 |
| step 42179 |  lr: 0.0000500 | loss  0.0669 | ms/batch 6268.23 |
| step 42199 |  lr: 0.0000500 | loss  0.0619 | ms/batch 6272.98 |
| step 42219 |  lr: 0.0000500 | loss  0.0677 | ms/batch 6502.13 |
| step 42239 |  lr: 0.0000500 | loss  0.0681 | ms/batch 6270.87 |
| step 42259 |  lr: 0.0000500 | loss  0.0575 | ms/batch 6413.34 |
| step 42279 |  lr: 0.0000500 | loss  0.0619 | ms/batch 6199.40 |
| step 42299 |  lr: 0.0000500 | loss  0.0506 | ms/batch 6301.16 |
| step 42319 |  lr: 0.0000500 | loss  0.0536 | ms/batch 6091.11 |
| step 42339 |  lr: 0.0000500 | loss  0.0493 | ms/batch 6148.79 |
| step 42359 |  lr: 0.0000500 | loss  0.0574 | ms/batch 6522.80 |
| step 42379 |  lr: 0.0000500 | loss  0.0663 | ms/batch 6499.56 |
| step 42399 |  lr: 0.0000500 | loss  0.0578 | ms/batch 6548.75 |
| step 42419 |  lr: 0.0000500 | loss  0.0482 | ms/batch 6642.26 |
| step 42439 |  lr: 0.0000500 | loss  0.0619 | ms/batch 6299.36 |
| step 42459 |  lr: 0.0000500 | loss  0.0452 | ms/batch 6320.69 |
| step 42479 |  lr: 0.0000500 | loss  0.0492 | ms/batch 6666.35 |
| step 42499 |  lr: 0.0000500 | loss  0.0671 | ms/batch 6623.12 |
| step 42519 |  lr: 0.0000500 | loss  0.0665 | ms/batch 6526.36 |
| step 42539 |  lr: 0.0000500 | loss  0.0629 | ms/batch 6566.54 |
| step 42559 |  lr: 0.0000500 | loss  0.0531 | ms/batch 6651.88 |
| step 42579 |  lr: 0.0000500 | loss  0.0697 | ms/batch 6460.67 |
| step 42599 |  lr: 0.0000500 | loss  0.0621 | ms/batch 6533.56 |
| step 42619 |  lr: 0.0000500 | loss  0.0553 | ms/batch 6182.85 |
| step 42639 |  lr: 0.0000500 | loss  0.0595 | ms/batch 6188.92 |
| step 42659 |  lr: 0.0000500 | loss  0.0569 | ms/batch 6270.82 |
| step 42679 |  lr: 0.0000500 | loss  0.0650 | ms/batch 6045.69 |
| step 42699 |  lr: 0.0000500 | loss  0.0619 | ms/batch 6000.93 |
| step 42719 |  lr: 0.0000500 | loss  0.0437 | ms/batch 5863.49 |
| step 42739 |  lr: 0.0000500 | loss  0.0507 | ms/batch 6315.95 |
| step 42759 |  lr: 0.0000500 | loss  0.0688 | ms/batch 6115.71 |
| step 42779 |  lr: 0.0000500 | loss  0.0675 | ms/batch 6270.08 |
| step 42799 |  lr: 0.0000500 | loss  0.0598 | ms/batch 6092.82 |
| step 42819 |  lr: 0.0000500 | loss  0.0589 | ms/batch 6312.57 |
| step 42839 |  lr: 0.0000500 | loss  0.0699 | ms/batch 6497.69 |
| step 42859 |  lr: 0.0000500 | loss  0.0558 | ms/batch 6289.56 |
-----------------------------------------------------------------------
| step 42870 | dev_acc  0.5013 | test_acc  0.2725 |
train_time : 12406.43 | eval_time : 97.36
-----------------------------------------------------------------------
| step 42879 |  lr: 0.0000500 | loss  0.0479 | ms/batch 3143.86 |
| step 42899 |  lr: 0.0000500 | loss  0.0403 | ms/batch 6092.83 |
| step 42919 |  lr: 0.0000500 | loss  0.0420 | ms/batch 5987.16 |
| step 42939 |  lr: 0.0000500 | loss  0.0482 | ms/batch 6199.72 |
| step 42959 |  lr: 0.0000500 | loss  0.0505 | ms/batch 6106.65 |
| step 42979 |  lr: 0.0000500 | loss  0.0535 | ms/batch 6223.09 |
| step 42999 |  lr: 0.0000500 | loss  0.0332 | ms/batch 6180.72 |
| step 43019 |  lr: 0.0000500 | loss  0.0522 | ms/batch 5957.32 |
| step 43039 |  lr: 0.0000500 | loss  0.0518 | ms/batch 5993.00 |
| step 43059 |  lr: 0.0000500 | loss  0.0469 | ms/batch 6320.62 |
| step 43079 |  lr: 0.0000500 | loss  0.0492 | ms/batch 6132.82 |
| step 43099 |  lr: 0.0000500 | loss  0.0422 | ms/batch 6109.73 |
| step 43119 |  lr: 0.0000500 | loss  0.0589 | ms/batch 6109.65 |
| step 43139 |  lr: 0.0000500 | loss  0.0510 | ms/batch 6538.97 |
| step 43159 |  lr: 0.0000500 | loss  0.0599 | ms/batch 6558.83 |
| step 43179 |  lr: 0.0000500 | loss  0.0390 | ms/batch 6648.60 |
| step 43199 |  lr: 0.0000500 | loss  0.0564 | ms/batch 6033.42 |
| step 43219 |  lr: 0.0000500 | loss  0.0554 | ms/batch 6086.90 |
| step 43239 |  lr: 0.0000500 | loss  0.0475 | ms/batch 6069.85 |
| step 43259 |  lr: 0.0000500 | loss  0.0499 | ms/batch 6068.60 |
| step 43279 |  lr: 0.0000500 | loss  0.0612 | ms/batch 6209.38 |
| step 43299 |  lr: 0.0000500 | loss  0.0637 | ms/batch 6606.92 |
| step 43319 |  lr: 0.0000500 | loss  0.0519 | ms/batch 6511.92 |
| step 43339 |  lr: 0.0000500 | loss  0.0422 | ms/batch 6478.03 |
| step 43359 |  lr: 0.0000500 | loss  0.0493 | ms/batch 6364.76 |
| step 43379 |  lr: 0.0000500 | loss  0.0513 | ms/batch 6365.74 |
| step 43399 |  lr: 0.0000500 | loss  0.0476 | ms/batch 6401.19 |
| step 43419 |  lr: 0.0000500 | loss  0.0439 | ms/batch 6353.96 |
| step 43439 |  lr: 0.0000500 | loss  0.0591 | ms/batch 6434.40 |
| step 43459 |  lr: 0.0000500 | loss  0.0758 | ms/batch 6471.11 |
| step 43479 |  lr: 0.0000500 | loss  0.0652 | ms/batch 6563.37 |
| step 43499 |  lr: 0.0000500 | loss  0.0482 | ms/batch 6358.70 |
| step 43519 |  lr: 0.0000500 | loss  0.0495 | ms/batch 6293.04 |
| step 43539 |  lr: 0.0000500 | loss  0.0553 | ms/batch 6166.11 |
| step 43559 |  lr: 0.0000500 | loss  0.0531 | ms/batch 6273.23 |
| step 43579 |  lr: 0.0000500 | loss  0.0548 | ms/batch 6459.59 |
| step 43599 |  lr: 0.0000500 | loss  0.0513 | ms/batch 6261.27 |
| step 43619 |  lr: 0.0000500 | loss  0.0483 | ms/batch 6247.13 |
| step 43639 |  lr: 0.0000500 | loss  0.0607 | ms/batch 6241.36 |
| step 43659 |  lr: 0.0000500 | loss  0.0385 | ms/batch 6130.60 |
| step 43679 |  lr: 0.0000500 | loss  0.0608 | ms/batch 6086.62 |
| step 43699 |  lr: 0.0000500 | loss  0.0516 | ms/batch 5987.62 |
| step 43719 |  lr: 0.0000500 | loss  0.0510 | ms/batch 5999.63 |
| step 43739 |  lr: 0.0000500 | loss  0.0650 | ms/batch 6025.56 |
| step 43759 |  lr: 0.0000500 | loss  0.0513 | ms/batch 6314.05 |
| step 43779 |  lr: 0.0000500 | loss  0.0444 | ms/batch 6414.47 |
| step 43799 |  lr: 0.0000500 | loss  0.0551 | ms/batch 6394.44 |
| step 43819 |  lr: 0.0000500 | loss  0.0592 | ms/batch 6530.03 |
| step 43839 |  lr: 0.0000500 | loss  0.0465 | ms/batch 6357.61 |
| step 43859 |  lr: 0.0000500 | loss  0.0503 | ms/batch 6294.36 |
| step 43879 |  lr: 0.0000500 | loss  0.0676 | ms/batch 6297.31 |
| step 43899 |  lr: 0.0000500 | loss  0.0578 | ms/batch 6245.08 |
| step 43919 |  lr: 0.0000500 | loss  0.0669 | ms/batch 6281.09 |
| step 43939 |  lr: 0.0000500 | loss  0.0459 | ms/batch 6173.61 |
| step 43959 |  lr: 0.0000500 | loss  0.0722 | ms/batch 6310.36 |
| step 43979 |  lr: 0.0000500 | loss  0.0633 | ms/batch 6369.53 |
| step 43999 |  lr: 0.0000500 | loss  0.0620 | ms/batch 6581.89 |
| step 44019 |  lr: 0.0000500 | loss  0.0656 | ms/batch 6624.49 |
| step 44039 |  lr: 0.0000500 | loss  0.0542 | ms/batch 6620.77 |
| step 44059 |  lr: 0.0000500 | loss  0.0630 | ms/batch 6214.44 |
| step 44079 |  lr: 0.0000500 | loss  0.0497 | ms/batch 6130.86 |
| step 44099 |  lr: 0.0000500 | loss  0.0463 | ms/batch 6298.83 |
| step 44119 |  lr: 0.0000500 | loss  0.0583 | ms/batch 6217.57 |
| step 44139 |  lr: 0.0000500 | loss  0.0616 | ms/batch 6088.61 |
| step 44159 |  lr: 0.0000500 | loss  0.0558 | ms/batch 6220.48 |
| step 44179 |  lr: 0.0000500 | loss  0.0631 | ms/batch 6411.46 |
| step 44199 |  lr: 0.0000500 | loss  0.0693 | ms/batch 6471.47 |
| step 44219 |  lr: 0.0000500 | loss  0.0485 | ms/batch 6440.27 |
| step 44239 |  lr: 0.0000500 | loss  0.0674 | ms/batch 6352.48 |
| step 44259 |  lr: 0.0000500 | loss  0.0517 | ms/batch 6310.84 |
| step 44279 |  lr: 0.0000500 | loss  0.0681 | ms/batch 6248.18 |
-----------------------------------------------------------------------
| step 44299 | dev_acc  0.4996 | test_acc  0.2789 |
train_time : 8978.71 | eval_time : 98.12
-----------------------------------------------------------------------
| step 44299 |  lr: 0.0000500 | loss  0.0546 | ms/batch  294.09 |
| step 44319 |  lr: 0.0000500 | loss  0.0496 | ms/batch 6117.30 |
| step 44339 |  lr: 0.0000500 | loss  0.0436 | ms/batch 6088.19 |
| step 44359 |  lr: 0.0000500 | loss  0.0427 | ms/batch 6420.80 |
| step 44379 |  lr: 0.0000500 | loss  0.0412 | ms/batch 6451.16 |
| step 44399 |  lr: 0.0000500 | loss  0.0631 | ms/batch 6423.18 |
| step 44419 |  lr: 0.0000500 | loss  0.0314 | ms/batch 6448.85 |
| step 44439 |  lr: 0.0000500 | loss  0.0425 | ms/batch 6448.97 |
| step 44459 |  lr: 0.0000500 | loss  0.0379 | ms/batch 6359.27 |
| step 44479 |  lr: 0.0000500 | loss  0.0377 | ms/batch 6292.00 |
| step 44499 |  lr: 0.0000500 | loss  0.0527 | ms/batch 6270.92 |
| step 44519 |  lr: 0.0000500 | loss  0.0450 | ms/batch 6356.80 |
| step 44539 |  lr: 0.0000500 | loss  0.0475 | ms/batch 6146.21 |
| step 44559 |  lr: 0.0000500 | loss  0.0450 | ms/batch 6359.55 |
| step 44579 |  lr: 0.0000500 | loss  0.0292 | ms/batch 6385.07 |
| step 44599 |  lr: 0.0000500 | loss  0.0690 | ms/batch 6504.45 |
| step 44619 |  lr: 0.0000500 | loss  0.0455 | ms/batch 6538.50 |
| step 44639 |  lr: 0.0000500 | loss  0.0494 | ms/batch 6460.07 |
| step 44659 |  lr: 0.0000500 | loss  0.0393 | ms/batch 6427.08 |
| step 44679 |  lr: 0.0000500 | loss  0.0530 | ms/batch 6474.86 |
| step 44699 |  lr: 0.0000500 | loss  0.0469 | ms/batch 6307.46 |
| step 44719 |  lr: 0.0000500 | loss  0.0438 | ms/batch 6042.06 |
| step 44739 |  lr: 0.0000500 | loss  0.0459 | ms/batch 9194.25 |
| step 44759 |  lr: 0.0000500 | loss  0.0491 | ms/batch 14070.54 |
| step 44779 |  lr: 0.0000500 | loss  0.0668 | ms/batch 12879.08 |
| step 44799 |  lr: 0.0000500 | loss  0.0509 | ms/batch 11951.58 |
| step 44819 |  lr: 0.0000500 | loss  0.0344 | ms/batch 14013.33 |
| step 44839 |  lr: 0.0000500 | loss  0.0511 | ms/batch 14446.10 |
| step 44859 |  lr: 0.0000500 | loss  0.0446 | ms/batch 12737.19 |
| step 44879 |  lr: 0.0000500 | loss  0.0409 | ms/batch 12627.25 |
| step 44899 |  lr: 0.0000500 | loss  0.0562 | ms/batch 12165.17 |
| step 44919 |  lr: 0.0000500 | loss  0.0595 | ms/batch 8251.86 |
| step 44939 |  lr: 0.0000500 | loss  0.0554 | ms/batch 8377.40 |
| step 44959 |  lr: 0.0000500 | loss  0.0617 | ms/batch 11814.49 |
| step 44979 |  lr: 0.0000500 | loss  0.0617 | ms/batch 13023.22 |
| step 44999 |  lr: 0.0000500 | loss  0.0521 | ms/batch 13558.92 |
| step 45019 |  lr: 0.0000500 | loss  0.0643 | ms/batch 12534.23 |
| step 45039 |  lr: 0.0000500 | loss  0.0536 | ms/batch 13129.70 |
| step 45059 |  lr: 0.0000500 | loss  0.0560 | ms/batch 12479.08 |
| step 45079 |  lr: 0.0000500 | loss  0.0590 | ms/batch 13283.26 |
| step 45099 |  lr: 0.0000500 | loss  0.0483 | ms/batch 12915.29 |
| step 45119 |  lr: 0.0000500 | loss  0.0486 | ms/batch 11690.00 |
| step 45139 |  lr: 0.0000500 | loss  0.0512 | ms/batch 8689.04 |
| step 45159 |  lr: 0.0000500 | loss  0.0766 | ms/batch 8988.71 |
| step 45179 |  lr: 0.0000500 | loss  0.0448 | ms/batch 14219.36 |
| step 45199 |  lr: 0.0000500 | loss  0.0409 | ms/batch 13609.31 |
| step 45219 |  lr: 0.0000500 | loss  0.0545 | ms/batch 12380.09 |
| step 45239 |  lr: 0.0000500 | loss  0.0565 | ms/batch 11706.02 |
| step 45259 |  lr: 0.0000500 | loss  0.0575 | ms/batch 12893.30 |
| step 45279 |  lr: 0.0000500 | loss  0.0556 | ms/batch 11371.49 |
| step 45299 |  lr: 0.0000500 | loss  0.0499 | ms/batch 10831.62 |
| step 45319 |  lr: 0.0000500 | loss  0.0684 | ms/batch 13184.16 |
| step 45339 |  lr: 0.0000500 | loss  0.0433 | ms/batch 11298.91 |
| step 45359 |  lr: 0.0000500 | loss  0.0718 | ms/batch 8615.37 |
| step 45379 |  lr: 0.0000500 | loss  0.0502 | ms/batch 9183.53 |
| step 45399 |  lr: 0.0000500 | loss  0.0380 | ms/batch 12594.29 |
| step 45419 |  lr: 0.0000500 | loss  0.0559 | ms/batch 12846.07 |
| step 45439 |  lr: 0.0000500 | loss  0.0435 | ms/batch 14250.98 |
| step 45459 |  lr: 0.0000500 | loss  0.0358 | ms/batch 12809.18 |
| step 45479 |  lr: 0.0000500 | loss  0.0646 | ms/batch 12862.20 |
| step 45499 |  lr: 0.0000500 | loss  0.0497 | ms/batch 11646.66 |
| step 45519 |  lr: 0.0000500 | loss  0.0636 | ms/batch 12128.43 |
| step 45539 |  lr: 0.0000500 | loss  0.0514 | ms/batch 13750.99 |
| step 45559 |  lr: 0.0000500 | loss  0.0609 | ms/batch 10657.87 |
| step 45579 |  lr: 0.0000500 | loss  0.0489 | ms/batch 8264.72 |
| step 45599 |  lr: 0.0000500 | loss  0.0518 | ms/batch 8390.21 |
| step 45619 |  lr: 0.0000500 | loss  0.0646 | ms/batch 14116.73 |
| step 45639 |  lr: 0.0000500 | loss  0.0556 | ms/batch 12590.70 |
| step 45659 |  lr: 0.0000500 | loss  0.0562 | ms/batch 12426.40 |
| step 45679 |  lr: 0.0000500 | loss  0.0486 | ms/batch 13265.57 |
| step 45699 |  lr: 0.0000500 | loss  0.0527 | ms/batch 10910.29 |
| step 45719 |  lr: 0.0000500 | loss  0.0511 | ms/batch 12584.56 |
-----------------------------------------------------------------------
| step 45728 | dev_acc  0.5030 | test_acc  0.2824 |
train_time : 14712.92 | eval_time : 692.42
-----------------------------------------------------------------------
| step 45739 |  lr: 0.0000500 | loss  0.0395 | ms/batch 4248.71 |
| step 45759 |  lr: 0.0000500 | loss  0.0533 | ms/batch 9277.55 |
| step 45779 |  lr: 0.0000500 | loss  0.0481 | ms/batch 11911.02 |
| step 45799 |  lr: 0.0000500 | loss  0.0536 | ms/batch 12865.30 |
| step 45819 |  lr: 0.0000500 | loss  0.0358 | ms/batch 10482.60 |
| step 45839 |  lr: 0.0000500 | loss  0.0513 | ms/batch 11503.15 |
| step 45859 |  lr: 0.0000500 | loss  0.0425 | ms/batch 11972.34 |
| step 45879 |  lr: 0.0000500 | loss  0.0426 | ms/batch 13537.14 |
| step 45899 |  lr: 0.0000500 | loss  0.0429 | ms/batch 12922.51 |
| step 45919 |  lr: 0.0000500 | loss  0.0566 | ms/batch 13471.32 |
| step 45939 |  lr: 0.0000500 | loss  0.0565 | ms/batch 10646.65 |
| step 45959 |  lr: 0.0000500 | loss  0.0478 | ms/batch 8642.17 |
| step 45979 |  lr: 0.0000500 | loss  0.0528 | ms/batch 10217.82 |
| step 45999 |  lr: 0.0000500 | loss  0.0357 | ms/batch 12672.15 |
| step 46019 |  lr: 0.0000500 | loss  0.0492 | ms/batch 14070.87 |
| step 46039 |  lr: 0.0000500 | loss  0.0529 | ms/batch 13070.77 |
| step 46059 |  lr: 0.0000500 | loss  0.0500 | ms/batch 14239.35 |
| step 46079 |  lr: 0.0000500 | loss  0.0530 | ms/batch 12064.04 |
| step 46099 |  lr: 0.0000500 | loss  0.0512 | ms/batch 12947.15 |
| step 46119 |  lr: 0.0000500 | loss  0.0563 | ms/batch 13107.14 |
| step 46139 |  lr: 0.0000500 | loss  0.0421 | ms/batch 13912.98 |
| step 46159 |  lr: 0.0000500 | loss  0.0554 | ms/batch 8534.24 |
| step 46179 |  lr: 0.0000500 | loss  0.0551 | ms/batch 8262.97 |
| step 46199 |  lr: 0.0000500 | loss  0.0408 | ms/batch 9885.92 |
| step 46219 |  lr: 0.0000500 | loss  0.0516 | ms/batch 12297.12 |
| step 46239 |  lr: 0.0000500 | loss  0.0659 | ms/batch 12296.44 |
| step 46259 |  lr: 0.0000500 | loss  0.0505 | ms/batch 12569.45 |
| step 46279 |  lr: 0.0000500 | loss  0.0682 | ms/batch 11494.13 |
| step 46299 |  lr: 0.0000500 | loss  0.0552 | ms/batch 11404.52 |
| step 46319 |  lr: 0.0000500 | loss  0.0559 | ms/batch 11537.50 |
| step 46339 |  lr: 0.0000500 | loss  0.0449 | ms/batch 9625.09 |
| step 46359 |  lr: 0.0000500 | loss  0.0416 | ms/batch 10611.21 |
| step 46379 |  lr: 0.0000500 | loss  0.0654 | ms/batch 12426.52 |
| step 46399 |  lr: 0.0000500 | loss  0.0567 | ms/batch 11173.16 |
| step 46419 |  lr: 0.0000500 | loss  0.0607 | ms/batch 8445.43 |
| step 46439 |  lr: 0.0000500 | loss  0.0413 | ms/batch 9331.07 |
| step 46459 |  lr: 0.0000500 | loss  0.0505 | ms/batch 13015.64 |
| step 46479 |  lr: 0.0000500 | loss  0.0574 | ms/batch 11162.87 |
| step 46499 |  lr: 0.0000500 | loss  0.0560 | ms/batch 13091.22 |
| step 46519 |  lr: 0.0000500 | loss  0.0627 | ms/batch 12836.82 |
| step 46539 |  lr: 0.0000500 | loss  0.0610 | ms/batch 14584.99 |
| step 46559 |  lr: 0.0000500 | loss  0.0458 | ms/batch 13572.22 |
| step 46579 |  lr: 0.0000500 | loss  0.0574 | ms/batch 13870.52 |
| step 46599 |  lr: 0.0000500 | loss  0.0530 | ms/batch 12861.78 |
| step 46619 |  lr: 0.0000500 | loss  0.0572 | ms/batch 9410.64 |
| step 46639 |  lr: 0.0000500 | loss  0.0480 | ms/batch 8373.28 |
| step 46659 |  lr: 0.0000500 | loss  0.0512 | ms/batch 9754.48 |
| step 46679 |  lr: 0.0000500 | loss  0.0604 | ms/batch 12264.33 |
| step 46699 |  lr: 0.0000500 | loss  0.0628 | ms/batch 12993.07 |
| step 46719 |  lr: 0.0000500 | loss  0.0607 | ms/batch 12984.85 |
| step 46739 |  lr: 0.0000500 | loss  0.0548 | ms/batch 13005.70 |
| step 46759 |  lr: 0.0000500 | loss  0.0578 | ms/batch 12908.27 |
| step 46779 |  lr: 0.0000500 | loss  0.0530 | ms/batch 13186.01 |
| step 46799 |  lr: 0.0000500 | loss  0.0599 | ms/batch 12695.40 |
| step 46819 |  lr: 0.0000500 | loss  0.0550 | ms/batch 11888.41 |
| step 46839 |  lr: 0.0000500 | loss  0.0412 | ms/batch 10341.13 |
| step 46859 |  lr: 0.0000500 | loss  0.0511 | ms/batch 8529.34 |
| step 46879 |  lr: 0.0000500 | loss  0.0579 | ms/batch 10322.63 |
| step 46899 |  lr: 0.0000500 | loss  0.0514 | ms/batch 13253.99 |
| step 46919 |  lr: 0.0000500 | loss  0.0533 | ms/batch 13414.37 |
| step 46939 |  lr: 0.0000500 | loss  0.0565 | ms/batch 12363.16 |
| step 46959 |  lr: 0.0000500 | loss  0.0457 | ms/batch 12219.22 |
| step 46979 |  lr: 0.0000500 | loss  0.0715 | ms/batch 12646.38 |
| step 46999 |  lr: 0.0000500 | loss  0.0686 | ms/batch 14005.28 |
| step 47019 |  lr: 0.0000500 | loss  0.0419 | ms/batch 12101.72 |
| step 47039 |  lr: 0.0000500 | loss  0.0582 | ms/batch 13458.60 |
| step 47059 |  lr: 0.0000500 | loss  0.0637 | ms/batch 9395.00 |
| step 47079 |  lr: 0.0000500 | loss  0.0676 | ms/batch 8814.26 |
| step 47099 |  lr: 0.0000500 | loss  0.0547 | ms/batch 11880.24 |
| step 47119 |  lr: 0.0000500 | loss  0.0546 | ms/batch 13486.23 |
| step 47139 |  lr: 0.0000500 | loss  0.0541 | ms/batch 14256.05 |
-----------------------------------------------------------------------
| step 47157 | dev_acc  0.4968 | test_acc  0.2750 |
train_time : 16857.28 | eval_time : 915.97
-----------------------------------------------------------------------
| step 47159 |  lr: 0.0000500 | loss  0.0392 | ms/batch 1596.56 |
| step 47179 |  lr: 0.0000500 | loss  0.0396 | ms/batch 8719.88 |
| step 47199 |  lr: 0.0000500 | loss  0.0531 | ms/batch 8086.90 |
| step 47219 |  lr: 0.0000500 | loss  0.0423 | ms/batch 8660.85 |
| step 47239 |  lr: 0.0000500 | loss  0.0298 | ms/batch 11671.41 |
| step 47259 |  lr: 0.0000500 | loss  0.0415 | ms/batch 13123.55 |
| step 47279 |  lr: 0.0000500 | loss  0.0494 | ms/batch 13778.14 |
| step 47299 |  lr: 0.0000500 | loss  0.0416 | ms/batch 13142.24 |
| step 47319 |  lr: 0.0000500 | loss  0.0499 | ms/batch 13864.33 |
| step 47339 |  lr: 0.0000500 | loss  0.0418 | ms/batch 13453.03 |
| step 47359 |  lr: 0.0000500 | loss  0.0462 | ms/batch 13144.00 |
| step 47379 |  lr: 0.0000500 | loss  0.0417 | ms/batch 13237.66 |
| step 47399 |  lr: 0.0000500 | loss  0.0500 | ms/batch 9179.05 |
| step 47419 |  lr: 0.0000500 | loss  0.0492 | ms/batch 8377.27 |
| step 47439 |  lr: 0.0000500 | loss  0.0470 | ms/batch 8893.24 |
| step 47459 |  lr: 0.0000500 | loss  0.0470 | ms/batch 12992.29 |
| step 47479 |  lr: 0.0000500 | loss  0.0544 | ms/batch 12550.06 |
| step 47499 |  lr: 0.0000500 | loss  0.0504 | ms/batch 12963.92 |
| step 47519 |  lr: 0.0000500 | loss  0.0425 | ms/batch 13286.25 |
| step 47539 |  lr: 0.0000500 | loss  0.0529 | ms/batch 13096.18 |
| step 47559 |  lr: 0.0000500 | loss  0.0404 | ms/batch 12477.42 |
| step 47579 |  lr: 0.0000500 | loss  0.0613 | ms/batch 13739.26 |
| step 47599 |  lr: 0.0000500 | loss  0.0367 | ms/batch 12661.98 |
| step 47619 |  lr: 0.0000500 | loss  0.0407 | ms/batch 10540.53 |
| step 47639 |  lr: 0.0000500 | loss  0.0525 | ms/batch 8504.01 |
| step 47659 |  lr: 0.0000500 | loss  0.0674 | ms/batch 10273.26 |
| step 47679 |  lr: 0.0000500 | loss  0.0555 | ms/batch 14040.54 |
| step 47699 |  lr: 0.0000500 | loss  0.0512 | ms/batch 13535.17 |
| step 47719 |  lr: 0.0000500 | loss  0.0590 | ms/batch 11433.27 |
| step 47739 |  lr: 0.0000500 | loss  0.0407 | ms/batch 11565.12 |
| step 47759 |  lr: 0.0000500 | loss  0.0552 | ms/batch 12210.86 |
| step 47779 |  lr: 0.0000500 | loss  0.0498 | ms/batch 13425.82 |
| step 47799 |  lr: 0.0000500 | loss  0.0582 | ms/batch 13032.62 |
| step 47819 |  lr: 0.0000500 | loss  0.0502 | ms/batch 14195.18 |
| step 47839 |  lr: 0.0000500 | loss  0.0454 | ms/batch 9885.00 |
| step 47859 |  lr: 0.0000500 | loss  0.0532 | ms/batch 8717.85 |
| step 47879 |  lr: 0.0000500 | loss  0.0516 | ms/batch 10819.85 |
| step 47899 |  lr: 0.0000500 | loss  0.0439 | ms/batch 13888.72 |
| step 47919 |  lr: 0.0000500 | loss  0.0654 | ms/batch 12106.18 |
| step 47939 |  lr: 0.0000500 | loss  0.0505 | ms/batch 12802.05 |
| step 47959 |  lr: 0.0000500 | loss  0.0581 | ms/batch 12112.08 |
| step 47979 |  lr: 0.0000500 | loss  0.0507 | ms/batch 13471.32 |
| step 47999 |  lr: 0.0000500 | loss  0.0449 | ms/batch 12168.77 |
| step 48019 |  lr: 0.0000500 | loss  0.0592 | ms/batch 12988.65 |
| step 48039 |  lr: 0.0000500 | loss  0.0472 | ms/batch 13000.03 |
| step 48059 |  lr: 0.0000500 | loss  0.0415 | ms/batch 9260.46 |
| step 48079 |  lr: 0.0000500 | loss  0.0594 | ms/batch 8379.12 |
| step 48099 |  lr: 0.0000500 | loss  0.0572 | ms/batch 9801.07 |
| step 48119 |  lr: 0.0000500 | loss  0.0428 | ms/batch 13298.94 |
| step 48139 |  lr: 0.0000500 | loss  0.0452 | ms/batch 10880.10 |
| step 48159 |  lr: 0.0000500 | loss  0.0443 | ms/batch 11180.61 |
| step 48179 |  lr: 0.0000500 | loss  0.0556 | ms/batch 12494.37 |
| step 48199 |  lr: 0.0000500 | loss  0.0606 | ms/batch 14022.84 |
| step 48219 |  lr: 0.0000500 | loss  0.0521 | ms/batch 13912.52 |
| step 48239 |  lr: 0.0000500 | loss  0.0449 | ms/batch 13470.48 |
| step 48259 |  lr: 0.0000500 | loss  0.0662 | ms/batch 12987.13 |
| step 48279 |  lr: 0.0000500 | loss  0.0578 | ms/batch 9752.97 |
| step 48299 |  lr: 0.0000500 | loss  0.0544 | ms/batch 8210.45 |
| step 48319 |  lr: 0.0000500 | loss  0.0655 | ms/batch 8586.35 |
| step 48339 |  lr: 0.0000500 | loss  0.0462 | ms/batch 12716.47 |
| step 48359 |  lr: 0.0000500 | loss  0.0547 | ms/batch 12703.70 |
| step 48379 |  lr: 0.0000500 | loss  0.0431 | ms/batch 13694.56 |
| step 48399 |  lr: 0.0000500 | loss  0.0427 | ms/batch 12919.72 |
| step 48419 |  lr: 0.0000500 | loss  0.0575 | ms/batch 12557.11 |
| step 48439 |  lr: 0.0000500 | loss  0.0506 | ms/batch 12476.06 |
| step 48459 |  lr: 0.0000500 | loss  0.0534 | ms/batch 13321.87 |
| step 48479 |  lr: 0.0000500 | loss  0.0504 | ms/batch 11670.26 |
| step 48499 |  lr: 0.0000500 | loss  0.0549 | ms/batch 11728.49 |
| step 48519 |  lr: 0.0000500 | loss  0.0390 | ms/batch 8708.01 |
| step 48539 |  lr: 0.0000500 | loss  0.0466 | ms/batch 9538.44 |
| step 48559 |  lr: 0.0000500 | loss  0.0559 | ms/batch 13158.98 |
| step 48579 |  lr: 0.0000500 | loss  0.0568 | ms/batch 13867.85 |
-----------------------------------------------------------------------
| step 48586 | dev_acc  0.4975 | test_acc  0.2763 |
train_time : 16936.38 | eval_time : 866.40
-----------------------------------------------------------------------
| step 48599 |  lr: 0.0000500 | loss  0.0421 | ms/batch 8903.34 |
| step 48619 |  lr: 0.0000500 | loss  0.0384 | ms/batch 12283.53 |
| step 48639 |  lr: 0.0000500 | loss  0.0359 | ms/batch 8717.30 |
| step 48659 |  lr: 0.0000500 | loss  0.0510 | ms/batch 8457.67 |
| step 48679 |  lr: 0.0000500 | loss  0.0461 | ms/batch 12699.68 |
| step 48699 |  lr: 0.0000500 | loss  0.0376 | ms/batch 12529.74 |
| step 48719 |  lr: 0.0000500 | loss  0.0413 | ms/batch 13538.28 |
| step 48739 |  lr: 0.0000500 | loss  0.0485 | ms/batch 12644.18 |
| step 48759 |  lr: 0.0000500 | loss  0.0423 | ms/batch 11318.50 |
| step 48779 |  lr: 0.0000500 | loss  0.0401 | ms/batch 13323.89 |
| step 48799 |  lr: 0.0000500 | loss  0.0444 | ms/batch 13134.67 |
| step 48819 |  lr: 0.0000500 | loss  0.0483 | ms/batch 13398.87 |
| step 48839 |  lr: 0.0000500 | loss  0.0433 | ms/batch 11242.21 |
| step 48859 |  lr: 0.0000500 | loss  0.0440 | ms/batch 8662.68 |
| step 48879 |  lr: 0.0000500 | loss  0.0438 | ms/batch 9962.83 |
| step 48899 |  lr: 0.0000500 | loss  0.0327 | ms/batch 13193.09 |
| step 48919 |  lr: 0.0000500 | loss  0.0469 | ms/batch 12343.43 |
| step 48939 |  lr: 0.0000500 | loss  0.0296 | ms/batch 14009.55 |
| step 48959 |  lr: 0.0000500 | loss  0.0611 | ms/batch 12415.86 |
| step 48979 |  lr: 0.0000500 | loss  0.0499 | ms/batch 10698.36 |
| step 48999 |  lr: 0.0000500 | loss  0.0577 | ms/batch 11566.68 |
| step 49019 |  lr: 0.0000500 | loss  0.0544 | ms/batch 10975.02 |
| step 49039 |  lr: 0.0000500 | loss  0.0441 | ms/batch 11725.12 |
| step 49059 |  lr: 0.0000500 | loss  0.0367 | ms/batch 11746.84 |
| step 49079 |  lr: 0.0000500 | loss  0.0511 | ms/batch 7772.04 |
| step 49099 |  lr: 0.0000500 | loss  0.0357 | ms/batch 7715.18 |
| step 49119 |  lr: 0.0000500 | loss  0.0439 | ms/batch 7954.95 |
| step 49139 |  lr: 0.0000500 | loss  0.0538 | ms/batch 12331.24 |
| step 49159 |  lr: 0.0000500 | loss  0.0540 | ms/batch 12454.41 |
| step 49179 |  lr: 0.0000500 | loss  0.0432 | ms/batch 14019.92 |
| step 49199 |  lr: 0.0000500 | loss  0.0464 | ms/batch 13380.90 |
| step 49219 |  lr: 0.0000500 | loss  0.0653 | ms/batch 12247.29 |
| step 49239 |  lr: 0.0000500 | loss  0.0557 | ms/batch 11855.51 |
| step 49259 |  lr: 0.0000500 | loss  0.0430 | ms/batch 12515.57 |
| step 49279 |  lr: 0.0000500 | loss  0.0592 | ms/batch 14127.62 |
| step 49299 |  lr: 0.0000500 | loss  0.0448 | ms/batch 10443.40 |
| step 49319 |  lr: 0.0000500 | loss  0.0465 | ms/batch 8686.39 |
| step 49339 |  lr: 0.0000500 | loss  0.0529 | ms/batch 10103.37 |
| step 49359 |  lr: 0.0000500 | loss  0.0543 | ms/batch 14692.19 |
| step 49379 |  lr: 0.0000500 | loss  0.0417 | ms/batch 12135.35 |
| step 49399 |  lr: 0.0000500 | loss  0.0552 | ms/batch 13610.76 |
| step 49419 |  lr: 0.0000500 | loss  0.0598 | ms/batch 14115.48 |
| step 49439 |  lr: 0.0000500 | loss  0.0370 | ms/batch 12577.10 |
| step 49459 |  lr: 0.0000500 | loss  0.0454 | ms/batch 13540.51 |
| step 49479 |  lr: 0.0000500 | loss  0.0471 | ms/batch 11880.97 |
| step 49499 |  lr: 0.0000500 | loss  0.0624 | ms/batch 13415.11 |
| step 49519 |  lr: 0.0000500 | loss  0.0453 | ms/batch 8293.27 |
| step 49539 |  lr: 0.0000500 | loss  0.0509 | ms/batch 8235.68 |
| step 49559 |  lr: 0.0000500 | loss  0.0763 | ms/batch 10308.56 |
| step 49579 |  lr: 0.0000500 | loss  0.0517 | ms/batch 12770.85 |
| step 49599 |  lr: 0.0000500 | loss  0.0516 | ms/batch 12982.09 |
| step 49619 |  lr: 0.0000500 | loss  0.0467 | ms/batch 13783.47 |
| step 49639 |  lr: 0.0000500 | loss  0.0592 | ms/batch 12443.21 |
| step 49659 |  lr: 0.0000500 | loss  0.0518 | ms/batch 13023.56 |
| step 49679 |  lr: 0.0000500 | loss  0.0518 | ms/batch 13814.89 |
| step 49699 |  lr: 0.0000500 | loss  0.0552 | ms/batch 12142.90 |
| step 49719 |  lr: 0.0000500 | loss  0.0460 | ms/batch 11411.84 |
| step 49739 |  lr: 0.0000500 | loss  0.0502 | ms/batch 8317.06 |
| step 49759 |  lr: 0.0000500 | loss  0.0723 | ms/batch 7258.00 |
| step 49779 |  lr: 0.0000500 | loss  0.0527 | ms/batch 7056.07 |
| step 49799 |  lr: 0.0000500 | loss  0.0774 | ms/batch 7736.21 |
| step 49819 |  lr: 0.0000500 | loss  0.0434 | ms/batch 12310.92 |
| step 49839 |  lr: 0.0000500 | loss  0.0491 | ms/batch 13800.96 |
| step 49859 |  lr: 0.0000500 | loss  0.0576 | ms/batch 13766.15 |
| step 49879 |  lr: 0.0000500 | loss  0.0470 | ms/batch 12193.28 |
| step 49899 |  lr: 0.0000500 | loss  0.0691 | ms/batch 14642.73 |
| step 49919 |  lr: 0.0000500 | loss  0.0496 | ms/batch 14244.31 |
| step 49939 |  lr: 0.0000500 | loss  0.0463 | ms/batch 13194.91 |
| step 49959 |  lr: 0.0000500 | loss  0.0374 | ms/batch 13104.58 |
| step 49979 |  lr: 0.0000500 | loss  0.0664 | ms/batch 8711.90 |
| step 49999 |  lr: 0.0000500 | loss  0.0673 | ms/batch 8200.23 |
-----------------------------------------------------------------------
| step 50015 | dev_acc  0.4941 | test_acc  0.2737 |
train_time : 16639.10 | eval_time : 971.58
-----------------------------------------------------------------------
| step 50019 |  lr: 0.0000500 | loss  0.0492 | ms/batch 2957.71 |
| step 50039 |  lr: 0.0000500 | loss  0.0482 | ms/batch 12775.15 |
| step 50059 |  lr: 0.0000500 | loss  0.0447 | ms/batch 13087.25 |
| step 50079 |  lr: 0.0000500 | loss  0.0267 | ms/batch 13508.79 |
| step 50099 |  lr: 0.0000500 | loss  0.0432 | ms/batch 9061.29 |
| step 50119 |  lr: 0.0000500 | loss  0.0515 | ms/batch 8666.63 |
| step 50139 |  lr: 0.0000500 | loss  0.0456 | ms/batch 10493.81 |
| step 50159 |  lr: 0.0000500 | loss  0.0281 | ms/batch 12965.70 |
| step 50179 |  lr: 0.0000500 | loss  0.0357 | ms/batch 12140.83 |
| step 50199 |  lr: 0.0000500 | loss  0.0540 | ms/batch 13294.96 |
| step 50219 |  lr: 0.0000500 | loss  0.0346 | ms/batch 13862.21 |
| step 50239 |  lr: 0.0000500 | loss  0.0558 | ms/batch 14790.25 |
| step 50259 |  lr: 0.0000500 | loss  0.0396 | ms/batch 12804.46 |
| step 50279 |  lr: 0.0000500 | loss  0.0439 | ms/batch 12733.99 |
| step 50299 |  lr: 0.0000500 | loss  0.0493 | ms/batch 12680.11 |
| step 50319 |  lr: 0.0000500 | loss  0.0511 | ms/batch 8126.31 |
| step 50339 |  lr: 0.0000500 | loss  0.0522 | ms/batch 8140.95 |
| step 50359 |  lr: 0.0000500 | loss  0.0443 | ms/batch 11270.31 |
| step 50379 |  lr: 0.0000500 | loss  0.0343 | ms/batch 12265.21 |
| step 50399 |  lr: 0.0000500 | loss  0.0463 | ms/batch 13876.58 |
| step 50419 |  lr: 0.0000500 | loss  0.0410 | ms/batch 12628.93 |
| step 50439 |  lr: 0.0000500 | loss  0.0509 | ms/batch 12646.16 |
| step 50459 |  lr: 0.0000500 | loss  0.0382 | ms/batch 13757.45 |
| step 50479 |  lr: 0.0000500 | loss  0.0511 | ms/batch 13573.79 |
| step 50499 |  lr: 0.0000500 | loss  0.0415 | ms/batch 12584.97 |
| step 50519 |  lr: 0.0000500 | loss  0.0553 | ms/batch 11677.86 |
| step 50539 |  lr: 0.0000500 | loss  0.0423 | ms/batch 9041.37 |
| step 50559 |  lr: 0.0000500 | loss  0.0404 | ms/batch 8487.99 |
| step 50579 |  lr: 0.0000500 | loss  0.0522 | ms/batch 10474.22 |
| step 50599 |  lr: 0.0000500 | loss  0.0533 | ms/batch 11536.16 |
| step 50619 |  lr: 0.0000500 | loss  0.0343 | ms/batch 12743.35 |
| step 50639 |  lr: 0.0000500 | loss  0.0388 | ms/batch 11892.75 |
| step 50659 |  lr: 0.0000500 | loss  0.0436 | ms/batch 12662.54 |
| step 50679 |  lr: 0.0000500 | loss  0.0560 | ms/batch 13153.55 |
| step 50699 |  lr: 0.0000500 | loss  0.0386 | ms/batch 12400.47 |
| step 50719 |  lr: 0.0000500 | loss  0.0456 | ms/batch 13291.83 |
| step 50739 |  lr: 0.0000500 | loss  0.0358 | ms/batch 11572.17 |
| step 50759 |  lr: 0.0000500 | loss  0.0452 | ms/batch 12097.68 |
| step 50779 |  lr: 0.0000500 | loss  0.0443 | ms/batch 8206.62 |
| step 50799 |  lr: 0.0000500 | loss  0.0430 | ms/batch 7309.70 |
| step 50819 |  lr: 0.0000500 | loss  0.0547 | ms/batch 9492.97 |
| step 50839 |  lr: 0.0000500 | loss  0.0528 | ms/batch 12693.07 |
| step 50859 |  lr: 0.0000500 | loss  0.0424 | ms/batch 13666.50 |
| step 50879 |  lr: 0.0000500 | loss  0.0530 | ms/batch 12090.86 |
| step 50899 |  lr: 0.0000500 | loss  0.0541 | ms/batch 12459.75 |
| step 50919 |  lr: 0.0000500 | loss  0.0408 | ms/batch 12252.48 |
| step 50939 |  lr: 0.0000500 | loss  0.0464 | ms/batch 13379.19 |
| step 50959 |  lr: 0.0000500 | loss  0.0693 | ms/batch 13288.54 |
| step 50979 |  lr: 0.0000500 | loss  0.0465 | ms/batch 11987.72 |
| step 50999 |  lr: 0.0000500 | loss  0.0506 | ms/batch 10236.18 |
| step 51019 |  lr: 0.0000500 | loss  0.0455 | ms/batch 8407.29 |
| step 51039 |  lr: 0.0000500 | loss  0.0537 | ms/batch 8830.86 |
| step 51059 |  lr: 0.0000500 | loss  0.0512 | ms/batch 11933.63 |
| step 51079 |  lr: 0.0000500 | loss  0.0399 | ms/batch 12702.05 |
| step 51099 |  lr: 0.0000500 | loss  0.0517 | ms/batch 14161.10 |
| step 51119 |  lr: 0.0000500 | loss  0.0415 | ms/batch 12224.26 |
| step 51139 |  lr: 0.0000500 | loss  0.0594 | ms/batch 13855.95 |
| step 51159 |  lr: 0.0000500 | loss  0.0511 | ms/batch 13110.20 |
| step 51179 |  lr: 0.0000500 | loss  0.0458 | ms/batch 12621.11 |
| step 51199 |  lr: 0.0000500 | loss  0.0420 | ms/batch 12195.71 |
| step 51219 |  lr: 0.0000500 | loss  0.0592 | ms/batch 11363.64 |
| step 51239 |  lr: 0.0000500 | loss  0.0528 | ms/batch 8310.95 |
| step 51259 |  lr: 0.0000500 | loss  0.0614 | ms/batch 8407.31 |
| step 51279 |  lr: 0.0000500 | loss  0.0448 | ms/batch 13082.02 |
| step 51299 |  lr: 0.0000500 | loss  0.0574 | ms/batch 13651.14 |
| step 51319 |  lr: 0.0000500 | loss  0.0499 | ms/batch 13321.44 |
| step 51339 |  lr: 0.0000500 | loss  0.0475 | ms/batch 13304.41 |
| step 51359 |  lr: 0.0000500 | loss  0.0477 | ms/batch 12956.68 |
| step 51379 |  lr: 0.0000500 | loss  0.0436 | ms/batch 13381.04 |
| step 51399 |  lr: 0.0000500 | loss  0.0682 | ms/batch 13174.11 |
| step 51419 |  lr: 0.0000500 | loss  0.0495 | ms/batch 11743.24 |
| step 51439 |  lr: 0.0000500 | loss  0.0573 | ms/batch 10624.87 |
-----------------------------------------------------------------------
| step 51444 | dev_acc  0.5004 | test_acc  0.2685 |
train_time : 16951.77 | eval_time : 697.58
-----------------------------------------------------------------------

training ends in 51444 steps
best dev acc: 0.5164 (at epoch 25)
final test acc: 0.2706
total_time : 372816.22

